{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "season_list = [2014, 2015, 2016]\n",
    "league = 'E0'\n",
    "classes = ['A', 'D', 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "best_features_NB = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features_extend_no_fouls = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"A_STD_THREE_AC\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"H_STD_THREE_AC\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"AandH_SEVEN_AC\",\"AandH_SEVEN_AR\",\"AandH_SEVEN_AS\",\"AandH_SEVEN_AST\",\"AandH_SEVEN_FTAG\",\"AandH_SEVEN_FTHG\",\"AandH_SEVEN_FTR_A\",\"AandH_SEVEN_FTR_D\",\"AandH_SEVEN_FTR_H\",\"AandH_SEVEN_HC\",\"AandH_SEVEN_HS\",\"AandH_SEVEN_HST\",\"AandH_SEVEN_HTAG\",\"AandH_SEVEN_HTHG\",\"AandH_SEVEN_HTR_A\",\"AandH_SEVEN_HTR_D\",\"AandH_SEVEN_HTR_H\",\"HandA_SEVEN_AC\",\"HandA_SEVEN_AR\",\"HandA_SEVEN_AS\",\"HandA_SEVEN_AST\",\"HandA_SEVEN_FTAG\",\"HandA_SEVEN_FTHG\",\"HandA_SEVEN_FTR_A\",\"HandA_SEVEN_FTR_D\",\"HandA_SEVEN_FTR_H\",\"HandA_SEVEN_HC\",\"HandA_SEVEN_HS\",\"HandA_SEVEN_HST\",\"HandA_SEVEN_HTAG\",\"HandA_SEVEN_HTHG\",\"HandA_SEVEN_HTR_A\",\"HandA_SEVEN_HTR_D\",\"HandA_SEVEN_HTR_H\"]\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP],\n",
    "    ['all_features', all_features],\n",
    "    ['best_features_NB', best_features_NB]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter for layer 1\n",
    "best_params = {\n",
    "    'C': 8.291,\n",
    "    'penalty': 'l2',\n",
    "    'class_weight': None,\n",
    "    'solver': 'sag',\n",
    "    'max_iter': 270,\n",
    "    'multi_class': 'multinomial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct base layer\n",
    "base_layer = [\n",
    "    ['XGBoost', False, 'no', 9, XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=160,\n",
    "        max_depth=8,\n",
    "        min_child_weight=7,\n",
    "        gamma=0.28,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6,\n",
    "        objective='multi:softprob',\n",
    "        reg_alpha=0.87,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=15), \n",
    "     ['all_features', all_features]\n",
    "    ],\n",
    "    ['NB', True, 'no', 9, GaussianNB(), ['best_features_NB', best_features_NB]],\n",
    "    ['MLP', True, 'no', 7, MLPClassifier(\n",
    "        random_state=0,\n",
    "        activation='logistic', \n",
    "        alpha=1.2, \n",
    "        hidden_layer_sizes=(100,),\n",
    "        max_iter=210, \n",
    "        solver='sgd'),\n",
    "     ['best_features_MLP', best_features_MLP]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure number of fold\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30912, 190)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month >= 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, calibration, historical_training_year, features):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'].dt.month < 6) | (df_test['INFO_Date'].dt.month > 10)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    # TODO drop NaN instead of replacing ith means \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    if calibration:\n",
    "        sc_X = StandardScaler().fit(X)\n",
    "        X = sc_X.transform(X)\n",
    "        X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out of fold prediction\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "    oof_train = np.zeros((x_train.shape[0],3))\n",
    "    oof_test = np.zeros((x_test.shape[0],3))\n",
    "    oof_test_skf = np.empty((NFOLDS, x_test.shape[0], 3))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        # Calibrate model\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_columns(layer, classes):\n",
    "    cols = []\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, clf, features in layer:\n",
    "        for result in classes:\n",
    "            cols.append(clf_name+result)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer1_df(X, X_test_season, base_layer, cols):\n",
    "    X_train_layer1 = np.zeros((X.shape[0], len(base_layer)*3))\n",
    "    X_train_layer1 = pd.DataFrame(X_train_layer1, columns=cols)\n",
    "    X_test_layer1 = np.zeros((X_test_season.shape[0], len(base_layer)*3))\n",
    "    X_test_layer1 = pd.DataFrame(X_test_layer1, columns=cols)\n",
    "    return X_train_layer1, X_test_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(y, pred, probs):\n",
    "    # Compute cross-entropy score\n",
    "    ll = log_loss(y, probs)\n",
    "    # Compute accuracy score\n",
    "    acc = accuracy_score(y, pred)\n",
    "    # Compute precision score\n",
    "    prec = precision_score(y, pred, average=None)\n",
    "    prec_A = prec[0]\n",
    "    prec_D = prec[1]\n",
    "    prec_H = prec[2]\n",
    "    # Compute recall score\n",
    "    rec = recall_score(y, pred, average=None)\n",
    "    rec_A = rec[0]\n",
    "    rec_D = rec[1]\n",
    "    rec_H = rec[2]\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y, pred, average=None)\n",
    "    f1_A = f1[0]\n",
    "    f1_D = f1[1]\n",
    "    f1_H = f1[2]\n",
    "    return {\n",
    "        'll': ll, \n",
    "        'acc': acc, \n",
    "        'prec_A': prec_A, \n",
    "        'prec_D': prec_D, \n",
    "        'prec_H': prec_H, \n",
    "        'rec_A': rec_A, \n",
    "        'rec_D': rec_D, \n",
    "        'rec_H': rec_H, \n",
    "        'f1_A': f1_A, \n",
    "        'f1_D': f1_D, \n",
    "        'f1_H': f1_H\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_money(df_test, pred_season, prob_season):\n",
    "    # Join odd and prediction together\n",
    "    df_test_season = df_test\n",
    "    df_test_season['probs_A'] = prob_season[:,0]\n",
    "    df_test_season['probs_D'] = prob_season[:,1]\n",
    "    df_test_season['probs_H'] = prob_season[:,2]\n",
    "    df_test_season['probs'] = df_test_season[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "    #df_test_season['pred'] = le.inverse_transform(pred_season)\n",
    "    df_test_season['pred'] = pred_season\n",
    "    df_test_season['WIN'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN'] = df_test_season['INFO_WIN']-1\n",
    "    df_test_season['WIN_P'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN_P'] = df_test_season['INFO_WIN_P']-1\n",
    "    df_test_season['INFO_ODD_BET'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'INFO_ODD_BET'] = df_test_season[odd_A]\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'INFO_ODD_BET'] = df_test_season[odd_D]\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'INFO_ODD_BET'] = df_test_season[odd_H]\n",
    "    df_test_season['prob_less_bet'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_A].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_D].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_H].apply(lambda x: 1/x)\n",
    "    # calculate money I can get following different scenario\n",
    "    # Bet on all\n",
    "    bet_all = df_test_season.WIN.mean()\n",
    "    # Bet under 1.9\n",
    "    bet_lte_19 = df_test_season[df_test_season['INFO_ODD_BET'] < 1.9].WIN.mean()\n",
    "    # Bet under 4\n",
    "    bet_lte_4 = df_test_season[df_test_season['INFO_ODD_BET'] < 4].WIN.mean()\n",
    "    # Bet between 1.9 and 4\n",
    "    bet_btw_19_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.9 and 5\n",
    "    bet_btw_19_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet between 1.5 and 4\n",
    "    bet_btw_15_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.5 and 5\n",
    "    bet_btw_15_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet prob higher than 50%\n",
    "    bet_pred_gte_50 = df_test_season[df_test_season.probs > 0.5].WIN.mean()\n",
    "    # Bet prob higher than 60%\n",
    "    bet_pred_gte_60 = df_test_season[df_test_season.probs > 0.6].WIN.mean()\n",
    "    # Bet prob higher than 70%\n",
    "    bet_pred_gte_70 = df_test_season[df_test_season.probs > 0.7].WIN.mean()\n",
    "    return {\n",
    "        'bet_all': bet_all,\n",
    "        'bet_lte_19': bet_lte_19,\n",
    "        'bet_lte_4': bet_lte_4,\n",
    "        'bet_btw_19_4': bet_btw_19_4,\n",
    "        'bet_btw_19_5': bet_btw_19_5,\n",
    "        'bet_btw_15_4': bet_btw_15_4,\n",
    "        'bet_btw_15_5': bet_btw_15_5\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season',\n",
    "    'C',\n",
    "    'penalty',\n",
    "    'class_weight',\n",
    "    'solver',\n",
    "    'max_iter',\n",
    "    'multi_class',\n",
    "    'll',\n",
    "    'acc',\n",
    "    'prec_A',\n",
    "    'prec_D',\n",
    "    'prec_H',\n",
    "    'rec_A',\n",
    "    'rec_D',\n",
    "    'rec_H',\n",
    "    'f1_A',\n",
    "    'f1_D',\n",
    "    'f1_H',\n",
    "    'bet_all',\n",
    "    'bet_lte_19',\n",
    "    'bet_lte_4',\n",
    "    'bet_btw_19_4',\n",
    "    'bet_btw_19_5',\n",
    "    'bet_btw_15_4',\n",
    "    'bet_btw_15_5'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 2014\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 2015\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n",
      "E0 2016\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n"
     ]
    }
   ],
   "source": [
    "for season in season_list:\n",
    "    print league,str(season)\n",
    "    \n",
    "    # Prepare the layer 1\n",
    "    df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, False, 9, all_features)\n",
    "    cols = get_layer_columns(base_layer, classes)\n",
    "    X_layer1, X_layer1_test_season = get_layer1_df(X, X_test_season, base_layer, cols)\n",
    "    \n",
    "    # train base layer\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, classifier, features in base_layer:\n",
    "        \n",
    "        #Get the dataset\n",
    "        df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, calibration, 9, features[1])\n",
    "        \n",
    "        print \"Processing model:\",clf_name\n",
    "        # Check if we need to recalibrate the prediction\n",
    "        if calibration == 'sigmoid':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "        elif calibration == 'isotonic':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "        elif calibration == 'no':\n",
    "            clf = classifier\n",
    "        # obtain out-of-fold predictions for this model\n",
    "        oof_train, oof_test = get_oof(clf, X, y, X_test_season)\n",
    "        X_layer1.loc[:, [clf_name+result for result in classes]] = oof_train\n",
    "        \n",
    "        # Base Layer for test season\n",
    "        #Get the dataset\n",
    "        df2, df_test, X2, y2, X_test_season, y_test_season = get_dataset(league, season, calibration, historical_training_year, features[1])\n",
    "        clf_test = classifier\n",
    "        clf_test.fit(X, y)\n",
    "        predict_probs_test = clf.predict_proba(X_test_season)\n",
    "        X_layer1_test_season.loc[:, [clf_name+result for result in classes]] = predict_probs_test\n",
    "\n",
    "    # train stacking model\n",
    "    clf_1 = LogisticRegression()\n",
    "    clf_1.fit(X_layer1, y)\n",
    "    # Predict target values\n",
    "    y_pred = clf_1.predict(X_layer1_test_season)\n",
    "    # Predict probabilities\n",
    "    y_probs = clf_1.predict_proba(X_layer1_test_season)\n",
    "    # get scores\n",
    "    score_dict = get_score(y_test_season, y_pred, y_probs)\n",
    "    # get money earned\n",
    "    money_dict = get_money(df_test, y_pred, y_probs)\n",
    "    # Keep result for further analyis\n",
    "    df_result = df_result.append(df_test)\n",
    "    # Add all info to result dataframe\n",
    "    result_df.loc[len(result_df.index)] = [\n",
    "        league, \n",
    "        season, \n",
    "        best_params['C'],\n",
    "        best_params['penalty'],\n",
    "        best_params['class_weight'],\n",
    "        best_params['solver'],\n",
    "        best_params['max_iter'],\n",
    "        best_params['multi_class'],\n",
    "        score_dict['ll'],\n",
    "        score_dict['acc'],\n",
    "        score_dict['prec_A'],\n",
    "        score_dict['prec_D'],\n",
    "        score_dict['prec_H'],\n",
    "        score_dict['rec_A'],\n",
    "        score_dict['rec_D'],\n",
    "        score_dict['rec_H'],\n",
    "        score_dict['f1_A'],\n",
    "        score_dict['f1_D'],\n",
    "        score_dict['f1_H'],\n",
    "        money_dict['bet_all'],\n",
    "        money_dict['bet_lte_19'],\n",
    "        money_dict['bet_lte_4'],\n",
    "        money_dict['bet_btw_19_4'],\n",
    "        money_dict['bet_btw_19_5'],\n",
    "        money_dict['bet_btw_15_4'],\n",
    "        money_dict['bet_btw_15_5']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('./report/STACKING_1_FTR_E0_BEST_VALIDATION-old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_result.to_csv('./report/E0-last-3-seasons-tuned-new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "Best is with ??? and ??? years of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_result\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.probs <= 0.4].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred != 'H'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred == 'D'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.prob_less_bet <= 0].index)\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] > 2]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    67.97153\n",
       "A    32.02847\n",
       "Name: pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.pred.value_counts() / len(df_bet_current_season.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    47.568209\n",
       "A    28.706999\n",
       "D    23.724792\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0018623962040332257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014400948991696319"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843, 202)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_Date</th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>probs</th>\n",
       "      <th>prob_less_bet</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.114309</td>\n",
       "      <td>0.211616</td>\n",
       "      <td>0.674075</td>\n",
       "      <td>0.674075</td>\n",
       "      <td>-0.113327</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.079738</td>\n",
       "      <td>0.193640</td>\n",
       "      <td>0.726622</td>\n",
       "      <td>0.726622</td>\n",
       "      <td>-0.128079</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.272184</td>\n",
       "      <td>0.265425</td>\n",
       "      <td>0.462391</td>\n",
       "      <td>0.462391</td>\n",
       "      <td>-0.119004</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.522355</td>\n",
       "      <td>0.251708</td>\n",
       "      <td>0.225937</td>\n",
       "      <td>0.522355</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.374546</td>\n",
       "      <td>0.270024</td>\n",
       "      <td>0.355431</td>\n",
       "      <td>0.374546</td>\n",
       "      <td>0.062046</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.351972</td>\n",
       "      <td>0.280973</td>\n",
       "      <td>0.367055</td>\n",
       "      <td>0.367055</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.387792</td>\n",
       "      <td>0.269847</td>\n",
       "      <td>0.342361</td>\n",
       "      <td>0.387792</td>\n",
       "      <td>0.067279</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-11-02</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.285104</td>\n",
       "      <td>0.377501</td>\n",
       "      <td>0.377501</td>\n",
       "      <td>0.108684</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-11-02</td>\n",
       "      <td>0.183922</td>\n",
       "      <td>0.235105</td>\n",
       "      <td>0.580973</td>\n",
       "      <td>0.580973</td>\n",
       "      <td>0.049058</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>0.347407</td>\n",
       "      <td>0.289580</td>\n",
       "      <td>0.363014</td>\n",
       "      <td>0.363014</td>\n",
       "      <td>-0.120078</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.316858</td>\n",
       "      <td>0.282708</td>\n",
       "      <td>0.400434</td>\n",
       "      <td>0.400434</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.271666</td>\n",
       "      <td>0.294268</td>\n",
       "      <td>0.434066</td>\n",
       "      <td>0.434066</td>\n",
       "      <td>0.128256</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.151405</td>\n",
       "      <td>0.229419</td>\n",
       "      <td>0.619176</td>\n",
       "      <td>0.619176</td>\n",
       "      <td>-0.150055</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.531087</td>\n",
       "      <td>0.247322</td>\n",
       "      <td>0.221591</td>\n",
       "      <td>0.531087</td>\n",
       "      <td>-0.149185</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.198278</td>\n",
       "      <td>0.707319</td>\n",
       "      <td>0.707319</td>\n",
       "      <td>0.008018</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.269829</td>\n",
       "      <td>0.274721</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>-0.125946</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>0.407730</td>\n",
       "      <td>0.275669</td>\n",
       "      <td>0.316601</td>\n",
       "      <td>0.407730</td>\n",
       "      <td>-0.087319</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>0.278185</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>0.176305</td>\n",
       "      <td>0.241315</td>\n",
       "      <td>0.582380</td>\n",
       "      <td>0.582380</td>\n",
       "      <td>-0.016422</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>0.316765</td>\n",
       "      <td>0.272481</td>\n",
       "      <td>0.410754</td>\n",
       "      <td>0.410754</td>\n",
       "      <td>-0.031724</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.122287</td>\n",
       "      <td>0.207827</td>\n",
       "      <td>0.669886</td>\n",
       "      <td>0.669886</td>\n",
       "      <td>0.204769</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.099824</td>\n",
       "      <td>0.199456</td>\n",
       "      <td>0.700719</td>\n",
       "      <td>0.700719</td>\n",
       "      <td>-0.112289</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.404724</td>\n",
       "      <td>0.266259</td>\n",
       "      <td>0.329016</td>\n",
       "      <td>0.404724</td>\n",
       "      <td>0.180509</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.286293</td>\n",
       "      <td>0.280314</td>\n",
       "      <td>0.433394</td>\n",
       "      <td>0.433394</td>\n",
       "      <td>-0.042797</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.125185</td>\n",
       "      <td>0.214540</td>\n",
       "      <td>0.660276</td>\n",
       "      <td>0.660276</td>\n",
       "      <td>-0.069651</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.107036</td>\n",
       "      <td>0.208820</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.134693</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-11-22</td>\n",
       "      <td>0.120088</td>\n",
       "      <td>0.215675</td>\n",
       "      <td>0.664237</td>\n",
       "      <td>0.664237</td>\n",
       "      <td>0.072521</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>0.395516</td>\n",
       "      <td>0.275531</td>\n",
       "      <td>0.328953</td>\n",
       "      <td>0.395516</td>\n",
       "      <td>-0.142119</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>0.456987</td>\n",
       "      <td>0.265796</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>0.456987</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>0.536779</td>\n",
       "      <td>0.252710</td>\n",
       "      <td>0.210511</td>\n",
       "      <td>0.536779</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>0.162342</td>\n",
       "      <td>0.229746</td>\n",
       "      <td>0.607913</td>\n",
       "      <td>0.607913</td>\n",
       "      <td>0.245594</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.409684</td>\n",
       "      <td>0.297321</td>\n",
       "      <td>0.292996</td>\n",
       "      <td>0.409684</td>\n",
       "      <td>0.166375</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.237795</td>\n",
       "      <td>0.284233</td>\n",
       "      <td>0.477972</td>\n",
       "      <td>0.477972</td>\n",
       "      <td>-0.150959</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.118426</td>\n",
       "      <td>0.203023</td>\n",
       "      <td>0.678551</td>\n",
       "      <td>0.678551</td>\n",
       "      <td>-0.183518</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0.235957</td>\n",
       "      <td>0.264808</td>\n",
       "      <td>0.499235</td>\n",
       "      <td>0.499235</td>\n",
       "      <td>0.219905</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.120604</td>\n",
       "      <td>0.204780</td>\n",
       "      <td>0.674616</td>\n",
       "      <td>0.674616</td>\n",
       "      <td>-0.015039</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.511916</td>\n",
       "      <td>0.258935</td>\n",
       "      <td>0.229149</td>\n",
       "      <td>0.511916</td>\n",
       "      <td>-0.223378</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.182621</td>\n",
       "      <td>0.244990</td>\n",
       "      <td>0.572389</td>\n",
       "      <td>0.572389</td>\n",
       "      <td>0.051556</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.128367</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.656007</td>\n",
       "      <td>0.656007</td>\n",
       "      <td>-0.157001</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.383343</td>\n",
       "      <td>0.299120</td>\n",
       "      <td>0.317537</td>\n",
       "      <td>0.383343</td>\n",
       "      <td>-0.116657</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.333684</td>\n",
       "      <td>0.287278</td>\n",
       "      <td>0.379039</td>\n",
       "      <td>0.379039</td>\n",
       "      <td>0.159741</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.350791</td>\n",
       "      <td>0.289502</td>\n",
       "      <td>0.359707</td>\n",
       "      <td>0.359707</td>\n",
       "      <td>0.112183</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.174456</td>\n",
       "      <td>0.246044</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.094064</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.187902</td>\n",
       "      <td>0.682430</td>\n",
       "      <td>0.682430</td>\n",
       "      <td>0.094195</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>0.271986</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>-0.137745</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>0.119660</td>\n",
       "      <td>0.191968</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>0.140176</td>\n",
       "      <td>0.213306</td>\n",
       "      <td>0.646518</td>\n",
       "      <td>0.646518</td>\n",
       "      <td>-0.270913</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>0.119250</td>\n",
       "      <td>0.206090</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>-0.210296</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>0.420179</td>\n",
       "      <td>0.278540</td>\n",
       "      <td>0.301281</td>\n",
       "      <td>0.420179</td>\n",
       "      <td>0.056543</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>0.329842</td>\n",
       "      <td>0.247523</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.189534</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.116621</td>\n",
       "      <td>0.199825</td>\n",
       "      <td>0.683554</td>\n",
       "      <td>0.683554</td>\n",
       "      <td>-0.020671</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.319332</td>\n",
       "      <td>0.313172</td>\n",
       "      <td>0.367495</td>\n",
       "      <td>0.367495</td>\n",
       "      <td>-0.052673</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.102186</td>\n",
       "      <td>0.190969</td>\n",
       "      <td>0.706845</td>\n",
       "      <td>0.706845</td>\n",
       "      <td>-0.162720</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.526507</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.226423</td>\n",
       "      <td>0.526507</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.132536</td>\n",
       "      <td>0.208649</td>\n",
       "      <td>0.658815</td>\n",
       "      <td>0.658815</td>\n",
       "      <td>0.137982</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.108766</td>\n",
       "      <td>0.217419</td>\n",
       "      <td>0.673815</td>\n",
       "      <td>0.673815</td>\n",
       "      <td>-0.219042</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.119746</td>\n",
       "      <td>0.215943</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.261085</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.328378</td>\n",
       "      <td>0.285482</td>\n",
       "      <td>0.386140</td>\n",
       "      <td>0.386140</td>\n",
       "      <td>-0.178831</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.142817</td>\n",
       "      <td>0.225197</td>\n",
       "      <td>0.631985</td>\n",
       "      <td>0.631985</td>\n",
       "      <td>0.146549</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.514314</td>\n",
       "      <td>0.247815</td>\n",
       "      <td>0.237872</td>\n",
       "      <td>0.514314</td>\n",
       "      <td>-0.266936</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFO_Date   probs_A   probs_D   probs_H     probs  prob_less_bet pred  \\\n",
       "0   2014-11-01  0.114309  0.211616  0.674075  0.674075      -0.113327    H   \n",
       "1   2014-11-01  0.079738  0.193640  0.726622  0.726622      -0.128079    H   \n",
       "2   2014-11-01  0.272184  0.265425  0.462391  0.462391      -0.119004    H   \n",
       "3   2014-11-01  0.522355  0.251708  0.225937  0.522355       0.024843    A   \n",
       "4   2014-11-01  0.374546  0.270024  0.355431  0.374546       0.062046    A   \n",
       "5   2014-11-01  0.351972  0.280973  0.367055  0.367055       0.098238    H   \n",
       "6   2014-11-01  0.387792  0.269847  0.342361  0.387792       0.067279    A   \n",
       "7   2014-11-02  0.337395  0.285104  0.377501  0.377501       0.108684    H   \n",
       "8   2014-11-02  0.183922  0.235105  0.580973  0.580973       0.049058    H   \n",
       "9   2014-11-03  0.347407  0.289580  0.363014  0.363014      -0.120078    H   \n",
       "10  2014-11-08  0.316858  0.282708  0.400434  0.400434      -0.001172    H   \n",
       "11  2014-11-08  0.271666  0.294268  0.434066  0.434066       0.128256    H   \n",
       "12  2014-11-08  0.151405  0.229419  0.619176  0.619176      -0.150055    H   \n",
       "13  2014-11-08  0.531087  0.247322  0.221591  0.531087      -0.149185    A   \n",
       "14  2014-11-08  0.094404  0.198278  0.707319  0.707319       0.008018    H   \n",
       "15  2014-11-08  0.269829  0.274721  0.455450  0.455450      -0.125946    H   \n",
       "16  2014-11-09  0.407730  0.275669  0.316601  0.407730      -0.087319    A   \n",
       "17  2014-11-09  0.460919  0.260896  0.278185  0.460919      -0.006371    A   \n",
       "18  2014-11-09  0.176305  0.241315  0.582380  0.582380      -0.016422    H   \n",
       "19  2014-11-09  0.316765  0.272481  0.410754  0.410754      -0.031724    H   \n",
       "20  2014-11-22  0.122287  0.207827  0.669886  0.669886       0.204769    H   \n",
       "21  2014-11-22  0.099824  0.199456  0.700719  0.700719      -0.112289    H   \n",
       "22  2014-11-22  0.404724  0.266259  0.329016  0.404724       0.180509    A   \n",
       "23  2014-11-22  0.286293  0.280314  0.433394  0.433394      -0.042797    H   \n",
       "24  2014-11-22  0.125185  0.214540  0.660276  0.660276      -0.069651    H   \n",
       "25  2014-11-22  0.107036  0.208820  0.684143  0.684143       0.134693    H   \n",
       "26  2014-11-22  0.120088  0.215675  0.664237  0.664237       0.072521    H   \n",
       "27  2014-11-23  0.395516  0.275531  0.328953  0.395516      -0.142119    A   \n",
       "28  2014-11-23  0.456987  0.265796  0.277217  0.456987      -0.005976    A   \n",
       "29  2014-11-24  0.536779  0.252710  0.210511  0.536779      -0.037934    A   \n",
       "..         ...       ...       ...       ...       ...            ...  ...   \n",
       "250 2017-05-06  0.162342  0.229746  0.607913  0.607913       0.245594    H   \n",
       "251 2017-05-07  0.409684  0.297321  0.292996  0.409684       0.166375    A   \n",
       "252 2017-05-07  0.237795  0.284233  0.477972  0.477972      -0.150959    H   \n",
       "253 2017-05-08  0.118426  0.203023  0.678551  0.678551      -0.183518    H   \n",
       "254 2017-05-10  0.235957  0.264808  0.499235  0.499235       0.219905    H   \n",
       "255 2017-05-12  0.120604  0.204780  0.674616  0.674616      -0.015039    H   \n",
       "256 2017-05-12  0.511916  0.258935  0.229149  0.511916      -0.223378    A   \n",
       "257 2017-05-13  0.182621  0.244990  0.572389  0.572389       0.051556    H   \n",
       "258 2017-05-13  0.128367  0.215627  0.656007  0.656007      -0.157001    H   \n",
       "259 2017-05-13  0.383343  0.299120  0.317537  0.383343      -0.116657    A   \n",
       "260 2017-05-13  0.333684  0.287278  0.379039  0.379039       0.159741    H   \n",
       "261 2017-05-13  0.350791  0.289502  0.359707  0.359707       0.112183    H   \n",
       "262 2017-05-14  0.174456  0.246044  0.579500  0.579500       0.094064    H   \n",
       "263 2017-05-14  0.129668  0.187902  0.682430  0.682430       0.094195    H   \n",
       "264 2017-05-14  0.461057  0.271986  0.266957  0.461057      -0.137745    A   \n",
       "265 2017-05-15  0.119660  0.191968  0.688372  0.688372      -0.118080    H   \n",
       "266 2017-05-16  0.140176  0.213306  0.646518  0.646518      -0.270913    H   \n",
       "267 2017-05-16  0.119250  0.206090  0.674660  0.674660      -0.210296    H   \n",
       "268 2017-05-17  0.420179  0.278540  0.301281  0.420179       0.056543    A   \n",
       "269 2017-05-18  0.329842  0.247523  0.422634  0.422634       0.189534    H   \n",
       "270 2017-05-21  0.116621  0.199825  0.683554  0.683554      -0.020671    H   \n",
       "271 2017-05-21  0.319332  0.313172  0.367495  0.367495      -0.052673    H   \n",
       "272 2017-05-21  0.102186  0.190969  0.706845  0.706845      -0.162720    H   \n",
       "273 2017-05-21  0.526507  0.247070  0.226423  0.526507      -0.127088    A   \n",
       "274 2017-05-21  0.132536  0.208649  0.658815  0.658815       0.137982    H   \n",
       "275 2017-05-21  0.108766  0.217419  0.673815  0.673815      -0.219042    H   \n",
       "276 2017-05-21  0.119746  0.215943  0.664311  0.664311       0.261085    H   \n",
       "277 2017-05-21  0.328378  0.285482  0.386140  0.386140      -0.178831    H   \n",
       "278 2017-05-21  0.142817  0.225197  0.631985  0.631985       0.146549    H   \n",
       "279 2017-05-21  0.514314  0.247815  0.237872  0.514314      -0.266936    A   \n",
       "\n",
       "    INFO_FTR   WIN  \n",
       "0          H  0.27  \n",
       "1          H  0.17  \n",
       "2          D -1.00  \n",
       "3          A  1.01  \n",
       "4          A  2.20  \n",
       "5          H  2.72  \n",
       "6          D -1.00  \n",
       "7          A -1.00  \n",
       "8          H  0.88  \n",
       "9          A -1.00  \n",
       "10         H  1.49  \n",
       "11         A -1.00  \n",
       "12         H  0.30  \n",
       "13         D -1.00  \n",
       "14         H  0.43  \n",
       "15         D -1.00  \n",
       "16         D -1.00  \n",
       "17         H -1.00  \n",
       "18         A -1.00  \n",
       "19         A -1.00  \n",
       "20         A -1.00  \n",
       "21         H  0.23  \n",
       "22         H -1.00  \n",
       "23         D -1.00  \n",
       "24         H  0.37  \n",
       "25         H  0.82  \n",
       "26         A -1.00  \n",
       "27         H -1.00  \n",
       "28         A  1.16  \n",
       "29         D -1.00  \n",
       "..       ...   ...  \n",
       "250        H  1.76  \n",
       "251        H -1.00  \n",
       "252        D -1.00  \n",
       "253        H  0.16  \n",
       "254        A -1.00  \n",
       "255        H  0.45  \n",
       "256        A  0.36  \n",
       "257        H  0.92  \n",
       "258        H  0.23  \n",
       "259        A  1.00  \n",
       "260        A -1.00  \n",
       "261        A -1.00  \n",
       "262        H  1.06  \n",
       "263        H  0.70  \n",
       "264        A  0.67  \n",
       "265        H  0.24  \n",
       "266        H  0.09  \n",
       "267        H  0.13  \n",
       "268        D -1.00  \n",
       "269        A -1.00  \n",
       "270        H  0.42  \n",
       "271        A -1.00  \n",
       "272        H  0.15  \n",
       "273        A  0.53  \n",
       "274        D -1.00  \n",
       "275        H  0.12  \n",
       "276        H  1.48  \n",
       "277        A -1.00  \n",
       "278        H  1.06  \n",
       "279        A  0.28  \n",
       "\n",
       "[843 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season[['INFO_Date', 'probs_A','probs_D','probs_H', 'probs', 'prob_less_bet', 'pred', 'INFO_FTR', 'WIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

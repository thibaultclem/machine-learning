{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost FTR HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # visualization library based on matplotlib\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\",\"INFO_Div\"]\n",
    "best_features_60 = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST',\n",
    "       'A_MEANS_FIVE_AY', 'A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG',\n",
    "       'A_MEANS_FIVE_FTR_A', 'A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC',\n",
    "       'A_MEANS_FIVE_HF', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST',\n",
    "       'A_MEANS_FIVE_HTHG', 'A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY',\n",
    "       'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST',\n",
    "       'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG',\n",
    "       'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC',\n",
    "       'H_MEANS_FIVE_HF', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST',\n",
    "       'H_MEANS_FIVE_HTAG', 'H_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_HTR_H',\n",
    "       'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG',\n",
    "       'A_MEANS_THREE_FTR_A', 'A_MEANS_THREE_HC', 'A_MEANS_THREE_HF',\n",
    "       'A_MEANS_THREE_HS', 'A_MEANS_THREE_HST', 'H_MEANS_THREE_AC',\n",
    "       'H_MEANS_THREE_AS', 'H_MEANS_THREE_AST', 'H_MEANS_THREE_FTHG',\n",
    "       'H_MEANS_THREE_HC', 'H_MEANS_THREE_HST', 'H_MEANS_THREE_HTR_H',\n",
    "       'A_STD_FIVE_AF', 'A_STD_FIVE_AS', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC',\n",
    "       'A_STD_FIVE_HF', 'A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS',\n",
    "       'H_STD_FIVE_AST', 'H_STD_FIVE_HC', 'H_STD_FIVE_HF',\n",
    "       'H_STD_FIVE_HST', 'H_STD_FIVE_HTHG', 'H_STD_THREE_AS',\n",
    "       'H_STD_THREE_HST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'XGboost-best_features'\n",
    "target = 'INFO_FTR_H'\n",
    "odd = 'INFO_BbAvH'\n",
    "bet_on = 'H'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all prematch data\n",
    "df = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df = (df[df.columns.drop(['index'])])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df['INFO_Date'] = pd.to_datetime(df['INFO_Date'])\n",
    "df['INFO_Date'].dt.month\n",
    "df = df[(df['INFO_Date'].dt.month < 6) | (df['INFO_Date'].dt.month > 10)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a particular league\n",
    "#df = df[(df['INFO_Div'] == 'D1')]\n",
    "#df = df[(df['INFO_Div'] == 'E0')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the average odd\n",
    "df[odd].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing column where odd is too high or too low\n",
    "# df = df.drop(df[df['INFO_BbAvH'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvH'] > 10].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] > 10].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain. If bet success it's equal to odd -1, else -1 (loose your bet)\n",
    "df['INFO_WIN'] = df[odd]-1\n",
    "df.loc[df.INFO_FTR != bet_on, 'INFO_WIN'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic about winners\n",
    "display(plt.show(), 100. * df.INFO_FTR.value_counts() / len(df.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much did you win/lost per match if bet on all\n",
    "df.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep season 2016/2017 for further test and don't use it for traning\n",
    "import datetime\n",
    "date_start_current_season = datetime.date(2016, 8, 1)\n",
    "df_current_season = df[(df['INFO_Date'] > date_start_current_season)]\n",
    "df = df[(df['INFO_Date'] < date_start_current_season)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of matches in current season\n",
    "df_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "features_list = all_features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X = pd.get_dummies(df[features_list])\n",
    "y = pd.get_dummies(df)[target].astype('bool_')\n",
    "X_current_season = pd.get_dummies(df_current_season[features_list])\n",
    "y_current_season = pd.get_dummies(df_current_season)[target].astype('bool_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc_X = StandardScaler().fit(X)\n",
    "#X = sc_X.transform(X)\n",
    "#X_current_season = sc_X.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute of missing values (NaN) with the mean\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp = imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "X_current_season = imp.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = XGBClassifier(nthread=4, seed=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# # Find the best n_estimator\n",
    "# import xgboost as xgb\n",
    "# xgb1 = XGBClassifier(\n",
    "#  learning_rate =0.01,\n",
    "#  n_estimators=5000,\n",
    "#  max_depth=3,\n",
    "#  min_child_weight=5,\n",
    "#  gamma=0,\n",
    "#  subsample=0.9,\n",
    "#  colsample_bytree=0.9,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# cvresult = xgb.cv(xgb1.get_xgb_params(), xgtrain, num_boost_round=1000, nfold=8,\n",
    "#             metrics='logloss', early_stopping_rounds=50, verbose_eval=True)\n",
    "# cvresult.shape[0]\n",
    "# # Result = 572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best hyper-parameters for our Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.classification import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [23],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# 'max_depth': 3, 'min_child_weight': 5\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [23],\n",
    "    'max_depth': [2, 3, 10, 30],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# 'max_depth': 3, 'min_child_weight': 5\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [44],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0, 0.2, 0.4, 0.6],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# gamma: 0\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [44],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# colsample_bytree': 0.9, 'subsample': 0.9\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [44],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0],\n",
    "    'subsample': [0.9, 1.0],\n",
    "    'colsample_bytree': [0.9, 1.0],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# colsample_bytree': 0.9, 'subsample': 0.9\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [44],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0],\n",
    "    'subsample': [0.85, 0.9, 0.95],\n",
    "    'colsample_bytree': [0.85, 0.9, 0.95],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1]\n",
    "}]\n",
    "# colsample_bytree': 0.9, 'subsample': 0.9\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [44],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0],\n",
    "    'subsample': [0.9],\n",
    "    'colsample_bytree': [0.9],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha':[0, 1e-5, 1e-2, 0.1, 1, 100]\n",
    "}]\n",
    "# 'reg_alpha': 0\n",
    "parameters = [{\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [572],#[716] for 60 features\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [5],\n",
    "    'gamma': [0.0],\n",
    "    'subsample': [0.9],\n",
    "    'colsample_bytree': [0.9],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha':[0]\n",
    "}]\n",
    "# FINAL\n",
    "parameters = [{\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [572],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha':[0]\n",
    "}]\n",
    "# {'colsample_bytree': 0.9,'max_depth': 3,'min_child_weight': 1,'scale_pos_weight': 1,'subsample': 0.9}\n",
    "parameters = [{\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [572],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.85, 0.9, 0.95],\n",
    "    'colsample_bytree': [0.85, 0.9, 0.95],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'scale_pos_weight': [1],\n",
    "    'reg_alpha':[0]\n",
    "}]\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=parameters,\n",
    "                           #scoring=make_scorer(log_loss, greater_is_better=False),\n",
    "                           scoring='roc_auc',\n",
    "                           cv=8,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best score calculated with the GridSearchCV\n",
    "best_score = grid_search.best_score_\n",
    "display(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyper-parameter calculated with the GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get all results of Grid Search\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.to_csv('./tuning/'+model_name+'-'+target+'_'+start_date+'.csv')\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new classifier using the best parameters found by the grid search\n",
    "clf = XGBClassifier(\n",
    "    nthread=4, \n",
    "    seed=15,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_child_weight=best_params['min_child_weight'],\n",
    "    gamma=best_params['gamma'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    objective=best_params['objective'],\n",
    "    scale_pos_weight=best_params['scale_pos_weight'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "clf.fit(X_train, y_train, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict target values\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-entropy score\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion Matrix\n",
    "df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test.ravel(), y_probs[:, 1].ravel())\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL DATASET TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on all the dataset\n",
    "X_pred = clf.predict(X)\n",
    "df['pred'] = X_pred\n",
    "df_bet_all_seasons = df.drop(df[df.pred == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many bet I did\n",
    "df_bet_all_seasons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_all_seasons.INFO_FTR.value_counts() / len(df_bet_all_seasons.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for all dataset\n",
    "precision_recall_fscore_support(y, X_pred, average='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the confusion Matrix\n",
    "df_confusion = pd.crosstab(y, X_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bet_all_seasons.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEASON 2016/2017 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on current season that is not use for train and test set\n",
    "X_pred_current_season = clf.predict(X_current_season)\n",
    "X_prob_current_season = clf.predict_proba(X_current_season)\n",
    "df_current_season['pred'] = X_pred_current_season\n",
    "df_current_season['prob'] = X_prob_current_season[:,1:]\n",
    "df_current_season['prob_less_bet'] = df_current_season['prob'] - df_current_season[odd].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_current_season\n",
    "df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred == 0].index)\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season.prob > 0.45]\n",
    "df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season[odd] > 2]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season[odd] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many bet I did\n",
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many matches was play\n",
    "X_pred_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y_current_season, X_pred_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for this current season\n",
    "precision_recall_fscore_support(y_current_season, X_pred_current_season, average='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_current_season, X_pred_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the confusion Matrix\n",
    "df_confusion = pd.crosstab(y_current_season, X_pred_current_season, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What I win/lost on each match\n",
    "df_bet_current_season.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bet_current_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a leqrning curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(clf, 'Learning Curve', X, y, cv=4, n_jobs=-1).show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_pos = y_probs[:,1]\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)\n",
    "\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('Classifier', ))\n",
    "\n",
    "ax2.hist(prob_iso_pos, range=(0, 1), bins=10, label='Classifier',histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "iso = CalibratedClassifierCV(clf, cv=4, method='isotonic')\n",
    "iso.fit(X_train, y_train)\n",
    "y_iso_probs = iso.predict_proba(X_test)\n",
    "prob_iso_pos = y_iso_probs[:,1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_iso_pos, n_bins=20)\n",
    "\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('Classifier', ))\n",
    "\n",
    "ax2.hist(prob_pos, range=(0, 1), bins=10, label='Classifier',histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_iso_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

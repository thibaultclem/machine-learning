{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP FTR HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # visualization library based on matplotlib\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\",\"INFO_Div\"]\n",
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST',\n",
    "       'A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H',\n",
    "       'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST',\n",
    "       'A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS',\n",
    "       'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG',\n",
    "       'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H',\n",
    "       'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST',\n",
    "       'H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS',\n",
    "       'A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS',\n",
    "       'A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "features_list = best_features_MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'MLP_FTR_GT2_LT4_LOG_LOSS'\n",
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "min_odd = 2\n",
    "max_odd = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25275, 190)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df = (df[df.columns.drop(['index'])])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df['INFO_Date'] = pd.to_datetime(df['INFO_Date'])\n",
    "df['INFO_Date'].dt.month\n",
    "df = df[(df['INFO_Date'].dt.month < 6) | (df['INFO_Date'].dt.month > 10)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove too small odd\n",
    "#df = df[(df[odd_H] > min_odd) & (df[odd_A] > min_odd)]\n",
    "#df = df[(df[odd_H] < max_odd) & (df[odd_A] < max_odd)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a particular league\n",
    "#df = df[(df['INFO_Div'] == 'E0')]\n",
    "#df = df[(df['INFO_Div'] == 'E0')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing column where odd is too high or too low\n",
    "# df = df.drop(df[df['INFO_BbAvH'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvH'] > 10].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] > 10].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_BbAvH</th>\n",
       "      <th>INFO_BbAvD</th>\n",
       "      <th>INFO_BbAvA</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>INFO_WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>1.86</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.09</td>\n",
       "      <td>H</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>3.75</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.95</td>\n",
       "      <td>A</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>4.28</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1.83</td>\n",
       "      <td>D</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>1.83</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.18</td>\n",
       "      <td>D</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>2.51</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.63</td>\n",
       "      <td>A</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>1.99</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.86</td>\n",
       "      <td>H</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>1.64</td>\n",
       "      <td>3.41</td>\n",
       "      <td>5.66</td>\n",
       "      <td>A</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>2.71</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.68</td>\n",
       "      <td>A</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>2.08</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.64</td>\n",
       "      <td>H</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>2.49</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.84</td>\n",
       "      <td>D</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFO_BbAvH  INFO_BbAvD  INFO_BbAvA INFO_FTR  INFO_WIN\n",
       "920        1.86        3.38        4.09        H      1.86\n",
       "921        3.75        3.34        1.95        A      1.95\n",
       "922        4.28        3.44        1.83        D      3.44\n",
       "923        1.83        3.38        4.18        D      3.38\n",
       "924        2.51        3.25        2.63        A      2.63\n",
       "925        1.99        3.13        3.86        H      1.99\n",
       "926        1.64        3.41        5.66        A      5.66\n",
       "927        2.71        2.94        2.68        A      2.68\n",
       "928        2.08        3.14        3.64        H      2.08\n",
       "929        2.49        3.11        2.84        D      3.11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df['INFO_WIN'] = 0\n",
    "df.loc[df.INFO_FTR == 'H', 'INFO_WIN'] = df[odd_H]\n",
    "df.loc[df.INFO_FTR == 'A', 'INFO_WIN'] = df[odd_A]\n",
    "df.loc[df.INFO_FTR == 'D', 'INFO_WIN'] = df[odd_D]\n",
    "df['INFO_WIN_P'] = 0\n",
    "df.loc[df.INFO_FTR == 'H', 'INFO_WIN_P'] = df['INFO_PSH']\n",
    "df.loc[df.INFO_FTR == 'A', 'INFO_WIN_P'] = df['INFO_PSA']\n",
    "df.loc[df.INFO_FTR == 'D', 'INFO_WIN_P'] = df['INFO_PSD']\n",
    "df[[odd_H, odd_D, odd_A, 'INFO_FTR', 'INFO_WIN']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    45.515061\n",
       "A    28.856715\n",
       "D    25.628224\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Statistic about winners\n",
    "display(plt.show(), 100. * df.INFO_FTR.value_counts() / len(df.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7576302213346655"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much did you win/lost per match if bet on all\n",
    "df.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep season 2016/2017 for further test and don't use it for traning\n",
    "import datetime\n",
    "date_start_learn = datetime.date(2007, 8, 1)\n",
    "date_end_learn = datetime.date(2016, 8, 1)\n",
    "date_start_current_season = datetime.date(2016, 8, 1)\n",
    "date_end_current_season = datetime.date(2017, 8, 1)\n",
    "df_current_season = df[(df['INFO_Date'] > date_start_current_season)]\n",
    "df_current_season = df_current_season[(df_current_season['INFO_Date'] < date_end_current_season)]\n",
    "df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "df = df[(df['INFO_Date'] < date_end_learn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    37.382704\n",
       "A    33.578494\n",
       "D    29.038803\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove too small odd\n",
    "df = df[(df[odd_H] > min_odd) & (df[odd_A] > min_odd)]\n",
    "df = df[(df[odd_H] < max_odd) & (df[odd_A] < max_odd)]\n",
    "display(plt.show(), 100. * df.INFO_FTR.value_counts() / len(df.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 192)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222, 192)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of matches in current season\n",
    "df_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode string label\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[target])\n",
    "# Prepare the dataset\n",
    "X = pd.get_dummies(df[features_list])\n",
    "y = le.transform(df[target]) \n",
    "X_current_season = pd.get_dummies(df_current_season[features_list])\n",
    "y_current_season = le.transform(df_current_season[target]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_current_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X)\n",
    "X = sc_X.transform(X)\n",
    "X_current_season = sc_X.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute of missing values (NaN) with the mean\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp = imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "X_current_season = imp.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = MLPClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 3 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.131742000579834"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Grid Search to find the best hyper-parameters for our Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.classification import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "parameters = [{\n",
    "    'hidden_layer_sizes': [(10, ), (30, ), (100, )], # 100\n",
    "    'activation': ['identity', 'logistic', 'relu'], # logistic\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'], # sgd\n",
    "    'alpha': [1, 3, 10] # 1\n",
    "}]\n",
    "\n",
    "parameters = [{\n",
    "    'hidden_layer_sizes': [(80, ), (100, ), (150, )], # 100\n",
    "    'activation': ['logistic'], # logistic\n",
    "    'solver': ['sgd'], # sgd\n",
    "    'alpha': [0.1, 1] # 1\n",
    "}]\n",
    "parameters = [{\n",
    "    'hidden_layer_sizes': [(100, ), (120, )], # 100\n",
    "    'activation': ['logistic'], # logistic\n",
    "    'solver': ['sgd'], # sgd\n",
    "    'alpha': [0.7, 1, 1.2] # 1\n",
    "}]\n",
    "parameters = [{\n",
    "    'hidden_layer_sizes': [(100, )], # 100\n",
    "    'activation': ['logistic'], # logistic\n",
    "    'solver': ['sgd'], # sgd\n",
    "    'alpha': [1], # 1\n",
    "    'max_iter': [100, 200, 300] # 200\n",
    "}]\n",
    "parameters = [{\n",
    "    'hidden_layer_sizes': [(100, )], # 100\n",
    "    'activation': ['logistic'], # logistic\n",
    "    'solver': ['sgd'], # sgd\n",
    "    'alpha': [1], # 1\n",
    "    'max_iter': [200] # 200\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=parameters,\n",
    "                           scoring=make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
    "                           cv=8,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0895229080033264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract best score calculated with the GridSearchCV\n",
    "best_score = grid_search.best_score_\n",
    "display(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'alpha': 1,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'max_iter': 200,\n",
       " 'solver': 'sgd'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyper-parameter calculated with the GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600802</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>-1.089535</td>\n",
       "      <td>-1.086240</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{u'alpha': 1, u'activation': u'logistic', u'ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089182</td>\n",
       "      <td>-1.085842</td>\n",
       "      <td>-1.090097</td>\n",
       "      <td>-1.085589</td>\n",
       "      <td>-1.088012</td>\n",
       "      <td>-1.08603</td>\n",
       "      <td>0.673824</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.726111</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>-1.089523</td>\n",
       "      <td>-1.086203</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>200</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{u'alpha': 1, u'activation': u'logistic', u'ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089084</td>\n",
       "      <td>-1.085541</td>\n",
       "      <td>-1.090097</td>\n",
       "      <td>-1.085589</td>\n",
       "      <td>-1.088012</td>\n",
       "      <td>-1.08603</td>\n",
       "      <td>1.004610</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.325504</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>-1.089523</td>\n",
       "      <td>-1.086203</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>300</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{u'alpha': 1, u'activation': u'logistic', u'ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089084</td>\n",
       "      <td>-1.085541</td>\n",
       "      <td>-1.090097</td>\n",
       "      <td>-1.085589</td>\n",
       "      <td>-1.088012</td>\n",
       "      <td>-1.08603</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       3.600802         0.004735        -1.089535         -1.086240   \n",
       "1       3.726111         0.003858        -1.089523         -1.086203   \n",
       "2       3.325504         0.003805        -1.089523         -1.086203   \n",
       "\n",
       "  param_activation param_alpha param_hidden_layer_sizes param_max_iter  \\\n",
       "0         logistic           1                   (100,)            100   \n",
       "1         logistic           1                   (100,)            200   \n",
       "2         logistic           1                   (100,)            300   \n",
       "\n",
       "  param_solver                                             params  \\\n",
       "0          sgd  {u'alpha': 1, u'activation': u'logistic', u'ma...   \n",
       "1          sgd  {u'alpha': 1, u'activation': u'logistic', u'ma...   \n",
       "2          sgd  {u'alpha': 1, u'activation': u'logistic', u'ma...   \n",
       "\n",
       "        ...         split5_test_score  split5_train_score  split6_test_score  \\\n",
       "0       ...                 -1.089182           -1.085842          -1.090097   \n",
       "1       ...                 -1.089084           -1.085541          -1.090097   \n",
       "2       ...                 -1.089084           -1.085541          -1.090097   \n",
       "\n",
       "   split6_train_score  split7_test_score  split7_train_score  std_fit_time  \\\n",
       "0           -1.085589          -1.088012            -1.08603      0.673824   \n",
       "1           -1.085589          -1.088012            -1.08603      1.004610   \n",
       "2           -1.085589          -1.088012            -1.08603      0.603938   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000501        0.001209         0.000439  \n",
       "1        0.000162        0.001213         0.000482  \n",
       "2        0.000369        0.001213         0.000482  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all results of Grid Search\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.to_csv('./tuning/'+model_name+'-'+target+'_'+start_date+'.csv')\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a new classifier using the best parameters found by the grid search\n",
    "clf = MLPClassifier(random_state=0,\n",
    "                    activation=best_params['activation'],\n",
    "                    alpha=best_params['alpha'],\n",
    "                    hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "                    solver=best_params['solver']\n",
    "                   )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict target values\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0953926071968678"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.37      0.17      0.23       812\n",
      "          D       0.00      0.00      0.00       703\n",
      "          H       0.37      0.86      0.52       851\n",
      "\n",
      "avg / total       0.26      0.37      0.26      2366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=['A', 'D', 'H']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36728655959425188"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL DATASET TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on all the dataset\n",
    "X_pred = clf.predict(X)\n",
    "X_probs = clf.predict_proba(X)\n",
    "\n",
    "df['pred'] = le.inverse_transform(X_pred)\n",
    "\n",
    "df['probs_A'] = X_probs[:,0]\n",
    "df['probs_D'] = X_probs[:,1]\n",
    "df['probs_H'] = X_probs[:,2]\n",
    "#df['probs_A'] = X_probs[:,0]\n",
    "#df['probs_D'] = X_probs[:,1]\n",
    "#df['probs_H'] = X_probs[:,2]\n",
    "df['probs'] = df[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "\n",
    "df['WIN'] = -1\n",
    "df.loc[df.INFO_FTR == df.pred, 'WIN'] = df['INFO_WIN']\n",
    "\n",
    "df_bet_all_seasons = df.drop(df[df.pred == 'X'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0.360504</td>\n",
       "      <td>0.270994</td>\n",
       "      <td>0.368502</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.343951</td>\n",
       "      <td>0.284987</td>\n",
       "      <td>0.371062</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.323935</td>\n",
       "      <td>0.304490</td>\n",
       "      <td>0.371576</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0.280394</td>\n",
       "      <td>0.286063</td>\n",
       "      <td>0.433543</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.355033</td>\n",
       "      <td>0.225053</td>\n",
       "      <td>0.419914</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.300526</td>\n",
       "      <td>0.312887</td>\n",
       "      <td>0.386587</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0.355304</td>\n",
       "      <td>0.261278</td>\n",
       "      <td>0.383419</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.271416</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.324874</td>\n",
       "      <td>0.299562</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.349898</td>\n",
       "      <td>0.275734</td>\n",
       "      <td>0.374368</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.299473</td>\n",
       "      <td>0.303722</td>\n",
       "      <td>0.396806</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.329428</td>\n",
       "      <td>0.258576</td>\n",
       "      <td>0.411997</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.359077</td>\n",
       "      <td>0.273831</td>\n",
       "      <td>0.367092</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0.315160</td>\n",
       "      <td>0.285771</td>\n",
       "      <td>0.399069</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.347844</td>\n",
       "      <td>0.308913</td>\n",
       "      <td>0.343243</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.366169</td>\n",
       "      <td>0.289943</td>\n",
       "      <td>0.343887</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.289476</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>0.442208</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.290132</td>\n",
       "      <td>0.293804</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.326988</td>\n",
       "      <td>0.311874</td>\n",
       "      <td>0.361138</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.326883</td>\n",
       "      <td>0.281419</td>\n",
       "      <td>0.391698</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.285070</td>\n",
       "      <td>0.456344</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0.298508</td>\n",
       "      <td>0.284057</td>\n",
       "      <td>0.417435</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.357053</td>\n",
       "      <td>0.283054</td>\n",
       "      <td>0.359893</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.277352</td>\n",
       "      <td>0.368103</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.336181</td>\n",
       "      <td>0.282941</td>\n",
       "      <td>0.380878</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.326088</td>\n",
       "      <td>0.303325</td>\n",
       "      <td>0.370587</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.316022</td>\n",
       "      <td>0.258554</td>\n",
       "      <td>0.425424</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.311007</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>0.412450</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.349226</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>0.340348</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.324943</td>\n",
       "      <td>0.293105</td>\n",
       "      <td>0.381952</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22037</th>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.246601</td>\n",
       "      <td>0.439846</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22042</th>\n",
       "      <td>0.295490</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.391444</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22043</th>\n",
       "      <td>0.345789</td>\n",
       "      <td>0.262920</td>\n",
       "      <td>0.391292</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>0.301463</td>\n",
       "      <td>0.281017</td>\n",
       "      <td>0.417520</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22048</th>\n",
       "      <td>0.344184</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.373193</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22049</th>\n",
       "      <td>0.326277</td>\n",
       "      <td>0.284408</td>\n",
       "      <td>0.389315</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22051</th>\n",
       "      <td>0.323909</td>\n",
       "      <td>0.255553</td>\n",
       "      <td>0.420538</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22052</th>\n",
       "      <td>0.353418</td>\n",
       "      <td>0.290315</td>\n",
       "      <td>0.356267</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22057</th>\n",
       "      <td>0.329036</td>\n",
       "      <td>0.295114</td>\n",
       "      <td>0.375850</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22058</th>\n",
       "      <td>0.355487</td>\n",
       "      <td>0.319203</td>\n",
       "      <td>0.325310</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22059</th>\n",
       "      <td>0.365530</td>\n",
       "      <td>0.302524</td>\n",
       "      <td>0.331946</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22067</th>\n",
       "      <td>0.321321</td>\n",
       "      <td>0.269949</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22069</th>\n",
       "      <td>0.324911</td>\n",
       "      <td>0.252897</td>\n",
       "      <td>0.422192</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22071</th>\n",
       "      <td>0.344263</td>\n",
       "      <td>0.267986</td>\n",
       "      <td>0.387751</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22073</th>\n",
       "      <td>0.306241</td>\n",
       "      <td>0.292925</td>\n",
       "      <td>0.400834</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22075</th>\n",
       "      <td>0.396014</td>\n",
       "      <td>0.247583</td>\n",
       "      <td>0.356403</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22078</th>\n",
       "      <td>0.338562</td>\n",
       "      <td>0.309716</td>\n",
       "      <td>0.351722</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22080</th>\n",
       "      <td>0.348683</td>\n",
       "      <td>0.297160</td>\n",
       "      <td>0.354158</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22083</th>\n",
       "      <td>0.311897</td>\n",
       "      <td>0.305786</td>\n",
       "      <td>0.382318</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22090</th>\n",
       "      <td>0.339257</td>\n",
       "      <td>0.293886</td>\n",
       "      <td>0.366857</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22091</th>\n",
       "      <td>0.334136</td>\n",
       "      <td>0.302447</td>\n",
       "      <td>0.363416</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22092</th>\n",
       "      <td>0.354957</td>\n",
       "      <td>0.303058</td>\n",
       "      <td>0.341985</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22094</th>\n",
       "      <td>0.322992</td>\n",
       "      <td>0.274499</td>\n",
       "      <td>0.402509</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22098</th>\n",
       "      <td>0.367386</td>\n",
       "      <td>0.301148</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100</th>\n",
       "      <td>0.310327</td>\n",
       "      <td>0.308492</td>\n",
       "      <td>0.381181</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22101</th>\n",
       "      <td>0.322229</td>\n",
       "      <td>0.327160</td>\n",
       "      <td>0.350610</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22102</th>\n",
       "      <td>0.308338</td>\n",
       "      <td>0.251728</td>\n",
       "      <td>0.439934</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22103</th>\n",
       "      <td>0.357088</td>\n",
       "      <td>0.271664</td>\n",
       "      <td>0.371248</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22105</th>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.293576</td>\n",
       "      <td>0.371397</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22107</th>\n",
       "      <td>0.289854</td>\n",
       "      <td>0.307960</td>\n",
       "      <td>0.402186</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7886 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        probs_A   probs_D   probs_H pred INFO_FTR   WIN\n",
       "924    0.360504  0.270994  0.368502    H        A -1.00\n",
       "927    0.343951  0.284987  0.371062    H        A -1.00\n",
       "928    0.323935  0.304490  0.371576    H        H  2.08\n",
       "929    0.280394  0.286063  0.433543    H        D -1.00\n",
       "932    0.355033  0.225053  0.419914    H        D -1.00\n",
       "935    0.300526  0.312887  0.386587    H        D -1.00\n",
       "942    0.355304  0.261278  0.383419    H        A -1.00\n",
       "944    0.348293  0.271416  0.380291    H        H  2.74\n",
       "946    0.324874  0.299562  0.375565    H        H  2.18\n",
       "948    0.349898  0.275734  0.374368    H        A -1.00\n",
       "949    0.299473  0.303722  0.396806    H        A -1.00\n",
       "950    0.329428  0.258576  0.411997    H        H  2.07\n",
       "951    0.359077  0.273831  0.367092    H        D -1.00\n",
       "953    0.315160  0.285771  0.399069    H        H  2.09\n",
       "958    0.347844  0.308913  0.343243    A        H -1.00\n",
       "959    0.366169  0.289943  0.343887    A        A  2.68\n",
       "961    0.289476  0.268316  0.442208    H        D -1.00\n",
       "962    0.290132  0.293804  0.416063    H        H  2.39\n",
       "963    0.326988  0.311874  0.361138    H        D -1.00\n",
       "964    0.326883  0.281419  0.391698    H        A -1.00\n",
       "965    0.258587  0.285070  0.456344    H        H  2.42\n",
       "966    0.298508  0.284057  0.417435    H        H  2.39\n",
       "967    0.357053  0.283054  0.359893    H        A -1.00\n",
       "970    0.354545  0.277352  0.368103    H        A -1.00\n",
       "973    0.336181  0.282941  0.380878    H        D -1.00\n",
       "975    0.326088  0.303325  0.370587    H        D -1.00\n",
       "978    0.316022  0.258554  0.425424    H        A -1.00\n",
       "979    0.311007  0.276543  0.412450    H        D -1.00\n",
       "981    0.349226  0.310426  0.340348    A        D -1.00\n",
       "982    0.324943  0.293105  0.381952    H        D -1.00\n",
       "...         ...       ...       ...  ...      ...   ...\n",
       "22037  0.313554  0.246601  0.439846    H        A -1.00\n",
       "22042  0.295490  0.313066  0.391444    H        D -1.00\n",
       "22043  0.345789  0.262920  0.391292    H        D -1.00\n",
       "22047  0.301463  0.281017  0.417520    H        A -1.00\n",
       "22048  0.344184  0.282623  0.373193    H        H  3.41\n",
       "22049  0.326277  0.284408  0.389315    H        A -1.00\n",
       "22051  0.323909  0.255553  0.420538    H        H  2.96\n",
       "22052  0.353418  0.290315  0.356267    H        D -1.00\n",
       "22057  0.329036  0.295114  0.375850    H        D -1.00\n",
       "22058  0.355487  0.319203  0.325310    A        A  2.45\n",
       "22059  0.365530  0.302524  0.331946    A        A  3.09\n",
       "22067  0.321321  0.269949  0.408730    H        A -1.00\n",
       "22069  0.324911  0.252897  0.422192    H        D -1.00\n",
       "22071  0.344263  0.267986  0.387751    H        H  2.30\n",
       "22073  0.306241  0.292925  0.400834    H        H  2.32\n",
       "22075  0.396014  0.247583  0.356403    A        H -1.00\n",
       "22078  0.338562  0.309716  0.351722    H        H  3.28\n",
       "22080  0.348683  0.297160  0.354158    H        A -1.00\n",
       "22083  0.311897  0.305786  0.382318    H        A -1.00\n",
       "22090  0.339257  0.293886  0.366857    H        H  2.07\n",
       "22091  0.334136  0.302447  0.363416    H        A -1.00\n",
       "22092  0.354957  0.303058  0.341985    A        D -1.00\n",
       "22094  0.322992  0.274499  0.402509    H        D -1.00\n",
       "22098  0.367386  0.301148  0.331465    A        H -1.00\n",
       "22100  0.310327  0.308492  0.381181    H        D -1.00\n",
       "22101  0.322229  0.327160  0.350610    H        D -1.00\n",
       "22102  0.308338  0.251728  0.439934    H        D -1.00\n",
       "22103  0.357088  0.271664  0.371248    H        H  2.53\n",
       "22105  0.335027  0.293576  0.371397    H        A -1.00\n",
       "22107  0.289854  0.307960  0.402186    H        A -1.00\n",
       "\n",
       "[7886 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['probs_A','probs_D','probs_H','pred', 'INFO_FTR', 'WIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0890354425548381"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y, X_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.40      0.18      0.25      2648\n",
      "          D       0.16      0.00      0.00      2290\n",
      "          H       0.39      0.87      0.53      2948\n",
      "\n",
      "avg / total       0.32      0.39      0.29      7886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, X_pred, target_names=['A', 'D', 'H']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 198)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_all_seasons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    37.382704\n",
       "A    33.578494\n",
       "D    29.038803\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_all_seasons.INFO_FTR.value_counts() / len(df_bet_all_seasons.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34039183362921643"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_all_seasons.WIN.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEASON 2016/2017 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on current season that is not use for train and test set\n",
    "X_pred_current_season = clf.predict(X_current_season)\n",
    "X_prob_current_season = clf.predict_proba(X_current_season)\n",
    "\n",
    "df_current_season['probs_A'] = X_prob_current_season[:,0]\n",
    "df_current_season['probs_D'] = X_prob_current_season[:,1]\n",
    "df_current_season['probs_H'] = X_prob_current_season[:,2]\n",
    "df_current_season['probs'] = df_current_season[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "\n",
    "df_current_season['pred'] = le.inverse_transform(X_pred_current_season)\n",
    "\n",
    "df_current_season['WIN'] = -1\n",
    "df_current_season.loc[df_current_season.INFO_FTR == df_current_season.pred, 'WIN'] = df_current_season['INFO_WIN']-1\n",
    "\n",
    "df_current_season['WIN_P'] = -1\n",
    "df_current_season.loc[df_current_season.INFO_FTR == df_current_season.pred, 'WIN_P'] = df_current_season['INFO_WIN_P']-1\n",
    "\n",
    "df_current_season['INFO_ODD'] = 0\n",
    "df_current_season.loc[df_current_season.pred == 'A', 'INFO_ODD_BET'] = df_current_season[odd_A]\n",
    "df_current_season.loc[df_current_season.pred == 'D', 'INFO_ODD_BET'] = df_current_season[odd_D]\n",
    "df_current_season.loc[df_current_season.pred == 'H', 'INFO_ODD_BET'] = df_current_season[odd_H]\n",
    "\n",
    "#TODO\n",
    "# test prob_less_bet <= 0.2 et si ceux que je predisais H je les mettais A en fait !\n",
    "\n",
    "df_current_season['prob_less_bet'] = 0\n",
    "df_current_season.loc[df_current_season.pred == 'A', 'prob_less_bet'] = df_current_season['probs'] - df_current_season[odd_A].apply(lambda x: 1/x)\n",
    "df_current_season.loc[df_current_season.pred == 'D', 'prob_less_bet'] = df_current_season['probs'] - df_current_season[odd_D].apply(lambda x: 1/x)\n",
    "df_current_season.loc[df_current_season.pred == 'H', 'prob_less_bet'] = df_current_season['probs'] - df_current_season[odd_H].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2963505 ,  0.27230019,  0.43134931],\n",
       "       [ 0.32663934,  0.24519409,  0.42816657],\n",
       "       [ 0.33026414,  0.25770984,  0.41202602],\n",
       "       ..., \n",
       "       [ 0.31523999,  0.24817648,  0.43658352],\n",
       "       [ 0.37812801,  0.30229161,  0.31958037],\n",
       "       [ 0.27241218,  0.27842583,  0.44916199]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prob_current_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many matches was play\n",
    "X_pred_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.51      0.35      0.41       637\n",
      "          D       0.00      0.00      0.00       516\n",
      "          H       0.53      0.88      0.66      1069\n",
      "\n",
      "avg / total       0.40      0.52      0.44      2222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score for this current season\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_current_season, X_pred_current_season, target_names=['A', 'D', 'H']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_current_season\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.probs <= 0.4].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred != 'A'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred == 'D'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.prob_less_bet <= 0].index)\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] > 2]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222, 202)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many bet I did\n",
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    48.109811\n",
       "A    28.667867\n",
       "D    23.222322\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    80.378038\n",
       "A    19.531953\n",
       "D     0.090009\n",
       "Name: pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.pred.value_counts() / len(df_bet_current_season.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0457664440804542"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y_current_season, X_prob_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3951577678753074"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.probs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7012241224122406"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7997292418772575"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.INFO_WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025535553555355486"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What I win/lost on each match\n",
    "df_bet_current_season.WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04642921550946801"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_Date</th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>probs</th>\n",
       "      <th>prob_less_bet</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23053</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.296350</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.431349</td>\n",
       "      <td>0.431349</td>\n",
       "      <td>-0.089484</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23054</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.326639</td>\n",
       "      <td>0.245194</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>-0.130493</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23055</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>0.330264</td>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.412026</td>\n",
       "      <td>0.412026</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23056</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>0.357552</td>\n",
       "      <td>0.259527</td>\n",
       "      <td>0.382921</td>\n",
       "      <td>0.382921</td>\n",
       "      <td>-0.053761</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23057</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>0.329024</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.396302</td>\n",
       "      <td>0.396302</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>0.322486</td>\n",
       "      <td>0.251356</td>\n",
       "      <td>0.426158</td>\n",
       "      <td>0.426158</td>\n",
       "      <td>-0.158637</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>0.410939</td>\n",
       "      <td>0.261978</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.410939</td>\n",
       "      <td>-0.138512</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.312383</td>\n",
       "      <td>0.303289</td>\n",
       "      <td>0.384327</td>\n",
       "      <td>0.384327</td>\n",
       "      <td>-0.449006</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0.298368</td>\n",
       "      <td>0.405806</td>\n",
       "      <td>0.405806</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.330546</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>0.380140</td>\n",
       "      <td>0.380140</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.373688</td>\n",
       "      <td>0.311734</td>\n",
       "      <td>0.314578</td>\n",
       "      <td>0.373688</td>\n",
       "      <td>-0.311244</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23064</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>0.268683</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>-0.098534</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23065</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.300829</td>\n",
       "      <td>0.275001</td>\n",
       "      <td>0.424171</td>\n",
       "      <td>0.424171</td>\n",
       "      <td>-0.369480</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23066</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.286838</td>\n",
       "      <td>0.273834</td>\n",
       "      <td>0.439329</td>\n",
       "      <td>0.439329</td>\n",
       "      <td>-0.177955</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23067</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.355286</td>\n",
       "      <td>0.289494</td>\n",
       "      <td>0.355219</td>\n",
       "      <td>0.355286</td>\n",
       "      <td>-0.077614</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23068</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.314545</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.404390</td>\n",
       "      <td>0.404390</td>\n",
       "      <td>-0.236636</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23069</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.283391</td>\n",
       "      <td>0.265760</td>\n",
       "      <td>0.450849</td>\n",
       "      <td>0.450849</td>\n",
       "      <td>-0.368823</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23070</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.307212</td>\n",
       "      <td>0.284648</td>\n",
       "      <td>0.408140</td>\n",
       "      <td>0.408140</td>\n",
       "      <td>-0.091860</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23071</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.331061</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>0.405267</td>\n",
       "      <td>0.405267</td>\n",
       "      <td>-0.212017</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23072</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.365658</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>-0.036378</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23073</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.316714</td>\n",
       "      <td>0.309515</td>\n",
       "      <td>0.373771</td>\n",
       "      <td>0.373771</td>\n",
       "      <td>-0.084945</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23074</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>0.292851</td>\n",
       "      <td>0.411294</td>\n",
       "      <td>0.411294</td>\n",
       "      <td>-0.041195</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23075</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.321095</td>\n",
       "      <td>0.291984</td>\n",
       "      <td>0.386921</td>\n",
       "      <td>0.386921</td>\n",
       "      <td>-0.307524</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23076</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.311431</td>\n",
       "      <td>0.274939</td>\n",
       "      <td>0.413629</td>\n",
       "      <td>0.413629</td>\n",
       "      <td>-0.135821</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23077</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.371292</td>\n",
       "      <td>0.286465</td>\n",
       "      <td>0.342243</td>\n",
       "      <td>0.371292</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23078</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.356772</td>\n",
       "      <td>0.262352</td>\n",
       "      <td>0.380877</td>\n",
       "      <td>0.380877</td>\n",
       "      <td>0.054079</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23079</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.318885</td>\n",
       "      <td>0.267963</td>\n",
       "      <td>0.413151</td>\n",
       "      <td>0.413151</td>\n",
       "      <td>-0.168244</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23080</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.299120</td>\n",
       "      <td>0.321749</td>\n",
       "      <td>0.379131</td>\n",
       "      <td>0.379131</td>\n",
       "      <td>-0.024095</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23081</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.365069</td>\n",
       "      <td>0.297897</td>\n",
       "      <td>0.337034</td>\n",
       "      <td>0.365069</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23082</th>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>0.318431</td>\n",
       "      <td>0.279183</td>\n",
       "      <td>0.402386</td>\n",
       "      <td>0.402386</td>\n",
       "      <td>-0.014280</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.254716</td>\n",
       "      <td>0.271659</td>\n",
       "      <td>0.473626</td>\n",
       "      <td>0.473626</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.332107</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>0.392707</td>\n",
       "      <td>0.392707</td>\n",
       "      <td>-0.172264</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.311595</td>\n",
       "      <td>0.271643</td>\n",
       "      <td>0.416762</td>\n",
       "      <td>0.416762</td>\n",
       "      <td>-0.068675</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25248</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.384278</td>\n",
       "      <td>0.282880</td>\n",
       "      <td>0.332841</td>\n",
       "      <td>0.384278</td>\n",
       "      <td>-0.396972</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25249</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.337223</td>\n",
       "      <td>0.306865</td>\n",
       "      <td>0.355912</td>\n",
       "      <td>0.355912</td>\n",
       "      <td>-0.075123</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25250</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.337924</td>\n",
       "      <td>0.315282</td>\n",
       "      <td>0.346794</td>\n",
       "      <td>0.346794</td>\n",
       "      <td>-0.150718</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25251</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.306459</td>\n",
       "      <td>0.260507</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>-0.414423</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25252</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.355424</td>\n",
       "      <td>0.259881</td>\n",
       "      <td>0.384695</td>\n",
       "      <td>0.384695</td>\n",
       "      <td>-0.112817</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25253</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.328813</td>\n",
       "      <td>0.237639</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>-0.296380</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25254</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.279729</td>\n",
       "      <td>0.288375</td>\n",
       "      <td>0.431896</td>\n",
       "      <td>0.431896</td>\n",
       "      <td>-0.123659</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25255</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.284054</td>\n",
       "      <td>0.283867</td>\n",
       "      <td>0.432079</td>\n",
       "      <td>0.432079</td>\n",
       "      <td>-0.048690</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25256</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.345540</td>\n",
       "      <td>0.297779</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>-0.143319</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25257</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.320966</td>\n",
       "      <td>0.244848</td>\n",
       "      <td>0.434186</td>\n",
       "      <td>0.434186</td>\n",
       "      <td>-0.518195</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25258</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.365064</td>\n",
       "      <td>0.274798</td>\n",
       "      <td>0.360138</td>\n",
       "      <td>0.365064</td>\n",
       "      <td>-0.199908</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25259</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.330836</td>\n",
       "      <td>0.324276</td>\n",
       "      <td>0.344888</td>\n",
       "      <td>0.344888</td>\n",
       "      <td>0.251343</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25260</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.304710</td>\n",
       "      <td>0.262371</td>\n",
       "      <td>0.432919</td>\n",
       "      <td>0.432919</td>\n",
       "      <td>0.099586</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.295506</td>\n",
       "      <td>0.286130</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>-0.414969</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25262</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.415074</td>\n",
       "      <td>0.294333</td>\n",
       "      <td>0.290593</td>\n",
       "      <td>0.415074</td>\n",
       "      <td>-0.143585</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25263</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.345896</td>\n",
       "      <td>0.294835</td>\n",
       "      <td>0.359269</td>\n",
       "      <td>0.359269</td>\n",
       "      <td>0.040797</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25264</th>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>0.356936</td>\n",
       "      <td>0.281246</td>\n",
       "      <td>0.361818</td>\n",
       "      <td>0.361818</td>\n",
       "      <td>-0.074863</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25265</th>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>0.293580</td>\n",
       "      <td>0.262470</td>\n",
       "      <td>0.443950</td>\n",
       "      <td>0.443950</td>\n",
       "      <td>-0.343452</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25266</th>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>0.337769</td>\n",
       "      <td>0.296618</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.136255</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25267</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.366740</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.356664</td>\n",
       "      <td>0.366740</td>\n",
       "      <td>-0.156820</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25268</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.360602</td>\n",
       "      <td>0.286771</td>\n",
       "      <td>0.352627</td>\n",
       "      <td>0.360602</td>\n",
       "      <td>0.040089</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25269</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.296950</td>\n",
       "      <td>0.266563</td>\n",
       "      <td>0.436487</td>\n",
       "      <td>0.436487</td>\n",
       "      <td>-0.433078</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25270</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>0.255321</td>\n",
       "      <td>0.442913</td>\n",
       "      <td>0.442913</td>\n",
       "      <td>-0.292381</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25271</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.284564</td>\n",
       "      <td>0.299018</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>0.243707</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25272</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.315240</td>\n",
       "      <td>0.248176</td>\n",
       "      <td>0.436584</td>\n",
       "      <td>0.436584</td>\n",
       "      <td>-0.515797</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25273</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.378128</td>\n",
       "      <td>0.302292</td>\n",
       "      <td>0.319580</td>\n",
       "      <td>0.378128</td>\n",
       "      <td>-0.476573</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25274</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.272412</td>\n",
       "      <td>0.278426</td>\n",
       "      <td>0.449162</td>\n",
       "      <td>0.449162</td>\n",
       "      <td>-0.168122</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       INFO_Date   probs_A   probs_D   probs_H     probs  prob_less_bet pred  \\\n",
       "23053 2016-11-01  0.296350  0.272300  0.431349  0.431349      -0.089484    H   \n",
       "23054 2016-11-01  0.326639  0.245194  0.428167  0.428167      -0.130493    H   \n",
       "23055 2016-11-04  0.330264  0.257710  0.412026  0.412026       0.013620    H   \n",
       "23056 2016-11-04  0.357552  0.259527  0.382921  0.382921      -0.053761    H   \n",
       "23057 2016-11-04  0.329024  0.274674  0.396302  0.396302       0.017514    H   \n",
       "23058 2016-11-04  0.322486  0.251356  0.426158  0.426158      -0.158637    H   \n",
       "23059 2016-11-04  0.410939  0.261978  0.327083  0.410939      -0.138512    A   \n",
       "23060 2016-11-05  0.312383  0.303289  0.384327  0.384327      -0.449006    H   \n",
       "23061 2016-11-05  0.295825  0.298368  0.405806  0.405806       0.022665    H   \n",
       "23062 2016-11-05  0.330546  0.289315  0.380140  0.380140       0.001352    H   \n",
       "23063 2016-11-05  0.373688  0.311734  0.314578  0.373688      -0.311244    A   \n",
       "23064 2016-11-05  0.360367  0.268683  0.370950  0.370950      -0.098534    H   \n",
       "23065 2016-11-05  0.300829  0.275001  0.424171  0.424171      -0.369480    H   \n",
       "23066 2016-11-05  0.286838  0.273834  0.439329  0.439329      -0.177955    H   \n",
       "23067 2016-11-05  0.355286  0.289494  0.355219  0.355286      -0.077614    A   \n",
       "23068 2016-11-05  0.314545  0.281065  0.404390  0.404390      -0.236636    H   \n",
       "23069 2016-11-05  0.283391  0.265760  0.450849  0.450849      -0.368823    H   \n",
       "23070 2016-11-05  0.307212  0.284648  0.408140  0.408140      -0.091860    H   \n",
       "23071 2016-11-05  0.331061  0.263672  0.405267  0.405267      -0.212017    H   \n",
       "23072 2016-11-05  0.371785  0.262557  0.365658  0.371785      -0.036378    A   \n",
       "23073 2016-11-05  0.316714  0.309515  0.373771  0.373771      -0.084945    H   \n",
       "23074 2016-11-05  0.295855  0.292851  0.411294  0.411294      -0.041195    H   \n",
       "23075 2016-11-05  0.321095  0.291984  0.386921  0.386921      -0.307524    H   \n",
       "23076 2016-11-05  0.311431  0.274939  0.413629  0.413629      -0.135821    H   \n",
       "23077 2016-11-05  0.371292  0.286465  0.342243  0.371292       0.055835    A   \n",
       "23078 2016-11-05  0.356772  0.262352  0.380877  0.380877       0.054079    H   \n",
       "23079 2016-11-05  0.318885  0.267963  0.413151  0.413151      -0.168244    H   \n",
       "23080 2016-11-05  0.299120  0.321749  0.379131  0.379131      -0.024095    H   \n",
       "23081 2016-11-05  0.365069  0.297897  0.337034  0.365069       0.012956    A   \n",
       "23082 2016-11-05  0.318431  0.279183  0.402386  0.402386      -0.014280    H   \n",
       "...          ...       ...       ...       ...       ...            ...  ...   \n",
       "25245 2017-05-21  0.254716  0.271659  0.473626  0.473626       0.070400    H   \n",
       "25246 2017-05-21  0.332107  0.275185  0.392707  0.392707      -0.172264    H   \n",
       "25247 2017-05-21  0.311595  0.271643  0.416762  0.416762      -0.068675    H   \n",
       "25248 2017-05-21  0.384278  0.282880  0.332841  0.384278      -0.396972    A   \n",
       "25249 2017-05-21  0.337223  0.306865  0.355912  0.355912      -0.075123    H   \n",
       "25250 2017-05-21  0.337924  0.315282  0.346794  0.346794      -0.150718    H   \n",
       "25251 2017-05-21  0.306459  0.260507  0.433034  0.433034      -0.414423    H   \n",
       "25252 2017-05-21  0.355424  0.259881  0.384695  0.384695      -0.112817    H   \n",
       "25253 2017-05-21  0.328813  0.237639  0.433547  0.433547      -0.296380    H   \n",
       "25254 2017-05-21  0.279729  0.288375  0.431896  0.431896      -0.123659    H   \n",
       "25255 2017-05-21  0.284054  0.283867  0.432079  0.432079      -0.048690    H   \n",
       "25256 2017-05-21  0.345540  0.297779  0.356681  0.356681      -0.143319    H   \n",
       "25257 2017-05-21  0.320966  0.244848  0.434186  0.434186      -0.518195    H   \n",
       "25258 2017-05-21  0.365064  0.274798  0.360138  0.365064      -0.199908    A   \n",
       "25259 2017-05-21  0.330836  0.324276  0.344888  0.344888       0.251343    H   \n",
       "25260 2017-05-21  0.304710  0.262371  0.432919  0.432919       0.099586    H   \n",
       "25261 2017-05-21  0.295506  0.286130  0.418364  0.418364      -0.414969    H   \n",
       "25262 2017-05-21  0.415074  0.294333  0.290593  0.415074      -0.143585    A   \n",
       "25263 2017-05-21  0.345896  0.294835  0.359269  0.359269       0.040797    H   \n",
       "25264 2017-05-22  0.356936  0.281246  0.361818  0.361818      -0.074863    H   \n",
       "25265 2017-05-27  0.293580  0.262470  0.443950  0.443950      -0.343452    H   \n",
       "25266 2017-05-27  0.337769  0.296618  0.365613  0.365613       0.136255    H   \n",
       "25267 2017-05-28  0.366740  0.276596  0.356664  0.366740      -0.156820    A   \n",
       "25268 2017-05-28  0.360602  0.286771  0.352627  0.360602       0.040089    A   \n",
       "25269 2017-05-28  0.296950  0.266563  0.436487  0.436487      -0.433078    H   \n",
       "25270 2017-05-28  0.301766  0.255321  0.442913  0.442913      -0.292381    H   \n",
       "25271 2017-05-28  0.284564  0.299018  0.416418  0.416418       0.243707    H   \n",
       "25272 2017-05-28  0.315240  0.248176  0.436584  0.436584      -0.515797    H   \n",
       "25273 2017-05-28  0.378128  0.302292  0.319580  0.378128      -0.476573    A   \n",
       "25274 2017-05-28  0.272412  0.278426  0.449162  0.449162      -0.168122    H   \n",
       "\n",
       "      INFO_FTR   WIN  \n",
       "23053        H  0.92  \n",
       "23054        H  0.79  \n",
       "23055        H  1.51  \n",
       "23056        A -1.00  \n",
       "23057        H  1.64  \n",
       "23058        H  0.71  \n",
       "23059        A  0.82  \n",
       "23060        D -1.00  \n",
       "23061        H  1.61  \n",
       "23062        A -1.00  \n",
       "23063        A  0.46  \n",
       "23064        A -1.00  \n",
       "23065        H  0.26  \n",
       "23066        A -1.00  \n",
       "23067        H -1.00  \n",
       "23068        H  0.56  \n",
       "23069        D -1.00  \n",
       "23070        D -1.00  \n",
       "23071        H  0.62  \n",
       "23072        A  1.45  \n",
       "23073        D -1.00  \n",
       "23074        D -1.00  \n",
       "23075        H  0.44  \n",
       "23076        A -1.00  \n",
       "23077        D -1.00  \n",
       "23078        A -1.00  \n",
       "23079        A -1.00  \n",
       "23080        A -1.00  \n",
       "23081        A  1.84  \n",
       "23082        H  1.40  \n",
       "...        ...   ...  \n",
       "25245        H  1.48  \n",
       "25246        A -1.00  \n",
       "25247        H  1.06  \n",
       "25248        A  0.28  \n",
       "25249        A -1.00  \n",
       "25250        H  1.01  \n",
       "25251        H  0.18  \n",
       "25252        A -1.00  \n",
       "25253        H  0.37  \n",
       "25254        H  0.80  \n",
       "25255        D -1.00  \n",
       "25256        H  1.00  \n",
       "25257        H  0.05  \n",
       "25258        D -1.00  \n",
       "25259        A -1.00  \n",
       "25260        A -1.00  \n",
       "25261        H  0.20  \n",
       "25262        A  0.79  \n",
       "25263        A -1.00  \n",
       "25264        H  1.29  \n",
       "25265        H  0.27  \n",
       "25266        A -1.00  \n",
       "25267        H -1.00  \n",
       "25268        H -1.00  \n",
       "25269        D -1.00  \n",
       "25270        H  0.36  \n",
       "25271        H  4.79  \n",
       "25272        H  0.05  \n",
       "25273        A  0.17  \n",
       "25274        H  0.62  \n",
       "\n",
       "[2222 rows x 9 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season[['INFO_Date', 'probs_A','probs_D','probs_H', 'probs', 'prob_less_bet', 'pred', 'INFO_FTR', 'WIN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'H_MEANS_FIVE_HF', u'H_MEANS_FIVE_HR', u'H_MEANS_FIVE_HS',\n",
       "       u'H_MEANS_FIVE_HST', u'H_MEANS_FIVE_HTAG', u'H_MEANS_FIVE_HTHG',\n",
       "       u'H_MEANS_FIVE_HTR_A', u'H_MEANS_FIVE_HTR_D', u'H_MEANS_FIVE_HTR_H',\n",
       "       u'H_MEANS_FIVE_HY', u'H_MEANS_THREE_AC', u'H_MEANS_THREE_AF',\n",
       "       u'H_MEANS_THREE_AR', u'H_MEANS_THREE_AS', u'H_MEANS_THREE_AST',\n",
       "       u'H_MEANS_THREE_AY', u'H_MEANS_THREE_FTAG', u'H_MEANS_THREE_FTHG',\n",
       "       u'H_MEANS_THREE_FTR_A', u'H_MEANS_THREE_FTR_D', u'H_MEANS_THREE_FTR_H',\n",
       "       u'H_MEANS_THREE_HC', u'H_MEANS_THREE_HF', u'H_MEANS_THREE_HR',\n",
       "       u'H_MEANS_THREE_HS', u'H_MEANS_THREE_HST', u'H_MEANS_THREE_HTAG',\n",
       "       u'H_MEANS_THREE_HTHG', u'H_MEANS_THREE_HTR_A', u'H_MEANS_THREE_HTR_D',\n",
       "       u'H_MEANS_THREE_HTR_H', u'H_MEANS_THREE_HY', u'H_STD_FIVE_AC',\n",
       "       u'H_STD_FIVE_AF', u'H_STD_FIVE_AR', u'H_STD_FIVE_AS', u'H_STD_FIVE_AST',\n",
       "       u'H_STD_FIVE_AY', u'H_STD_FIVE_FTAG', u'H_STD_FIVE_FTHG',\n",
       "       u'H_STD_FIVE_FTR_A', u'H_STD_FIVE_FTR_D', u'H_STD_FIVE_FTR_H',\n",
       "       u'H_STD_FIVE_HC', u'H_STD_FIVE_HF', u'H_STD_FIVE_HR', u'H_STD_FIVE_HS',\n",
       "       u'H_STD_FIVE_HST', u'H_STD_FIVE_HTAG', u'H_STD_FIVE_HTHG',\n",
       "       u'H_STD_FIVE_HTR_A', u'H_STD_FIVE_HTR_D', u'H_STD_FIVE_HTR_H',\n",
       "       u'H_STD_FIVE_HY', u'H_STD_THREE_AC', u'H_STD_THREE_AF',\n",
       "       u'H_STD_THREE_AR', u'H_STD_THREE_AS', u'H_STD_THREE_AST',\n",
       "       u'H_STD_THREE_AY', u'H_STD_THREE_FTAG', u'H_STD_THREE_FTHG',\n",
       "       u'H_STD_THREE_FTR_A', u'H_STD_THREE_FTR_D', u'H_STD_THREE_FTR_H',\n",
       "       u'H_STD_THREE_HC', u'H_STD_THREE_HF', u'H_STD_THREE_HR',\n",
       "       u'H_STD_THREE_HS', u'H_STD_THREE_HST', u'H_STD_THREE_HTAG',\n",
       "       u'H_STD_THREE_HTHG', u'H_STD_THREE_HTR_A', u'H_STD_THREE_HTR_D',\n",
       "       u'H_STD_THREE_HTR_H', u'H_STD_THREE_HY', u'INFO_AwayTeam',\n",
       "       u'INFO_BbAvA', u'INFO_BbAvD', u'INFO_BbAvH', u'INFO_Date', u'INFO_Div',\n",
       "       u'INFO_FTAG', u'INFO_FTHG', u'INFO_FTR', u'INFO_HTR', u'INFO_HomeTeam',\n",
       "       u'INFO_PSA', u'INFO_PSD', u'INFO_PSH', u'INFO_WIN', u'INFO_WIN_P',\n",
       "       u'probs_A', u'probs_D', u'probs_H', u'probs', u'pred', u'WIN', u'WIN_P',\n",
       "       u'INFO_ODD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_current_season.columns[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

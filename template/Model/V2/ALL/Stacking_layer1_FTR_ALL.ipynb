{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # visualization library based on matplotlib\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import sickit methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import and define deep learning model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def create_DNN_model(optimizer,nb_feature):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_feature, input_dim=nb_feature, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n",
    "def create_DNN_model_adam_all():\n",
    "    return create_DNN_model('adam',184)\n",
    "def create_DNN_model_adam_38():\n",
    "    return create_DNN_model('adam',38)\n",
    "def create_DNN_model_sgd_all():\n",
    "    return create_DNN_model('SGD',184)\n",
    "def create_DNN_model_sgd_56():\n",
    "    return create_DNN_model('SGD',56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "min_odd = 2\n",
    "max_odd = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define all different features dataset\n",
    "raw_features = [\"INFO_BbAvH\",\"INFO_BbAvA\",\"INFO_BbAvD\", \"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\",\"INFO_Div\"]\n",
    "all_features = ['A_MEANS_FIVE_AC','A_MEANS_FIVE_AF','A_MEANS_FIVE_AR','A_MEANS_FIVE_AS','A_MEANS_FIVE_AST','A_MEANS_FIVE_AY','A_MEANS_FIVE_FTAG','A_MEANS_FIVE_FTHG','A_MEANS_FIVE_FTR_A','A_MEANS_FIVE_FTR_D','A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC','A_MEANS_FIVE_HF','A_MEANS_FIVE_HR','A_MEANS_FIVE_HS','A_MEANS_FIVE_HST','A_MEANS_FIVE_HTAG','A_MEANS_FIVE_HTHG','A_MEANS_FIVE_HTR_A','A_MEANS_FIVE_HTR_D','A_MEANS_FIVE_HTR_H','A_MEANS_FIVE_HY','H_MEANS_FIVE_AC','H_MEANS_FIVE_AF','H_MEANS_FIVE_AR','H_MEANS_FIVE_AS','H_MEANS_FIVE_AST','H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG','H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_D','H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC','H_MEANS_FIVE_HF','H_MEANS_FIVE_HR','H_MEANS_FIVE_HS','H_MEANS_FIVE_HST','H_MEANS_FIVE_HTAG','H_MEANS_FIVE_HTHG','H_MEANS_FIVE_HTR_A','H_MEANS_FIVE_HTR_D','H_MEANS_FIVE_HTR_H','H_MEANS_FIVE_HY','A_MEANS_THREE_AC','A_MEANS_THREE_AF','A_MEANS_THREE_AR','A_MEANS_THREE_AS','A_MEANS_THREE_AST','A_MEANS_THREE_AY','A_MEANS_THREE_FTAG','A_MEANS_THREE_FTHG','A_MEANS_THREE_FTR_A','A_MEANS_THREE_FTR_D','A_MEANS_THREE_FTR_H','A_MEANS_THREE_HC','A_MEANS_THREE_HF','A_MEANS_THREE_HR','A_MEANS_THREE_HS','A_MEANS_THREE_HST','A_MEANS_THREE_HTAG','A_MEANS_THREE_HTHG','A_MEANS_THREE_HTR_A','A_MEANS_THREE_HTR_D','A_MEANS_THREE_HTR_H','A_MEANS_THREE_HY','H_MEANS_THREE_AC','H_MEANS_THREE_AF','H_MEANS_THREE_AR','H_MEANS_THREE_AS','H_MEANS_THREE_AST','H_MEANS_THREE_AY','H_MEANS_THREE_FTAG','H_MEANS_THREE_FTHG','H_MEANS_THREE_FTR_A','H_MEANS_THREE_FTR_D','H_MEANS_THREE_FTR_H','H_MEANS_THREE_HC','H_MEANS_THREE_HF','H_MEANS_THREE_HR','H_MEANS_THREE_HS','H_MEANS_THREE_HST','H_MEANS_THREE_HTAG','H_MEANS_THREE_HTHG','H_MEANS_THREE_HTR_A','H_MEANS_THREE_HTR_D','H_MEANS_THREE_HTR_H','H_MEANS_THREE_HY','A_STD_FIVE_AC','A_STD_FIVE_AF','A_STD_FIVE_AR','A_STD_FIVE_AS','A_STD_FIVE_AST','A_STD_FIVE_AY','A_STD_FIVE_FTAG','A_STD_FIVE_FTHG','A_STD_FIVE_FTR_A','A_STD_FIVE_FTR_D','A_STD_FIVE_FTR_H','A_STD_FIVE_HC','A_STD_FIVE_HF','A_STD_FIVE_HR','A_STD_FIVE_HS','A_STD_FIVE_HST','A_STD_FIVE_HTAG','A_STD_FIVE_HTHG','A_STD_FIVE_HTR_A','A_STD_FIVE_HTR_D','A_STD_FIVE_HTR_H','A_STD_FIVE_HY','H_STD_FIVE_AC','H_STD_FIVE_AF','H_STD_FIVE_AR','H_STD_FIVE_AS','H_STD_FIVE_AST','H_STD_FIVE_AY','H_STD_FIVE_FTAG','H_STD_FIVE_FTHG','H_STD_FIVE_FTR_A','H_STD_FIVE_FTR_D','H_STD_FIVE_FTR_H','H_STD_FIVE_HC','H_STD_FIVE_HF','H_STD_FIVE_HR','H_STD_FIVE_HS','H_STD_FIVE_HST','H_STD_FIVE_HTAG','H_STD_FIVE_HTHG','H_STD_FIVE_HTR_A','H_STD_FIVE_HTR_D','H_STD_FIVE_HTR_H','H_STD_FIVE_HY','A_STD_THREE_AC','A_STD_THREE_AF','A_STD_THREE_AR','A_STD_THREE_AS','A_STD_THREE_AST','A_STD_THREE_AY','A_STD_THREE_FTAG','A_STD_THREE_FTHG','A_STD_THREE_FTR_A','A_STD_THREE_FTR_D','A_STD_THREE_FTR_H','A_STD_THREE_HC','A_STD_THREE_HF','A_STD_THREE_HR','A_STD_THREE_HS','A_STD_THREE_HST','A_STD_THREE_HTAG','A_STD_THREE_HTHG','A_STD_THREE_HTR_A','A_STD_THREE_HTR_D','A_STD_THREE_HTR_H','A_STD_THREE_HY','H_STD_THREE_AC','H_STD_THREE_AF','H_STD_THREE_AR','H_STD_THREE_AS','H_STD_THREE_AST','H_STD_THREE_AY','H_STD_THREE_FTAG','H_STD_THREE_FTHG','H_STD_THREE_FTR_A','H_STD_THREE_FTR_D','H_STD_THREE_FTR_H','H_STD_THREE_HC','H_STD_THREE_HF','H_STD_THREE_HR','H_STD_THREE_HS','H_STD_THREE_HST','H_STD_THREE_HTAG','H_STD_THREE_HTHG','H_STD_THREE_HTR_A','H_STD_THREE_HTR_D','H_STD_THREE_HTR_H','H_STD_THREE_HY','INFO_Div_D1','INFO_Div_E0','INFO_Div_E1','INFO_Div_E2','INFO_Div_F1','INFO_Div_I1','INFO_Div_SC0','INFO_Div_SP1']\n",
    "best_features_DNN_adam_38 = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF', 'A_MEANS_FIVE_HS','A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY','H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG','H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC','H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTR_H','A_MEANS_THREE_AC', 'A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG','A_MEANS_THREE_HF', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','H_MEANS_THREE_HC', 'A_STD_FIVE_AST', 'A_STD_FIVE_HF','H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_HC', 'H_STD_FIVE_HF','H_STD_FIVE_HST']\n",
    "best_features_DNN_SGD_56 = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_A','A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF','A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTHG','A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HF','H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTAG','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_FTR_A', 'A_MEANS_THREE_HC','A_MEANS_THREE_HF', 'A_MEANS_THREE_HS', 'A_MEANS_THREE_HST','H_MEANS_THREE_AC', 'H_MEANS_THREE_AS', 'H_MEANS_THREE_FTHG','H_MEANS_THREE_HC', 'H_MEANS_THREE_HST', 'H_MEANS_THREE_HTR_H','A_STD_FIVE_AF', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC', 'A_STD_FIVE_HF','A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_AST','H_STD_FIVE_HC', 'H_STD_FIVE_HF', 'H_STD_FIVE_HST','H_STD_FIVE_HTHG', 'H_STD_THREE_AS', 'H_STD_THREE_HST']\n",
    "best_features_XGBoost_60 = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_AY', 'A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG','A_MEANS_FIVE_FTR_A', 'A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC','A_MEANS_FIVE_HF', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTHG', 'A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY','H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG','H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC','H_MEANS_FIVE_HF', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTAG', 'H_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_HTR_H','A_MEANS_THREE_AC', 'A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG','A_MEANS_THREE_FTR_A', 'A_MEANS_THREE_HC', 'A_MEANS_THREE_HF','A_MEANS_THREE_HS', 'A_MEANS_THREE_HST', 'H_MEANS_THREE_AC','H_MEANS_THREE_AS', 'H_MEANS_THREE_AST', 'H_MEANS_THREE_FTHG','H_MEANS_THREE_HC', 'H_MEANS_THREE_HST', 'H_MEANS_THREE_HTR_H','A_STD_FIVE_AF', 'A_STD_FIVE_AS', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC','A_STD_FIVE_HF', 'A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS','H_STD_FIVE_AST', 'H_STD_FIVE_HC', 'H_STD_FIVE_HF','H_STD_FIVE_HST', 'H_STD_FIVE_HTHG', 'H_STD_THREE_AS','H_STD_THREE_HST']\n",
    "best_features_SVM = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "best_features_RF = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_A','A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF','A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTHG','A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HF','H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTAG','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HC', 'A_MEANS_THREE_HF','A_MEANS_THREE_HS', 'H_MEANS_THREE_AC', 'H_MEANS_THREE_AS','H_MEANS_THREE_FTHG', 'H_MEANS_THREE_HC', 'H_MEANS_THREE_HST','A_STD_FIVE_AF', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC', 'A_STD_FIVE_HF','A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_AST','H_STD_FIVE_HC', 'H_STD_FIVE_HF', 'H_STD_FIVE_HST','H_STD_FIVE_HTHG', 'H_STD_THREE_AS', 'H_STD_THREE_HST']\n",
    "best_features_NB = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "best_features_MLP = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "best_features_LDA = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AS', 'A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_HC','A_MEANS_FIVE_HS', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS','H_MEANS_FIVE_HST']\n",
    "best_features_KNN = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS','A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','A_MEANS_THREE_AS', 'A_MEANS_THREE_HS', 'A_STD_FIVE_HF']\n",
    "best_features_ExraTree = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_A','A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF','A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTHG','A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HF','H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTAG','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_FTR_A', 'A_MEANS_THREE_HC','A_MEANS_THREE_HF', 'A_MEANS_THREE_HS', 'A_MEANS_THREE_HST','H_MEANS_THREE_AC', 'H_MEANS_THREE_AS', 'H_MEANS_THREE_FTHG','H_MEANS_THREE_HC', 'H_MEANS_THREE_HST', 'H_MEANS_THREE_HTR_H','A_STD_FIVE_AF', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC', 'A_STD_FIVE_HF','A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_AST','H_STD_FIVE_HC', 'H_STD_FIVE_HF', 'H_STD_FIVE_HST','H_STD_FIVE_HTHG', 'H_STD_THREE_AS', 'H_STD_THREE_HST']\n",
    "best_features_ElasticNEt = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC','A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTR_A','H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG','H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS','H_MEANS_FIVE_HST', 'A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG','A_MEANS_THREE_HS', 'A_STD_FIVE_HF', 'H_STD_FIVE_HST']\n",
    "best_features_bagging = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST', 'A_MEANS_FIVE_FTAG','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','A_MEANS_THREE_HS']\n",
    "best_features_AdaBoost = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS','H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC','A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS','H_MEANS_THREE_AS', 'H_MEANS_THREE_HC', 'A_STD_FIVE_AST','A_STD_FIVE_HF', 'H_STD_FIVE_AF', 'H_STD_FIVE_HC','H_STD_FIVE_HST']\n",
    "best_features_LR = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF', 'A_MEANS_FIVE_HS','A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY','H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST','H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG','H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC','H_MEANS_FIVE_HF', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTAG', 'H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC','A_MEANS_THREE_AS', 'A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HF','A_MEANS_THREE_HS', 'H_MEANS_THREE_AS', 'H_MEANS_THREE_HC','A_STD_FIVE_AST', 'A_STD_FIVE_HC', 'A_STD_FIVE_HF', 'A_STD_FIVE_HS','H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_AST', 'H_STD_FIVE_HC','H_STD_FIVE_HF', 'H_STD_FIVE_HST']\n",
    "best_features_GB = ['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD','A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_A','A_MEANS_FIVE_FTR_H', 'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HF','A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST', 'A_MEANS_FIVE_HTHG','A_MEANS_FIVE_HTR_A', 'A_MEANS_FIVE_HY', 'H_MEANS_FIVE_AC','H_MEANS_FIVE_AS', 'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY','H_MEANS_FIVE_FTAG', 'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A','H_MEANS_FIVE_FTR_H', 'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HF','H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST', 'H_MEANS_FIVE_HTAG','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HC', 'A_MEANS_THREE_HF','A_MEANS_THREE_HS', 'H_MEANS_THREE_AC', 'H_MEANS_THREE_AS','H_MEANS_THREE_FTHG', 'H_MEANS_THREE_HC', 'H_MEANS_THREE_HST','A_STD_FIVE_AF', 'A_STD_FIVE_AST', 'A_STD_FIVE_HC', 'A_STD_FIVE_HF','A_STD_FIVE_HS', 'H_STD_FIVE_AF', 'H_STD_FIVE_AS', 'H_STD_FIVE_AST','H_STD_FIVE_HC', 'H_STD_FIVE_HF', 'H_STD_FIVE_HST','H_STD_FIVE_HTHG', 'H_STD_THREE_AS', 'H_STD_THREE_HST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct layer 1\n",
    "# [Model_name, Preprocessing_needed, calibration, model_with_hyperparameter, feature_list]\n",
    "layer_1 = [\n",
    "    ['XGBoost_bf', False, 'no', XGBClassifier(learning_rate =0.01,n_estimators=207,max_depth=3,min_child_weight=3,gamma=0.4,subsample=0.65,colsample_bytree=0.85,objective= 'multi:softprob',nthread=4,scale_pos_weight=1,seed=15), best_features_XGBoost_60],\n",
    "    ['RF_bf', False, 'no', RandomForestClassifier(random_state=0, n_jobs=-1,criterion='entropy', max_depth=5, max_features='sqrt', min_samples_leaf=4, min_samples_split=23, n_estimators=620), best_features_RF],\n",
    "    ['NB', True, 'no', GaussianNB(), best_features_NB],\n",
    "    ['MLP', True, 'no', MLPClassifier(random_state=0,activation='logistic', alpha=1, hidden_layer_sizes=(100,), max_iter=200, solver= 'sgd'), best_features_MLP],\n",
    "    ['KNN', True, 'no', KNeighborsClassifier(n_jobs=-1,n_neighbors=650, p=2, weights='uniform'), best_features_KNN],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Prepare dataset\n",
    "# DB Sqlite connection\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()\n",
    "# Get all prematch data\n",
    "df = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df = (df[df.columns.drop(['index'])])\n",
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df['INFO_WIN'] = 0\n",
    "df.loc[df.INFO_FTR == 'H', 'INFO_WIN'] = df[odd_H]\n",
    "df.loc[df.INFO_FTR == 'A', 'INFO_WIN'] = df[odd_A]\n",
    "df.loc[df.INFO_FTR == 'D', 'INFO_WIN'] = df[odd_D]\n",
    "df['INFO_WIN_P'] = 0\n",
    "df.loc[df.INFO_FTR == 'H', 'INFO_WIN_P'] = df['INFO_PSH']\n",
    "df.loc[df.INFO_FTR == 'A', 'INFO_WIN_P'] = df['INFO_PSA']\n",
    "df.loc[df.INFO_FTR == 'D', 'INFO_WIN_P'] = df['INFO_PSD']\n",
    "df[[odd_H, odd_D, odd_A, 'INFO_FTR', 'INFO_WIN']].head(10)\n",
    "# Remove all game between June (include) and October (include)\n",
    "df['INFO_Date'] = pd.to_datetime(df['INFO_Date'])\n",
    "df['INFO_Date'].dt.month\n",
    "df = df[(df['INFO_Date'].dt.month < 6) | (df['INFO_Date'].dt.month > 10)]\n",
    "# Shuffle dataset\n",
    "df_all = pd.get_dummies(df.sample(frac=1))\n",
    "# Split in train and test set\n",
    "train_df, test_df = train_test_split(df, test_size = 0.3)\n",
    "train_df = train_df.reset_index()\n",
    "test_df = test_df.reset_index()\n",
    "# Remove too small and too high odd for training dataset\n",
    "train_df_range = train_df[(train_df[odd_H] > min_odd) & (train_df[odd_A] > min_odd)]\n",
    "train_df_range = train_df[(train_df[odd_H] < max_odd) & (train_df[odd_A] < max_odd)]\n",
    "# Encode string label\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[target])\n",
    "# Create X and y for train and test set\n",
    "X_train_df = pd.get_dummies(train_df[raw_features])\n",
    "X_train_df_range = pd.get_dummies(train_df_range[raw_features])\n",
    "X_test_df = pd.get_dummies(test_df[raw_features])\n",
    "y_train_df = le.transform(train_df[target])\n",
    "y_train_df_range = le.transform(train_df_range[target])\n",
    "y_test_df= le.transform(test_df[target])\n",
    "# Impute of missing values (NaN) with the mean\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp = imp.fit(X_train_df)\n",
    "X_imputed = imp.transform(X_train_df)\n",
    "X_train_df = pd.DataFrame(X_imputed, columns = X_train_df.columns)\n",
    "X_imputed = imp.transform(X_train_df_range)\n",
    "X_train_df_range = pd.DataFrame(X_imputed, columns = X_train_df_range.columns)\n",
    "X_imputed = imp.transform(X_test_df)\n",
    "X_test_df = pd.DataFrame(X_imputed, columns = X_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "ntrain = X_train_df.shape[0]\n",
    "#ntrain_range = X_train_df_range.shape[0]\n",
    "ntest = X_test_df.shape[0]\n",
    "NFOLDS = 4\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=0)\n",
    "#kf_range = KFold(ntrain_range, n_folds=NFOLDS, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, x_test, kf_param):\n",
    "    oof_train = np.zeros((x_train.shape[0],3))\n",
    "    oof_test = np.zeros((x_test.shape[0],3))\n",
    "    oof_test_skf = np.empty((NFOLDS, x_test.shape[0], 3))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf_param):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train_df[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        # Calibrate model\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: XGBoost_bf\n",
      "Processing model: RF_bf\n",
      "Processing model: NB\n",
      "Processing model: MLP\n",
      "Processing model: KNN\n",
      "Finish after 121 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compute out-of-fold predictions for layer 1 \n",
    "start = datetime.datetime.now()\n",
    "\n",
    "# Create column name of df\n",
    "cols = []\n",
    "for clf_name, preprocessing, calibration, clf, features in layer_1:\n",
    "    for result in le.classes_:\n",
    "        cols.append(clf_name+result)\n",
    "\n",
    "# Keep prediction of test in array\n",
    "X_train_layer2 = np.zeros((X_train_df.shape[0], len(layer_1)*3))\n",
    "X_train_layer2 = pd.DataFrame(X_train_layer2, columns=cols)\n",
    "\n",
    "X_test_layer2 = np.zeros((X_test_df.shape[0], len(layer_1)*3))\n",
    "X_test_layer2 = pd.DataFrame(X_test_layer2, columns=cols)\n",
    "\n",
    "for clf_name, preprocessing, calibration, classifier, features in layer_1:\n",
    "    print \"Processing model:\",clf_name\n",
    "    # Check if we need to standardize X for this model\n",
    "    if preprocessing:\n",
    "        sc_X = StandardScaler().fit(X_train_df[features])\n",
    "        X_train_model = sc_X.transform(X_train_df[features])\n",
    "        X_test_model = sc_X.transform(X_test_df[features])\n",
    "    else:\n",
    "        X_train_model = X_train_df[features].as_matrix()\n",
    "        X_test_model = X_test_df[features].as_matrix()\n",
    "    # Check if we need to recalibrate the prediction\n",
    "    if calibration == 'sigmoid':\n",
    "        clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "    elif calibration == 'isotonic':\n",
    "        clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "    elif calibration == 'no':\n",
    "        clf = classifier\n",
    "    # obtain out-of-fold predictions for this model\n",
    "    oof_train, oof_test = get_oof(clf, X_train_model, X_test_model, kf)\n",
    "    X_train_layer2.loc[:, [clf_name+result for result in le.classes_]] = oof_train\n",
    "    X_test_layer2.loc[:, [clf_name+result for result in le.classes_]] = oof_test\n",
    "X_train_layer2.to_csv('./report/'+start.strftime(\"%Y-%m-%d-%H-%M\")+'-layer1-train-pred.csv')\n",
    "X_test_layer2.to_csv('./report/'+start.strftime(\"%Y-%m-%d-%H-%M\")+'-layer1-test-pred.csv')\n",
    "\n",
    "print(\"Finish after %d seconds\" % (datetime.datetime.now() - start).total_seconds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat prediction with initial features\n",
    "#X_train_layer2_df_temp = X_train_layer2\n",
    "#X_test_layer2_df_temp = X_test_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concat prediction with initial features\n",
    "X_train_layer2_df = pd.concat([train_df, X_train_layer2, pd.DataFrame(y_train_df)], axis=1)\n",
    "X_test_layer2_df = pd.concat([test_df, X_test_layer2, pd.DataFrame(y_test_df)], axis=1)\n",
    "X_train_layer2_df.to_csv('./report/layer2-train-'+target+'-'+start.strftime(\"%Y-%m-%d-%H-%M\")+'.csv')\n",
    "X_test_layer2_df.to_csv('./report/layer2-test-'+target+'-'+start.strftime(\"%Y-%m-%d-%H-%M\")+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# # Compute out-of-fold predictions for layer 1 with H and A odd between 2 and 4\n",
    "# start = datetime.datetime.now()\n",
    "# \n",
    "# # Create column name of df\n",
    "# cols = []\n",
    "# for clf_name, preprocessing, calibration, clf, features in layer_1:\n",
    "#     for result in le.classes_:\n",
    "#         cols.append(clf_name+result)\n",
    "# \n",
    "# # Keep prediction of test in array\n",
    "# X_train_layer2 = np.zeros((X_train_df_range.shape[0], len(layer_1)*3))\n",
    "# X_train_layer2 = pd.DataFrame(X_train_layer2, columns=cols)\n",
    "# \n",
    "# X_test_layer2 = np.zeros((X_test_df.shape[0], len(layer_1)*3))\n",
    "# X_test_layer2 = pd.DataFrame(X_test_layer2, columns=cols)\n",
    "# \n",
    "# for clf_name, preprocessing, calibration, classifier, features in layer_1:\n",
    "#     print \"Processing model:\",clf_name\n",
    "#     # Check if we need to standardize X for this model\n",
    "#     if preprocessing:\n",
    "#         sc_X = StandardScaler().fit(X_train_df_range[features])\n",
    "#         X_train_model = sc_X.transform(X_train_df_range[features])\n",
    "#         X_test_model = sc_X.transform(X_test_df[features])\n",
    "#     else:\n",
    "#         X_train_model = X_train_df_range[features].as_matrix()\n",
    "#         X_test_model = X_test_df[features].as_matrix()\n",
    "#     # Check if we need to recalibrate the prediction\n",
    "#     if calibration == 'sigmoid':\n",
    "#         clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "#     elif calibration == 'isotonic':\n",
    "#         clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "#     elif calibration == 'no':\n",
    "#         clf = classifier\n",
    "#     # obtain out-of-fold predictions for this model\n",
    "#     oof_train, oof_test = get_oof(clf, X_train_model, X_test_model, kf_range)\n",
    "#     X_train_layer2.loc[:, [clf_name+result for result in le.classes_]] = oof_train\n",
    "#     X_test_layer2.loc[:, [clf_name+result for result in le.classes_]] = oof_test\n",
    "# X_train_layer2.to_csv('./report/'+start.strftime(\"%Y-%m-%d-%H-%M\")+'-layer1-train-pred.csv')\n",
    "# X_test_layer2.to_csv('./report/'+start.strftime(\"%Y-%m-%d-%H-%M\")+'-layer1-test-pred.csv')\n",
    "# \n",
    "# print(\"Finish after %d seconds\" % (datetime.datetime.now() - start).total_seconds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat prediction with initial features\n",
    "#X_train_layer2_df = pd.concat([train_df, X_train_layer2_df_temp, X_train_layer2, pd.DataFrame(y_train_df)], axis=1)\n",
    "#X_test_layer2_df = pd.concat([test_df, X_test_layer2_df_temp, X_test_layer2, pd.DataFrame(y_test_df)], axis=1)\n",
    "#X_train_layer2_df.to_csv('./report/layer2-train-'+target+'-'+start.strftime(\"%Y-%m-%d-%H-%M\")+'.csv')\n",
    "#X_test_layer2_df.to_csv('./report/layer2-test-'+target+'-'+start.strftime(\"%Y-%m-%d-%H-%M\")+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_layer2_train = X_train_layer2\n",
    "#X_layer2_test = X_test_layer2\n",
    "\n",
    "#X_layer2_train = pd.concat([X_train_df, X_train_layer2], axis=1)\n",
    "#X_layer2_test = pd.concat([X_test_df, X_test_layer2], axis=1)\n",
    "\n",
    "#X_layer2_train = pd.concat([X_train_df[best_features_NB], X_train_layer2], axis=1)\n",
    "#X_layer2_test = pd.concat([X_test_df[best_features_NB], X_test_layer2], axis=1)\n",
    "\n",
    "X_layer2_train = pd.concat([X_train_df[['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD']], X_train_layer2], axis=1)\n",
    "X_layer2_test = pd.concat([X_test_df[['INFO_BbAvH','INFO_BbAvA','INFO_BbAvD']], X_test_layer2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2 = XGBClassifier()\n",
    "#clf2 = XGBClassifier(learning_rate =0.01,n_estimators=572,max_depth=3,min_child_weight=5,gamma=0,subsample=0.9,colsample_bytree=0.9,objective= 'multi:softprob',nthread=4,scale_pos_weight=1,seed=15) \n",
    "clf2 = XGBClassifier(learning_rate =0.01,n_estimators=207,max_depth=3,min_child_weight=3,gamma=0.4,subsample=0.65,colsample_bytree=0.85,objective= 'multi:softprob',nthread=4,scale_pos_weight=1,seed=15)\n",
    "#clf2 = ExtraTreesClassifier(random_state=0,n_jobs=-1,criterion='entropy',max_depth=30,max_features=None,min_samples_leaf=1,min_samples_split=16,n_estimators=350)\n",
    "#clf2 = MLPClassifier(random_state=0,activation='logistic', alpha=1, hidden_layer_sizes=(100,), max_iter=500, solver= 'sgd')\n",
    "#clf2 = GaussianNB()\n",
    "#clf2 = LogisticRegression()\n",
    "clf2.fit(X_layer2_train, y_train_df)\n",
    "layer2_pred = clf2.predict(X_layer2_test)\n",
    "layer2_pred_probs = clf2.predict_proba(X_layer2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add all betting information back to the predic dataset\n",
    "X_test_layer2_df['pred'] = le.inverse_transform(layer2_pred)\n",
    "\n",
    "X_test_layer2_df['probs_A'] = layer2_pred_probs[:,0]\n",
    "X_test_layer2_df['probs_D'] = layer2_pred_probs[:,1]\n",
    "X_test_layer2_df['probs_H'] = layer2_pred_probs[:,2]\n",
    "X_test_layer2_df['probs'] = X_test_layer2_df[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "\n",
    "X_test_layer2_df['GOOD'] = False\n",
    "X_test_layer2_df.loc[X_test_layer2_df.INFO_FTR == X_test_layer2_df.pred, 'GOOD'] = True\n",
    "\n",
    "X_test_layer2_df['WIN'] = -1\n",
    "X_test_layer2_df.loc[X_test_layer2_df.INFO_FTR == X_test_layer2_df.pred, 'WIN'] = X_test_layer2_df['INFO_WIN']-1\n",
    "\n",
    "X_test_layer2_df['WIN_P'] = -1\n",
    "X_test_layer2_df.loc[X_test_layer2_df.INFO_FTR == X_test_layer2_df.pred, 'WIN_P'] = X_test_layer2_df['INFO_WIN_P']-1\n",
    "\n",
    "X_test_layer2_df['INFO_ODD_BET'] = 0\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'A', 'INFO_ODD_BET'] = X_test_layer2_df[odd_A]\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'D', 'INFO_ODD_BET'] = X_test_layer2_df[odd_D]\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'H', 'INFO_ODD_BET'] = X_test_layer2_df[odd_H]\n",
    "\n",
    "X_test_layer2_df['prob_less_bet'] = 0\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'A', 'prob_less_bet'] = X_test_layer2_df['probs'] - X_test_layer2_df[odd_A].apply(lambda x: 1/x)\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'D', 'prob_less_bet'] = X_test_layer2_df['probs'] - X_test_layer2_df[odd_D].apply(lambda x: 1/x)\n",
    "X_test_layer2_df.loc[X_test_layer2_df.pred == 'H', 'prob_less_bet'] = X_test_layer2_df['probs'] - X_test_layer2_df[odd_H].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98733840134827477"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test_df, layer2_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52523571824736548"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_df, layer2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.48      0.49      0.49      1585\n",
      "          D       0.25      0.00      0.00      1310\n",
      "          H       0.54      0.82      0.65      2514\n",
      "\n",
      "avg / total       0.45      0.53      0.45      5409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_df, layer2_pred, target_names=['A', 'D', 'H']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_test_season = X_test_layer2_df\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.probs <= 0.4].index)\n",
    "\n",
    "df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.pred != 'H'].index)\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.pred == 'D'].index)\n",
    "\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.prob_less_bet <= 0].index)\n",
    "#df_bet_test_season = df_bet_test_season[df_bet_test_season.prob_less_bet > -0.2]\n",
    "\n",
    "#df_bet_test_season = df_bet_test_season[df_bet_test_season['INFO_ODD_BET'] > 1.3]\n",
    "df_bet_test_season = df_bet_test_season[df_bet_test_season['INFO_ODD_BET'] < 1.9]\n",
    "\n",
    "df_bet_test_season = df_bet_test_season[(df_bet_test_season['INFO_Date'].dt.year < 2018) & (df_bet_test_season['INFO_Date'].dt.year > 2013)]\n",
    "\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[(df_bet_test_season.A_MEANS_FIVE_FTHG - df_bet_test_season.A_MEANS_FIVE_FTAG) > 0.8].index)\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[(df_bet_test_season.A_MEANS_FIVE_FTAG - df_bet_test_season.A_MEANS_FIVE_FTHG) > 0.8].index)\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.A_MEANS_FIVE_FTHG > 3].index)\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.A_MEANS_FIVE_FTAG < 1].index)\n",
    "#df_bet_test_season = df_bet_test_season.drop(df_bet_test_season[df_bet_test_season.A_MEANS_FIVE_FTAG > 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831, 219)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of games in the test set\n",
    "df_bet_test_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    66.666667\n",
       "D    19.013237\n",
       "A    14.320096\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_test_season.INFO_FTR.value_counts() / len(df_bet_test_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    100.0\n",
       "Name: pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will I bet on\n",
    "display(plt.show(), 100. * df_bet_test_season.pred.value_counts() / len(df_bet_test_season.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True     66.666667\n",
       "False    33.333333\n",
       "Name: GOOD, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How good I will be\n",
    "display(plt.show(), 100. * df_bet_test_season.GOOD.value_counts() / len(df_bet_test_season.GOOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5939700603485107"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_test_season.probs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.658194945848375"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_test_season.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015090252707581246"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What I win/lost on each match\n",
    "df_bet_test_season.WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028089480048367615"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What I win/lost on each match with pinnacle\n",
    "df_bet_test_season.dropna().WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_Date</th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>probs</th>\n",
       "      <th>prob_less_bet</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>INFO_ODD_BET</th>\n",
       "      <th>WIN</th>\n",
       "      <th>WIN_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>0.230354</td>\n",
       "      <td>0.250427</td>\n",
       "      <td>0.519218</td>\n",
       "      <td>0.519218</td>\n",
       "      <td>-0.065577</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>0.108082</td>\n",
       "      <td>0.796315</td>\n",
       "      <td>0.796315</td>\n",
       "      <td>-0.165223</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-02-22</td>\n",
       "      <td>0.158431</td>\n",
       "      <td>0.249763</td>\n",
       "      <td>0.591805</td>\n",
       "      <td>0.591805</td>\n",
       "      <td>-0.112420</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2014-02-11</td>\n",
       "      <td>0.235984</td>\n",
       "      <td>0.278648</td>\n",
       "      <td>0.485368</td>\n",
       "      <td>0.485368</td>\n",
       "      <td>-0.079604</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>0.162275</td>\n",
       "      <td>0.250612</td>\n",
       "      <td>0.587113</td>\n",
       "      <td>0.587113</td>\n",
       "      <td>-0.062237</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>0.240143</td>\n",
       "      <td>0.255462</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>-0.051160</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>0.231699</td>\n",
       "      <td>0.269124</td>\n",
       "      <td>0.499176</td>\n",
       "      <td>0.499176</td>\n",
       "      <td>-0.047272</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0.167035</td>\n",
       "      <td>0.263386</td>\n",
       "      <td>0.569579</td>\n",
       "      <td>0.569579</td>\n",
       "      <td>-0.063332</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>0.227286</td>\n",
       "      <td>0.268978</td>\n",
       "      <td>0.503736</td>\n",
       "      <td>0.503736</td>\n",
       "      <td>-0.074299</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>0.233635</td>\n",
       "      <td>0.269611</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>-0.061904</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>0.157661</td>\n",
       "      <td>0.237122</td>\n",
       "      <td>0.605217</td>\n",
       "      <td>0.605217</td>\n",
       "      <td>-0.099009</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>0.161031</td>\n",
       "      <td>0.255450</td>\n",
       "      <td>0.583519</td>\n",
       "      <td>0.583519</td>\n",
       "      <td>-0.087622</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>0.143121</td>\n",
       "      <td>0.178336</td>\n",
       "      <td>0.678544</td>\n",
       "      <td>0.678544</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.142471</td>\n",
       "      <td>0.758332</td>\n",
       "      <td>0.758332</td>\n",
       "      <td>-0.068115</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>0.107448</td>\n",
       "      <td>0.160506</td>\n",
       "      <td>0.732046</td>\n",
       "      <td>0.732046</td>\n",
       "      <td>-0.094400</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>0.236511</td>\n",
       "      <td>0.276748</td>\n",
       "      <td>0.486741</td>\n",
       "      <td>0.486741</td>\n",
       "      <td>-0.045174</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2014-02-16</td>\n",
       "      <td>0.098032</td>\n",
       "      <td>0.126135</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>-0.093733</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0.240023</td>\n",
       "      <td>0.259123</td>\n",
       "      <td>0.500854</td>\n",
       "      <td>0.500854</td>\n",
       "      <td>-0.045594</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>0.147279</td>\n",
       "      <td>0.245540</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>-0.122746</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>0.164444</td>\n",
       "      <td>0.260579</td>\n",
       "      <td>0.574977</td>\n",
       "      <td>0.574977</td>\n",
       "      <td>-0.074374</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2014-11-02</td>\n",
       "      <td>0.113677</td>\n",
       "      <td>0.150636</td>\n",
       "      <td>0.735687</td>\n",
       "      <td>0.735687</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>0.225032</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>0.511370</td>\n",
       "      <td>0.511370</td>\n",
       "      <td>-0.044186</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>0.137359</td>\n",
       "      <td>0.180785</td>\n",
       "      <td>0.681855</td>\n",
       "      <td>0.681855</td>\n",
       "      <td>-0.012589</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>0.107089</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.745991</td>\n",
       "      <td>0.745991</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2015-03-21</td>\n",
       "      <td>0.163721</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.588183</td>\n",
       "      <td>0.588183</td>\n",
       "      <td>-0.069711</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0.141691</td>\n",
       "      <td>0.758202</td>\n",
       "      <td>0.758202</td>\n",
       "      <td>-0.054806</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.137020</td>\n",
       "      <td>0.209961</td>\n",
       "      <td>0.653019</td>\n",
       "      <td>0.653019</td>\n",
       "      <td>-0.061267</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>0.204298</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>-0.077649</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>0.225996</td>\n",
       "      <td>0.275651</td>\n",
       "      <td>0.498353</td>\n",
       "      <td>0.498353</td>\n",
       "      <td>-0.060306</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>0.240601</td>\n",
       "      <td>0.276308</td>\n",
       "      <td>0.483090</td>\n",
       "      <td>0.483090</td>\n",
       "      <td>-0.066360</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.172030</td>\n",
       "      <td>0.256478</td>\n",
       "      <td>0.571492</td>\n",
       "      <td>0.571492</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>0.240045</td>\n",
       "      <td>0.258304</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>-0.030264</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0.098251</td>\n",
       "      <td>0.143567</td>\n",
       "      <td>0.758182</td>\n",
       "      <td>0.758182</td>\n",
       "      <td>-0.082154</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.103561</td>\n",
       "      <td>0.162957</td>\n",
       "      <td>0.733482</td>\n",
       "      <td>0.733482</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>0.203241</td>\n",
       "      <td>0.265805</td>\n",
       "      <td>0.530954</td>\n",
       "      <td>0.530954</td>\n",
       "      <td>-0.050441</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>0.237885</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>0.495449</td>\n",
       "      <td>0.495449</td>\n",
       "      <td>-0.045092</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>0.098252</td>\n",
       "      <td>0.118561</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>-0.109671</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>0.119204</td>\n",
       "      <td>0.112891</td>\n",
       "      <td>0.767905</td>\n",
       "      <td>0.767905</td>\n",
       "      <td>-0.193634</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.179293</td>\n",
       "      <td>0.265840</td>\n",
       "      <td>0.554868</td>\n",
       "      <td>0.554868</td>\n",
       "      <td>-0.054889</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.249456</td>\n",
       "      <td>0.588219</td>\n",
       "      <td>0.588219</td>\n",
       "      <td>-0.069676</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.103874</td>\n",
       "      <td>0.161783</td>\n",
       "      <td>0.734343</td>\n",
       "      <td>0.734343</td>\n",
       "      <td>-0.120358</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>2014-02-22</td>\n",
       "      <td>0.225957</td>\n",
       "      <td>0.249364</td>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.524679</td>\n",
       "      <td>-0.040293</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>0.182071</td>\n",
       "      <td>0.258069</td>\n",
       "      <td>0.559861</td>\n",
       "      <td>0.559861</td>\n",
       "      <td>-0.035377</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>0.198565</td>\n",
       "      <td>0.262028</td>\n",
       "      <td>0.539406</td>\n",
       "      <td>0.539406</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>2014-02-23</td>\n",
       "      <td>0.116866</td>\n",
       "      <td>0.166199</td>\n",
       "      <td>0.716935</td>\n",
       "      <td>0.716935</td>\n",
       "      <td>-0.076716</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.232853</td>\n",
       "      <td>0.262879</td>\n",
       "      <td>0.504268</td>\n",
       "      <td>0.504268</td>\n",
       "      <td>-0.048218</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>0.273494</td>\n",
       "      <td>0.248260</td>\n",
       "      <td>0.478245</td>\n",
       "      <td>0.478245</td>\n",
       "      <td>-0.053669</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>0.231526</td>\n",
       "      <td>0.243668</td>\n",
       "      <td>0.524806</td>\n",
       "      <td>0.524806</td>\n",
       "      <td>-0.092478</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.226410</td>\n",
       "      <td>0.250102</td>\n",
       "      <td>0.523488</td>\n",
       "      <td>0.523488</td>\n",
       "      <td>-0.075315</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>0.239024</td>\n",
       "      <td>0.258703</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>-0.047178</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>0.235260</td>\n",
       "      <td>0.269693</td>\n",
       "      <td>0.495046</td>\n",
       "      <td>0.495046</td>\n",
       "      <td>-0.048432</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>0.142264</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>-0.049000</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>0.162059</td>\n",
       "      <td>0.249211</td>\n",
       "      <td>0.588730</td>\n",
       "      <td>0.588730</td>\n",
       "      <td>-0.073522</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>0.246067</td>\n",
       "      <td>0.278376</td>\n",
       "      <td>0.475557</td>\n",
       "      <td>0.475557</td>\n",
       "      <td>-0.076929</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>2015-02-21</td>\n",
       "      <td>0.162734</td>\n",
       "      <td>0.248765</td>\n",
       "      <td>0.588501</td>\n",
       "      <td>0.588501</td>\n",
       "      <td>-0.060850</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>0.161319</td>\n",
       "      <td>0.258581</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>-0.086567</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>2014-12-07</td>\n",
       "      <td>0.162592</td>\n",
       "      <td>0.247376</td>\n",
       "      <td>0.590032</td>\n",
       "      <td>0.590032</td>\n",
       "      <td>-0.081109</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>0.174707</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>-0.043843</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>0.480728</td>\n",
       "      <td>0.480728</td>\n",
       "      <td>-0.065720</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>0.208097</td>\n",
       "      <td>0.255127</td>\n",
       "      <td>0.536776</td>\n",
       "      <td>0.536776</td>\n",
       "      <td>-0.096135</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INFO_Date   probs_A   probs_D   probs_H     probs  prob_less_bet pred  \\\n",
       "2    2016-03-05  0.230354  0.250427  0.519218  0.519218      -0.065577    H   \n",
       "4    2015-04-28  0.095603  0.108082  0.796315  0.796315      -0.165223    H   \n",
       "15   2014-02-22  0.158431  0.249763  0.591805  0.591805      -0.112420    H   \n",
       "33   2014-02-11  0.235984  0.278648  0.485368  0.485368      -0.079604    H   \n",
       "40   2014-02-15  0.162275  0.250612  0.587113  0.587113      -0.062237    H   \n",
       "46   2014-03-29  0.240143  0.255462  0.504395  0.504395      -0.051160    H   \n",
       "55   2014-11-23  0.231699  0.269124  0.499176  0.499176      -0.047272    H   \n",
       "58   2015-03-01  0.167035  0.263386  0.569579  0.569579      -0.063332    H   \n",
       "61   2014-03-22  0.227286  0.268978  0.503736  0.503736      -0.074299    H   \n",
       "67   2016-01-18  0.233635  0.269611  0.496755  0.496755      -0.061904    H   \n",
       "82   2016-11-27  0.157661  0.237122  0.605217  0.605217      -0.099009    H   \n",
       "87   2015-02-10  0.161031  0.255450  0.583519  0.583519      -0.087622    H   \n",
       "88   2015-04-18  0.143121  0.178336  0.678544  0.678544       0.020649    H   \n",
       "89   2016-12-18  0.099197  0.142471  0.758332  0.758332      -0.068115    H   \n",
       "90   2016-04-20  0.107448  0.160506  0.732046  0.732046      -0.094400    H   \n",
       "124  2016-01-24  0.236511  0.276748  0.486741  0.486741      -0.045174    H   \n",
       "129  2014-02-16  0.098032  0.126135  0.775833  0.775833      -0.093733    H   \n",
       "138  2015-03-01  0.240023  0.259123  0.500854  0.500854      -0.045594    H   \n",
       "145  2015-05-02  0.147279  0.245540  0.607181  0.607181      -0.122746    H   \n",
       "154  2015-02-03  0.164444  0.260579  0.574977  0.574977      -0.074374    H   \n",
       "162  2014-11-02  0.113677  0.150636  0.735687  0.735687      -0.057964    H   \n",
       "168  2014-01-18  0.225032  0.263598  0.511370  0.511370      -0.044186    H   \n",
       "169  2017-04-15  0.137359  0.180785  0.681855  0.681855      -0.012589    H   \n",
       "171  2015-05-23  0.107089  0.146919  0.745991  0.745991      -0.073681    H   \n",
       "187  2015-03-21  0.163721  0.248096  0.588183  0.588183      -0.069711    H   \n",
       "188  2016-12-14  0.100107  0.141691  0.758202  0.758202      -0.054806    H   \n",
       "196  2015-01-01  0.137020  0.209961  0.653019  0.653019      -0.061267    H   \n",
       "198  2015-01-17  0.204298  0.256068  0.539634  0.539634      -0.077649    H   \n",
       "203  2014-03-22  0.225996  0.275651  0.498353  0.498353      -0.060306    H   \n",
       "205  2016-04-23  0.240601  0.276308  0.483090  0.483090      -0.066360    H   \n",
       "...         ...       ...       ...       ...       ...            ...  ...   \n",
       "5206 2017-03-11  0.172030  0.256478  0.571492  0.571492      -0.027310    H   \n",
       "5210 2017-01-21  0.240045  0.258304  0.501651  0.501651      -0.030264    H   \n",
       "5211 2017-04-23  0.098251  0.143567  0.758182  0.758182      -0.082154    H   \n",
       "5222 2017-04-22  0.103561  0.162957  0.733482  0.733482      -0.121219    H   \n",
       "5237 2016-01-13  0.203241  0.265805  0.530954  0.530954      -0.050441    H   \n",
       "5244 2015-11-03  0.237885  0.266666  0.495449  0.495449      -0.045092    H   \n",
       "5247 2016-12-17  0.098252  0.118561  0.783186  0.783186      -0.109671    H   \n",
       "5257 2017-04-26  0.119204  0.112891  0.767905  0.767905      -0.193634    H   \n",
       "5267 2017-02-25  0.179293  0.265840  0.554868  0.554868      -0.054889    H   \n",
       "5272 2017-04-04  0.162325  0.249456  0.588219  0.588219      -0.069676    H   \n",
       "5273 2015-12-13  0.103874  0.161783  0.734343  0.734343      -0.120358    H   \n",
       "5276 2014-02-22  0.225957  0.249364  0.524679  0.524679      -0.040293    H   \n",
       "5305 2017-01-21  0.182071  0.258069  0.559861  0.559861      -0.035377    H   \n",
       "5306 2016-02-26  0.198565  0.262028  0.539406  0.539406      -0.032022    H   \n",
       "5309 2014-02-23  0.116866  0.166199  0.716935  0.716935      -0.076716    H   \n",
       "5315 2017-04-01  0.232853  0.262879  0.504268  0.504268      -0.048218    H   \n",
       "5319 2017-04-27  0.273494  0.248260  0.478245  0.478245      -0.053669    H   \n",
       "5320 2015-01-25  0.231526  0.243668  0.524806  0.524806      -0.092478    H   \n",
       "5325 2017-05-08  0.226410  0.250102  0.523488  0.523488      -0.075315    H   \n",
       "5350 2014-04-28  0.239024  0.258703  0.502273  0.502273      -0.047178    H   \n",
       "5354 2017-02-11  0.235260  0.269693  0.495046  0.495046      -0.048432    H   \n",
       "5358 2014-03-25  0.142264  0.226464  0.631272  0.631272      -0.049000    H   \n",
       "5360 2015-04-11  0.162059  0.249211  0.588730  0.588730      -0.073522    H   \n",
       "5364 2014-04-21  0.246067  0.278376  0.475557  0.475557      -0.076929    H   \n",
       "5370 2015-02-21  0.162734  0.248765  0.588501  0.588501      -0.060850    H   \n",
       "5380 2017-01-22  0.161319  0.258581  0.580100  0.580100      -0.086567    H   \n",
       "5383 2014-12-07  0.162592  0.247376  0.590032  0.590032      -0.081109    H   \n",
       "5389 2015-11-03  0.174707  0.255639  0.569654  0.569654      -0.043843    H   \n",
       "5391 2016-02-29  0.238763  0.280509  0.480728  0.480728      -0.065720    H   \n",
       "5397 2015-01-20  0.208097  0.255127  0.536776  0.536776      -0.096135    H   \n",
       "\n",
       "     INFO_FTR  INFO_ODD_BET   WIN  WIN_P  \n",
       "2           D          1.71 -1.00  -1.00  \n",
       "4           H          1.04  0.04   0.06  \n",
       "15          H          1.42  0.42   0.45  \n",
       "33          A          1.77 -1.00  -1.00  \n",
       "40          A          1.54 -1.00  -1.00  \n",
       "46          D          1.80 -1.00  -1.00  \n",
       "55          A          1.83 -1.00  -1.00  \n",
       "58          H          1.58  0.58   0.58  \n",
       "61          A          1.73 -1.00  -1.00  \n",
       "67          H          1.79  0.79   0.81  \n",
       "82          H          1.42  0.42   0.43  \n",
       "87          H          1.49  0.49   0.50  \n",
       "88          D          1.52 -1.00  -1.00  \n",
       "89          H          1.21  0.21   0.22  \n",
       "90          H          1.21  0.21   0.22  \n",
       "124         H          1.88  0.88   0.91  \n",
       "129         H          1.15  0.15   0.16  \n",
       "138         H          1.83  0.83   0.86  \n",
       "145         H          1.37  0.37   0.39  \n",
       "154         H          1.54  0.54   0.57  \n",
       "162         H          1.26  0.26   0.28  \n",
       "168         A          1.80 -1.00  -1.00  \n",
       "169         H          1.44  0.44   0.43  \n",
       "171         H          1.22  0.22   0.25  \n",
       "187         A          1.52 -1.00  -1.00  \n",
       "188         H          1.23  0.23   0.25  \n",
       "196         D          1.40 -1.00  -1.00  \n",
       "198         H          1.62  0.62   0.65  \n",
       "203         D          1.79 -1.00  -1.00  \n",
       "205         D          1.82 -1.00  -1.00  \n",
       "...       ...           ...   ...    ...  \n",
       "5206        H          1.67  0.67   0.68  \n",
       "5210        A          1.88 -1.00  -1.00  \n",
       "5211        H          1.19  0.19   0.19  \n",
       "5222        H          1.17  0.17   0.18  \n",
       "5237        H          1.72  0.72   0.75  \n",
       "5244        H          1.85  0.85   0.83  \n",
       "5247        H          1.12  0.12   0.14  \n",
       "5257        H          1.04  0.04   0.05  \n",
       "5267        H          1.64  0.64   0.68  \n",
       "5272        H          1.52  0.52   0.53  \n",
       "5273        H          1.17  0.17   0.18  \n",
       "5276        D          1.77 -1.00  -1.00  \n",
       "5305        H          1.68  0.68   0.70  \n",
       "5306        D          1.75 -1.00  -1.00  \n",
       "5309        H          1.26  0.26   0.27  \n",
       "5315        H          1.81  0.81   0.84  \n",
       "5319        D          1.88 -1.00  -1.00  \n",
       "5320        A          1.62 -1.00  -1.00  \n",
       "5325        H          1.67  0.67   0.71  \n",
       "5350        H          1.82  0.82   0.84  \n",
       "5354        H          1.84  0.84   0.85  \n",
       "5358        H          1.47  0.47   0.50  \n",
       "5360        H          1.51  0.51   0.53  \n",
       "5364        H          1.81  0.81   0.89  \n",
       "5370        A          1.54 -1.00  -1.00  \n",
       "5380        H          1.50  0.50   0.51  \n",
       "5383        A          1.49 -1.00  -1.00  \n",
       "5389        H          1.63  0.63   0.63  \n",
       "5391        H          1.83  0.83   0.84  \n",
       "5397        D          1.58 -1.00  -1.00  \n",
       "\n",
       "[831 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_test_season[['INFO_Date', 'probs_A','probs_D','probs_H', 'probs', 'prob_less_bet', 'pred', 'INFO_FTR', 'INFO_ODD_BET', 'WIN', 'WIN_P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABuoAAAaZCAYAAACqR1lYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm0V3W9//HXgcOggiJIBCjdFK8omnqVrmZZwc+bkqAy\nSKKQ4JBpTjiBWiIImmJY2gUnIgdQSQEHvBoo9tObNl1Db2EORYCKiIIynsPh/P5wdX4RglrAB+Px\nWIu1ON+9v3u/v190L/S59mdX1NbW1gYAAAAAAADYrOqVHgAAAAAAAAC2RkIdAAAAAAAAFCDUAQAA\nAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAABsofbYY49069YtRx11VN2vSy65\n5O8+3qxZs/Kd73xnI064thkzZuSKK67YZMdfn7lz5+bMM8/c7OcFAAD4R1WWHgAAAID1+/GPf5zm\nzZtvlGO99NJLWbBgwUY51vvp0qVLunTpssmOvz6vvvpq/vjHP2728wIAAPyjKmpra2tLDwEAAMC6\n9thjj/z85z9/31D38ssvZ8SIEVm8eHFqamrSr1+/9OrVK2vWrMnIkSPz29/+NsuWLUttbW2uuOKK\ntGnTJscdd1zefffd/Md//EeOPvroDB8+PA8++GCS5Jlnnqn7+frrr8+zzz6bN954I3vssUdGjRqV\nMWPG5NFHH82aNWvStm3bXHbZZWnVqtVaM91333155JFHcuONN6Zfv37p2LFjnn766SxatCj9+/fP\nokWL8otf/CIrVqzIddddlz322CP9+vXLbrvtlueffz5vv/12jjrqqJx11llJkunTp+eGG25ITU1N\nmjRpkiFDhuQzn/nMWvPtvvvuee6557JgwYJ06tQpt956a8aOHZvp06dn1apVWbFiRS666KIcdthh\nuf766zN//vwsXLgw8+fPT/PmzTN69Oi0atUqf/zjH/Od73wnb731VurVq5dvfvOb6dq1axYsWJBh\nw4bltddeS3V1db761a/mtNNO2/R/+AAAwFbBHXUAAABbsK9//eupV+//P7Vg3Lhx2WGHHXLWWWfl\n6quvTseOHfPuu++mT58+ad++fWpra/PGG2/k7rvvTr169XLTTTfl5ptvztixY3PWWWflkUceyZVX\nXplnnnlmg+edP39+HnzwwVRWVmbKlCn5wx/+kEmTJqWysjJ33313Lr300tx8880feIwpU6bkt7/9\nbY499tiMGTMmgwcPzsiRI3PHHXdk+PDhSd67I27ixIlZsWJFjj322Oyzzz5p165dLrvsstx1113Z\nZZdd8vOf/zynn356/uu//mud+f4SGW+99dbMnz8///3f/5077rgjjRs3zkMPPZQf/OAHOeyww5Ik\nv/rVrzJlypQ0adIkp512Wu6+++6cddZZGTRoUHr16pXjjz8+r732Wvr165dDDz00F1xwQU488cR0\n7tw5q1atyimnnJJ27dqla9eu/8gfKwAAQBKhDgAAYIv2fktfvvTSS/nzn/+ciy++uO61lStX5ne/\n+1369u2bHXbYIXfddVfmzp2bZ555Jtttt91HPu9+++2Xysr3/pPx8ccfz3PPPZeePXsmSdasWZMV\nK1Z84DH+Esd22WWXJMkXvvCFJEm7du3yi1/8om6/Pn36pEGDBmnQoEEOP/zwPPnkk9l1111z0EEH\n1b334IMPTvPmzfP888+vM99fa9u2bb773e/mgQceyJw5c+ruLPyLz372s2nSpEmSZK+99sqSJUuy\nePHizJ49O717906StG7dOtOnT8/y5cvzy1/+MkuWLMn3v//9JMny5csze/ZsoQ4AANgohDoAAICP\nmZqammy//faZOnVq3WtvvvlmmjZtmpkzZ2bEiBEZMGBAunTpkl133TX333//OseoqKjIXz8Jobq6\neq3t2267bd3v16xZk5NPPjl9+/ZNklRVVWXJkiUfOGfDhg3X+rlBgwbvu99fB7fa2trUq1cv7/eU\nhtra2qxevXqd+f7a//7v/+b000/PiSeemEMOOSSdOnXK5ZdfXre9cePGdb//y3fwl/NXVFTUbXvl\nlVfSsmXL1NbW5q677so222yTJHnrrbfSqFGjDX5uAACAD6veB+8CAADAluTTn/50GjVqVBfqXnvt\ntRx55JF5/vnn89RTT+XLX/5y+vbtm3322SfTp09PTU1NkqR+/fp1oat58+Z59dVXs2jRotTW1mb6\n9OnrPd/nP//5/OQnP8nSpUuTJN///vdz4YUXbrTPc//992fNmjVZsmRJHn744XTu3DkHHXRQnnrq\nqcydOzdJ8vOf/zyvvfZa9t1333XeX79+/brQ+Mtf/jJ77713BgwYkM9+9rOZMWNG3edfnyZNmqRj\nx46ZMmVKkve+z+OOOy4rV67Mfvvtlx/96EdJknfeeSfHHXdcZsyYsdE+OwAAsHVzRx0AAMDHTMOG\nDfOf//mfGTFiRG655ZasXr06Z599dg444IA0a9Ys559/frp165b69evnwAMPzKOPPpo1a9Zk//33\nz3XXXZczzjgjP/zhD/O1r30tPXv2TMuWLfOlL31pvefr3bt3FixYkGOPPTYVFRVp3bp1rrrqqo32\neVauXJlevXpl2bJl6du3bw4++OAkyWWXXZZvfetbqampSePGjTN27Ng0bdp0nffvvvvuqV+/fnr1\n6pWxY8fm0UcfTdeuXdOgQYMcfPDBWbJkSV1kXJ9rr702l19+eW6//fZUVFRkxIgRadmyZUaNGpXh\nw4enW7duqaqqypFHHpnu3btvtM8OAABs3Spq3289EQAAANgM+vXrl+OPPz6HH3546VEAAAA2O0tf\nAgAAAAAAQAHuqAMAAAAAAIAC3FEHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAVUlh5ga7F6dU3e\nfnt56TEAkiQ77ritaxKwRXFdArY0rkvAlsZ1CdjSuC7BR9OyZdP3fd0ddZtJZWX90iMA1HFNArY0\nrkvAlsZ1CdjSuC4BWxrXJdg4hDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKE\nOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKKCy9ABbi27nTS09\nAgAAAAAA8D7GDe5cegS2Uu6oAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIACPKMOAAAAAADgb1x/\n/eg8/vj0bL/9DkmSdu0+lWHDrkySLFjwer7xjQEZP35imjVrliT54x9fydVXj8iKFStSUZGcdtqZ\n+fd/P7jY/Hw8CHUAAAAAAAB/4/nnZ+Xyy0dmn332Xev1hx9+MLfeemPefHPhWq9fe+1V+epXu+fI\nI4/KH/4wO2ee+Y089NCMVFZKMazfJv+nY968eRk0aFB23XXXLF26NDfccEPdtkMOOSRPPfVUnnnm\nmZxzzjlp37593bYjjzwyffr0ydy5c3P11Vdn8eLFqa6uTocOHXL++eenSZMm6z1n586d07p161RU\nVGT58uU54ogjcsopp+S+++7LK6+8kvPPP3+d96xatSqdO3fOgAEDcvLJJ3/g55o2bVouvvjiPPLI\nI2nVqtVH/FYAAAAAAIAtVVVVVV588YVMnHhHRo26KjvvvHPOPPO8VFbWz//9v0/kmmu+n379jl3r\nPWvWrMm7776bJFm+fHkaNmxUYnQ+ZjZrxv31r3+dKVOm5Oijj15n20EHHZTRo0ev9drKlStz+umn\n54orrsi++75XrCdPnpzzzjsvN9544wbPNW7cuDRq1ChVVVXp2rVrevToscH9H3nkkXTt2jWTJ0/O\nwIEDU6/ehh/fN2nSpPTr1y/33HNPzjzzzA3uCwAAAAAAfHy8+ebC/Nu/HZjTTjsju+zyqUyceHuG\nDBmUcePuzMiR17zvewYNuihnn31a7rlnQt5++61cfvlId9PxgTZcozayQYMG5frrr8/rr7/+ofaf\nOXNmOnXqVBfpkuSYY47J22+/nblz536oY6xcuTKVlZVp3LhxkuTZZ5/N17/+9fTs2TMzZ86s22/S\npEnp2bNnOnTokCeeeCJJcuWVV2by5MlJkoULF9bFvrlz52bJkiU55ZRTMnXq1FRXV3+oWQAAAAAA\ngC1fmzZtM2rUD9Ku3b+koqIixx3XL/Pnz89rr736vvuvWrUql102JBdfPDSTJ0/LDTfcnGuuGZkF\nCz5cD2HrtVlTbqtWrXL22Wfnkksuya233rrWtqeffjr9+vWr+3n8+PGZO3du2rVrt85xdt5557z6\n6qvZZZdd1nuugQMHpqKiIq+88kq++MUvZtttt02SbLPNNrnpppvy1ltvpXfv3jn00EPz5z//OStW\nrEiHDh3Ss2fPjBs3Ll/+8pfTu3fvDBs2LMccc0ymTp1aF+p+8pOfpGfPntl+++2z33775ac//Wm6\ndu26Mb4iAAAAAABgM2vZsulaP8+ePTuzZ8+uWyGwtrY2SW1atWq21r4tWmyX5s2b5rnn/pTq6qoc\nffR7reDLX/5c/vVf/zXz5r2cvffefbN9Dj5+Nvs9l927d8/06dMzYcKEtV5/v6UvW7VqlVmzZq1z\njDlz5qRNmzYbPM9fL3156qmn5v7770+SHHDAAamoqEiLFi3StGnTLF68OJMmTcqKFSty0kknJUl+\n85vfZM6cOWnfvn1qamoyf/78TJs2LePHj09NTU0eeOCBtG3bNo899liWLFmSO+64Q6gDAAAAAICP\nqYUL313r5yVLVmT48Cvy6U93SJs2bXPffZOy227tU7/+dmvtu2jRstTUNMh227XIO++8k8ceezL7\n7LNv5s+flxdffCmf/OSn1jk2W6e/jcF/UWRx1KFDh+bYY4/NsmXLNrhfly5dMnbs2MyaNSuf+cxn\nkry3ROWOO+64wbvp/lrDhg3TokWLVFdXp169ennuueeSvLeU5fLly9O0adNMmzYtkydPTrNmzZIk\nY8aMyYQJEzJkyJD06tUr11xzTdq3b5/tt98+jz32WPbee+/84Ac/qDvHV77ylcyePTsdOnT4e74O\nAAAAAABgC7Lrru1z7rkX5KKLzs2aNWvSsuUnctllI9e7f9OmTTNy5Kh8//vXpqpqVSorK3PBBRen\nbdudN+PUfBwVCXXNmzfP4MGDc8YZZ2xwv+222y5jx47NyJEjs3jx4tTU1GSPPfbI9773vQ88x8CB\nA1OvXr3U1NSkdevW6d69ex588MGsXLky/fv3z/LlyzNs2LA8/vjj6dixY12kS5IePXrkqKOOyjnn\nnJPDDz88I0aMyJgxY5Ik99xzT3r37r3WuXr16pU777wzw4cP/zu+DQAAAAAAYEvzla90zVe+sv7V\n9J588ldr/fxv/3Zgbrnltk09Fv9kKmrfW1iVTazbeVNLjwAAAAAAALyPcYM7lx6Bf3Jb1NKXG8OM\nGTMyfvz4dV7v379/DjvssM0/EAAAAAAAAHwEH9tQ16VLl3Tp0qX0GAAAAAAAAPB3qVd6AAAAAAAA\nANgaeUbdZrRw4bulRwBI8t56yK5JwJbEdQnY0rguAVsa1yVgS+O6BB/N+p5R5446AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECo\nAwAAAAAAgAIqSw+wteh23tTSIwAAAACwmY0b3Ln0CADAFswddQAAAAAAAFCAUAcAAAAAAAAFCHUA\nAAAAAABQgGfUAQAAAMBmdO+9d2fy5HtTUZG0bbtzLrro0tSvXz+jRl2VF198Idtss026du2WXr2+\nttb7Xn11fk46qV9Gj74hHTrsVWh6AGBj2qShbt68eRk0aFB23XXXLF26NDfccEPdtkMOOSRPPfVU\nnnnmmZxzzjlp37593bYjjzwyffr0ydy5c3P11Vdn8eLFqa6uTocOHXL++eenSZMm6z1n586d07p1\n61RUVGT58uU54ogjcsopp+S+++7LK6+8kvPPP3+d96xatSqdO3fOgAEDcvLJJ2/w83Tv3j0dO3ZM\nbW1tqqqq0r1795xwwgl/5zcEAAAAwNZk9uzfZ+LEOzJ+/MQ0adIkN9xwXW6+eUyqqqqyzTbb5I47\nJmXNmjUZMuS8tG7dNocc8oUk7/3/q+HDv53Vq6sLfwIAYGPabHfU/frXv86UKVNy9NFHr7PtoIMO\nyujRo9d6beXKlTn99NNzxRVXZN99902STJ48Oeedd15uvPHGDZ5r3LhxadSoUaqqqtK1a9f06NFj\ng/s/8sgj6dq1ayZPnpyBAwemXr31rwjavn373H777UmS6urqnHHGGWnTpk06d+68wXMAAAAAQIcO\ne+auuyansrIyq1atysKFb6RNm7Z58skncu65F6Z+/fqpX79+Dj7485k5c0ZdqLv88stzxBHdcttt\n4wp/AgBgY9psz6gbNGhQrr/++rz++usfav+ZM2emU6dOdZEuSY455pi8/fbbmTt37oc6xsqVK1NZ\nWZnGjRsnSZ599tl8/etfT8+ePTNz5sy6/SZNmpSePXumQ4cOeeKJJ5IkV155ZSZPnpwkWbhw4fvG\nvgYNGqR///6ZNm3ah5oHAAAAACorK/Ozn81Mjx5d89vf/k+6du2WvfbaO488Mi2rV6/O8uXL88QT\nj2XRojeTJA88MCWrV69O9+7HFJ4cANjYNluoa9WqVc4+++xccskl62x7+umn069fv7pfNTU1mTt3\nbtq1a7fOvjvvvHNeffXVDZ5r4MCBOeGEE3L44Ydn//33z7bbbpsk2WabbTJ+/PjcdNNNGTZsWNas\nWZM//elPWbFiRTp06JCePXvmzjvvTJL07t27LtRNnTp1vXfl7bTTTnn77bc/0ncBAAAAwNbt0EO/\nlIcempGBA0/NoEFn5owzzk5FRUUGDOibiy8+P506/XsqKxvkhRdmZ8qUe3P55ZeXHhkA2AQ229KX\nSdK9e/dMnz49EyZMWOv191v6slWrVpk1a9Y6x5gzZ07atGmzwfP89dKXp556au6///4kyQEHHJCK\nioq0aNEiTZs2zeLFizNp0qSsWLEiJ510UpLkN7/5TebMmZP27dunpqYm8+fPz7Rp0zJ+/Pi88847\n65xr/vz5+eQnP/mRvgcAAAAAtg4tWzZd6+c5c+Zk4cKFOfDAA5MkJ554fEaNujKNG1fk29++OM2a\nNUuS3HTTTdl9913zxBOPZtWqFfna176WJFm06M1cccV3cuGFF6ZLly6b98MA/I2/vcYBH91mDXVJ\nMnTo0Bx77LFZtmzZBvfr0qVLxo4dm1mzZuUzn/lMkveWqNxxxx2zyy67fKhzNWzYMC1atEh1dXXq\n1auX5557Lsl7S1kuX748TZs2zbRp0zJ58uS6vwSNGTMmEyZMyJAhQ9KrV69cc801ad++fbbffvt1\nQl1VVVVuu+22fOMb3/ioXwMAAAAAW4GFC99d6+cXX5yToUMvyY9+NCHNmjXLww8/mE9/erf86Ee3\nZ9mypRk06KK89dai3HXX3Rk6dET23LNjTj31rLRs2TQLF76bXr265dJLh6VDh73WOTbA5vSX6xLw\n4awvbG/2UNe8efMMHjw4Z5xxxgb322677TJ27NiMHDkyixcvTk1NTfbYY49873vf+8BzDBw4MPXq\n1UtNTU1at26d7t2758EHH8zKlSvTv3//LF++PMOGDcvjjz+ejh071kW6JOnRo0eOOuqonHPOOTn8\n8MMzYsSIjBkzpm77Sy+9lH79+qWioiKrV69Ot27d8rnPfe7v/0IAAAAA2Grsu+/+6d9/YM4889TU\nr1+ZnXbaKVdeOSrNmjXL8OHfSb9+x6a2Nhk48NTsuWfH0uMCAJtYRW1tbW3pIbYG3c6bWnoEAAAA\nADazcYM7b5TjuHMF2NK4LsFHs8XcUbcxzJgxI+PHj1/n9f79++ewww7b/AMBAAAAAADAR/SxDHVd\nunTxsFwAAAAAAAA+1uqVHgAAAAAAAAC2RkIdAAAAAAAAFPCxXPry4+iBa4/yYE1gi+Fhv8CWxnUJ\n2NK4LgEAAJuDO+oAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAA\noQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAACqgsPcDWott5U0uPAAAAAPBPa9zgzqVHAAD4yNxR\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFeEYdAAAAAP907r337kyefG8qKpK2bXfORRddmu23\n3yGjR1+dZ5/9TZLkoIMOyRlnnJ2Kioq69z344NT87Gczc/XVo0uNDgBsRTbZHXVPPfVUunXrllWr\nViVJFixYkG7dumXBggV56KGH0rdv3/Tt2zf9+vXLiBEjUlVVlSTp3Llzjj/++Jxwwgnp0aNHbr75\n5o02009/+tMsWLBgvduvv/76TJw4cZ3X77jjjhxxxBGZNm1akmTWrFnZe++9M2vWrI02GwAAAAAb\nx+zZv8/EiXdk7Nhxuf32e7Lzzu1y881j8sgj0/LnP8/Jj398V8aPn5hnn/1NHn98RpLknXeW5Jpr\nRua6665JUlv2AwAAW41NFuoOOeSQfOELX8jIkSNTXV2dc889N4MHD87s2bNzzz33ZOzYsZkwYUJu\nu+22VFRUZMqUKXXvHTduXO64447cddddufvuu7No0aKNMtNtt92WpUuXfuT3Pfroo7nuuuvStWvX\nJMk999yb2qgnAAAgAElEQVSTAQMGZMKECRtlLgAAAAA2ng4d9sxdd01OkyZNsmrVqixc+EZ22KFZ\n1qypyYoVK1JdXZ2qqqpUV1enYcOGSZLHHvtpWrTYKWeccU7h6QGArckmXfry3HPPzXHHHZdvfvOb\n+dznPpdDDjkkJ598ci688MJsv/32SZKKiooMGTJkrSUG/mLlypWprKxM48aNU11dnSFDhmTevHmp\nqanJgAED0rVr1/zud7/L8OHDU79+/TRq1CjDhw9PixYtcvbZZ2fp0qVZsWJFzj333KxevTq///3v\nc9FFF2XChAl1fwn7W9OnT8/DDz+clStX5tJLL83vf//7/O53v8sll1yS0aNHp3nz5nn66afz0EMP\npVu3bnnrrbfSvHnzTfk1AgAAAPARVVZW5mc/m5nvfnd4GjRomJNPPi1t2rTNY4/NyNFHH5Gampp8\n9rP/ns9//tAkydFH90qSTJv2QMmxAYCtzCYNdQ0aNEifPn0ydOjQDBs2LEkyb968fOpTn0qS/M//\n/E++973vpbq6Oq1bt87o0e+t/T1w4MBUVFTklVdeyRe/+MVsu+22ufPOO9O8efOMGjUqS5cuTY8e\nPXLQQQfl0ksvzYgRI7Lnnntm+vTpueqqq3LmmWdm8eLFueWWW7Jo0aL86U9/ype+9KXsueeeGTp0\n6HojXZK0bds2w4YNy4svvpgLL7wwkydPzoMPPpihQ4dml112yaRJk3LYYYelUaNGOeKII/KTn/wk\np5566qb8GgEAAAD4AC1bNl3ntZ49u6Vnz2655557csEFZ6V79+755Cdb5tZb/zurVq3K6aefngce\nmJSBAwfWvadp08Zp2LDyfY9X2pY4E7B1c12Cf9wmDXXz5s3LLbfckgsuuCAXXHBBbrvttrRu3Trz\n5s1Lhw4dsv/+++f222/Pyy+/nKFDh9a9b9y4cWnUqFGqqqpy6qmn5v7778/LL7+cz33uc0mSJk2a\nZLfddsvcuXPzxhtvZM8990ySdOrUKddee21233339OnTJ4MGDcrq1avTr1+/Dz1zp06dkiS77757\nFi5cuM72SZMmpX79+jnppJOycuXKvP766zn55JNTr94mW0UUAAAAgA+wcOG7db+fN29uFi1alH33\n3S9Jcuih/5HLLrssDz00LeedNzhLlqxKkvyf/3NEZs6ckW7dete99913V6aqavVax9sStGzZdIub\nCdi6uS7BR7O+sL3J6lJVVVXOPffcXHzxxTnxxBPTunXr3HDDDTnhhBNy9dVX5913//+/wL/4xS/e\n9xgNGzZMixYtUl1dnd122y2/+tWvkiRLly7NH/7wh+y88875xCc+kdmzZydJfvnLX+Zf/uVf8sIL\nL2TZsmW56aabctVVV2X48OFJ3ltms7Z2ww8DnjVrVpLkhRdeSJs2bdba9sILL6SmpiYTJ07Mrbfe\nmjvvvDPt2rXL448//vd9SQAAAABsdIsWvZmhQy/O4sWLkySPPvpwPv3p3dKhw1557LGfJklWr16d\nJ5/8Wfbaa++SowIAW7lNdkfdd7/73RxwwAH54he/mCQZOnRo3XKVffr0yemnn54kWbZsWdq3b18X\n05L3lr6sV69eampq0rp163Tv3j1J8u1vfzvHHXdcVq1alW9961tp0aJFrrjiigwfPjy1tbWpX79+\nRo4cmU984hP54Q9/mIcffjhr1qzJWWedlSTZf//9c+GFF2bcuHFp1qzZ+849b9689O/fP1VVVXXL\ndf7FpEmTctRRR631Wu/evXPnnXemS5cuG+eLAwAAAOAfsu+++6d//4E588xTU79+ZXbaaadceeWo\nbLfddhk9+pr07dsz9erVz4EHdsoJJ5xYelwAYCtWUftBt5ixUXQ7b2rpEQAAAAD+aY0b3Ln0CJuU\nJeaALY3rEnw061v6cpM+o25L9a1vfStLlixZ67UmTZpkzJgxhSYCAAAAAABga7NVhrobbrih9AgA\nAAAAAABs5eqVHgAAAAAAAAC2RkIdAAAAAAAAFLBVLn1ZwgPXHuXBmsAWw8N+gS2N6xKwpXFdAgAA\nNgd31AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUUFl6gK1Ft/Omlh4BAAAAtlrjBncuPQIAAKzDHXUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBn1AEAAABbpXvvvTuTJ9+bioqkbdudc9FFl2bHHZvXbb/44gvy\n/9i79yiv6nr/468BBEwQlQF/Y1AZmCNWHk3PQSktLAuOA4kpeRlQ8HjKMC8oIGhN4CUK0sLSk4ok\nN2+JKOLSLI1fLeWcTh1pHRXLSiETRpCb3GF+f7ia4uelSOAzMo/HWqw1s797f+e9h2Ev1nrO/uzK\nyspcfPHIJMmiRS/kmmvGZtWqldlzzz1z+eVj8973vq/Q9AAA7A52yh11P//5z1NTU5MNGzYkSZYs\nWZKamposWbIkDzzwQE4//fScfvrpqa2tzVVXXZWNGzcmSXr37p0zzjgjZ555ZgYMGJCbbrpph830\nox/9KEuWLHnT1ydNmpSZM2e+bvu0adPSp0+fzJ07N7169drmtXnz5mXUqFE7bEYAAABg13jmmacz\nc+a03Hjj5Eydeme6dHlPbrrphsbXp0//QRYs+NU2x4wde3k++9nPZdq0uzJkyL9nzJgRaWho2NWj\nAwCwG9kpoa5Xr1752Mc+lquvvjqbNm3KRRddlFGjRuWZZ57JnXfemRtvvDEzZszIbbfdloqKitx7\n772Nx06ePDnTpk3L7bffnjvuuCPLli3bITPddtttWbNmzXYf9/DDD+e6665L3759d8gcAAAAQHnV\n1Yfk9ttnpV27dtmwYUPq65emQ4d9kiS//OUvMn/+4+nf/+TG/evrl+b555/PJz95QpLk6KN7Zf36\ndXn22YVF5gcAYPew05a+vOiii3Laaafli1/8Yo455pj06tUr55xzTkaMGJG99947SVJRUZHLLrss\nFRUVrzt+/fr1adWqVdq2bZtNmzblsssuy+LFi7Nly5acffbZ6du3b5566qmMGzcuLVu2TJs2bTJu\n3Lh07NgxF1xwQdasWZN169bloosuyubNm/P0009n5MiRmTFjRlq3bv2GMz/yyCN58MEHs379+lx+\n+eV5+umn89RTT2XMmDG59tprd9a3CgAAACigVatWmTfvsYwfPy577NE655zzhbz8cn2+/e0JmTjx\n+sye/cPGfZcsWZLKysq0aPGX33nu1Klz6uuX5OCDq0uMDwDAbmCnhbo99tgjAwcOTF1dXcaOHZsk\nWbx4cd773vcmSX71q1/lW9/6VjZt2pSqqqrGEDZkyJBUVFTkd7/7XY477ri8613vyvTp07Pffvtl\nwoQJWbNmTQYMGJCePXvm8ssvz1VXXZVDDjkkjzzySL7+9a/n/PPPz4oVK3LzzTdn2bJl+cMf/pCP\nf/zjOeSQQ1JXV/emkS5J3v3ud2fs2LH5zW9+kxEjRmTWrFmZM2dO6urq0rVr16xcuTK1tbWN+69Y\nsSKHHnrozvoWAgAAADtIp07t33D7ySfX5OSTa3LnnXfmkkvOT1VVVa644vIccsiBeeSRNtm4sXU6\ndWqfDh3apmXLFtu8zx57tMy++7Z70/eGHc3PGtDUuC7B27fTQt3ixYtz880359JLL82ll16a2267\nLVVVVVm8eHGqq6tz+OGHZ+rUqXnuuedSV1fXeNzkyZPTpk2bbNy4Meeee27uu+++PPfccznmmGOS\nJO3atUu3bt2yaNGiLF26NIccckiS5KijjsrEiRNz0EEHZeDAgbn44ouzefPmbcLa33LUUUclSQ46\n6KDU19e/7vUOHTpk6tSpjZ/Pmzcvc+fO/Ue+PQAAAMAuVF+/epvPFy9elGXLluWww/4pSXLssSfk\nq1/9apYvfyVXXnl1kmT58mXZunVLVq5ckyFDzk19fX2WLl3VuDLQn/70Ulq3bv+694adoVMnP2tA\n0+K6BNvnzcL2TnlG3caNG3PRRRdl9OjROeuss1JVVZXrr78+Z555Zr7xjW9k9eq//OP9z//8zzd8\nj9atW6djx47ZtGlTunXrll/84hdJkjVr1uTZZ59Nly5d0rlz5zzzzDNJkv/6r//K+973vixcuDCv\nvvpqvv/97+frX/96xo0bl+S1ZTb/1gOeFyxYkCRZuHBhDjjggLf9fQAAAACapmXLXk5d3eisWLEi\nSfLwww/mwAO75Uc/mpcpU2ZkypQZ6d9/QHr3/lRGjboinTvvnwMO6JIf//jhJMn8+Y+noqIi3bp1\nL3kaAAC8w+2UO+rGjx+fj3zkIznuuOOSJHV1dY3LVQ4cODDnnXdekuTVV19N9+7dG2Na8trSly1a\ntMiWLVtSVVWVfv36JUmuuOKKnHbaadmwYUOGDRuWjh075sorr8y4cePS0NCQli1b5uqrr07nzp3z\n3e9+Nw8++GC2bt2aL3/5y0mSww8/PCNGjMjkyZOzzz77vOHcixcvzqBBg7Jx48bG5ToBAACA3c9h\nhx2eQYOG5Pzzz03Llq1SWVmZa66Z8JbHfO1rV2f8+Cvzgx/cktat22TcuPHbPLMOAAC2V0XD37rN\njB2iZvjs0iMAAABAszV5VO/SI8DbYok5oKlxXYLt82ZLX+60Z9Q1VcOGDcvKlSu32dauXbvccMMN\nhSYCAAAAAACgOWp2oe76668vPQIAAAAAAADEQuoAAAAAAABQgFAHAAAAAAAABTS7pS9LuX9ifw/W\nBJoMD/sFmhrXJaCpcV0CAAB2BXfUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABTQqvQAzUXN8NmlRwAAAGAnmTyq\nd+kRAACAdyB31AEAAAAAAEABQh0AAAAAAAAUINQBAADADvbDH96RM888NbW1p2bUqIvzyivLs2XL\nllx33YScfvrJGTjws7n33rtfd9yLL/4xffr0zjPPPFVgagAAYFfzjDoAAADYgZ555unMnDktU6bM\nTLt27XL99dflpptuSPfuH8jixS/kttvuyNq1a/OFL5ydD3ygOj16fDBJsmHDhowbd0U2b95U+AwA\nAIBdZafeUbd48eKceuqpGTVqVIYNG7bNa7169UqSzJ8/P0cffXRqa2sb/9xxxx1JkkWLFuX8889P\nbW1tPv/5z6euri5r1qx5y6/Zu3fvnHHGGTnzzDMzYMCA3HTTTUmSe+65JxMmTHjDYzZs2JBevXrl\n5ptv/rvO56/NnDkzkyZNesvjAAAAaD6qqw/J7bfPSrt27bJhw4bU1y9Nhw77ZN68R9O3b7+0atUq\ne++9d44//oQ8/PCDjcd961vj06dPTTp02Kfg9AAAwK60y5a+/O///u/ce++9b/haz549M3Xq1MY/\nAwcOzPr163PeeeflnHPOydSpU3P77bfnsMMOy/Dhw//m15o8eXKmTZuW22+/PXfccUeWLVv2lvs/\n9NBD6du3b2bNmpWtW7f+Q+cHAAAAf9aqVavMm/dYBgzomyef/FX69q3J0qVL0rnz/o37dO68f5Yu\nXZokuf/+e7N58+b063dSqZEBAIACdlmou/jiizNp0qS89NJLf9f+jz32WI466qgcdthhjdtOOumk\nvPLKK1m0aNHf9R7r169Pq1at0rZt2yTJ//zP/2Tw4ME5+eST89hjjzXud9ddd+Xkk09OdXV1fvrT\nnyZJrrnmmsyaNStJUl9fnwEDBvxdXxMAAACS5NhjP54HHvhxhgw5NxdffH62bm143T4tWrTIwoXP\n5N57f5hLLx1dYEoAAKCkXfaMuv333z8XXHBBxowZk1tuuWWb15544onU1tY2fj5lypQsWrQo73nP\ne173Pl26dMmLL76Yrl27vunXGjJkSCoqKvK73/0uxx13XN71rnclSfbcc898//vfz/Lly3PKKafk\n2GOPzQsvvJB169aluro6J598ciZPnpxPfOITOeWUUzJ27NicdNJJmT17dmOo++1vf7vNrEuXLs2J\nJ574tr43AAAAvLN16tS+8ePnn38+9fX1OfLII5MkZ511RiZMuCZHHnlkNm9+tXHftWtX5r3v7ZKf\n/vThbNiwLsOGnZMkWbbs5Vx55VcyYsSIHH/88bv+ZIAm66+vNQBNgesSvH27LNQlSb9+/fLII49k\nxowZ22zv2bNnrr322m227b///lmwYMHr3uP555/PAQcc8JZfZ/LkyWnTpk02btyYc889N/fdd1+S\n5CMf+UgqKirSsWPHtG/fPitWrMhdd92VdevWZejQoUmSX/7yl3n++efTvXv3bNmyJX/84x8zd+7c\nTJkyJatWrUr37t0zderUxq81c+bMvPzyy//Q9wMAAIDdQ3396saPf/Ob51NXNya33joj++yzTx58\ncE4OPLBbjjnm2MyYcUc++MEjs27dutx33/255JLLcvjhH8m553658fjPfa4ml18+NtXVPbZ5X6B5\n69SpvWsC0KS4LsH2ebOwvUtDXZLU1dXl1FNPzauvvvqW+x1//PG58cYbs2DBgnz4wx9O8toSlfvu\nu+9b3k3311q3bp2OHTtm06ZNadGiRX79618neW0py7Vr16Z9+/aZO3duZs2alX32ee1h3TfccENm\nzJiRyy67LJ/73OfyzW9+M927d8/ee++dVatWvY0zBwAAoDk47LDDM2jQkJx//rlp2bJVKisrc801\nE9K58/754x//mLPOOj2bN29Kv34DcvjhHyk9LgAAUNAuD3X77bdfRo0alS996Utvud9ee+2VG2+8\nMVdffXVWrFiRLVu25OCDD863vvWtv/k1hgwZkhYtWmTLli2pqqpKv379MmfOnKxfvz6DBg3K2rVr\nM3bs2Dz66KM59NBDGyNdkgwYMCD9+/fPhRdemM985jO56qqrcsMNN7zt8wYAAKD5OOmkz+Wkkz73\nuu0XXDD8bx57993374yRAACAJqiioaHh9U+zZoerGT679AgAAADsJJNH9S49ArCbs8Qc0NS4LsH2\naTJLX+4IP/7xjzNlypTXbR80aFA+9alP7fqBAAAAAAAAYDu9I0Pd8ccfn+OPP770GAAAAAAAAPAP\na1F6AAAAAAAAAGiOhDoAAAAAAAAo4B259OU70f0T+3uwJtBkeNgv0NS4LgFNjesSAACwK7ijDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoAChDgAA\nAAAAAApoVXqA5qJm+OzSIwAAwG5v8qjepUcAAACAv5s76gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAA\nAACgAM+oAwAAdlsPPTQ3M2ZMTUVFRdq2bZsLL7wk1dU9cuKJn0xlZefG/U4/vTYnnNAnixa9kGuu\nGZtVq1Zmzz33zOWXj8173/u+cicAAADAbk2oAwAAdksvvPCHfO97384tt0xPZWVlHn/8Zxk9+tJc\nd913067d3pkyZcbrjhk79vKccsrpOeGEz+Txx3+eMWNGZOrUO1JRUVHgDAAAANjd7fZLX86fPz8H\nH3xwHnjggW2219TUZNSoUendu3c2bNiwzWv33HNPPv7xj6e2tja1tbUZOHBg5s6dmySpra3Nc889\n17jvhg0b0rt3751/IgAAwHbZY4/WGTnyilRWViZJqqt7ZPnyZfnlL/87LVu2yPnn/3sGD/58br31\npmzZsiX19Uvz/PPP55OfPCFJcvTRvbJ+/bo8++zCkqcBAADAbqxZ3FH3/ve/Pw888ED+9V//NUmy\ncOHCrFu37i2POfHEE3PJJZckSVasWJF+/fqlT58+O31WAABgx6iqOiBVVQckSRoaGjJp0rX56EeP\nTYsWLXLUUf+S8867IBs2bMiIERdkr732So8eH0plZWVatPjL7zN26tQ59fVLcvDB1aVOAwAAgN1Y\nswh11dXV+f3vf5/Vq1enffv2ue+++1JTU5M//elPf9fxq1evTtu2bS13AwAA70Dr1q3LVVfVZenS\nJZk4cVLat2/f+Frr1q0zcOAZufvuO3LIIYe+4fEtWrTcVaMCAADQzDSLUJckJ5xwQh5++OEMGDAg\nCxYsyL/927+9ZaibM2dOnnzyyVRUVGTPPffMN77xjcbXRo4cmT333DNJsnXr1p0+OwAA8Pfp1Kn9\nNp+/+OKLGTbsC+nWrVtmzpyetm3b5t577011dXWqq1+7S659+7bZc8826dGje155ZXkqK9s1/pLe\n8uUv5+CDD3zd+9I8+HsHmhrXJaCpcV2Ct6/ZhLqamprU1dWla9euOfLII//m/n+99OX/b/z48enW\nrVuS155RZ0lMAABoGurrVzd+vGrVygwdWps+fU7MkCHnZvXqTVm9elOefPJ/M2fO3Fx55TeyefOm\n3HrrD3LCCX3SsuVeqap6d26//Yf55Cc/nfnzH09DQ7LvvlXbvC/NQ6dO7f29A02K6xLQ1LguwfZ5\ns7DdbEJd165ds3bt2kydOjUXX3xxFi1aVHokAABgJ5o16+4sWfJS5s17LPPmPda4/ZvfvC433XRD\nBg/+fDZv3pxPfOKTqan5bJLka1+7OuPHX5kf/OCWtG7dJuPGjd/mmXUAAACwIzWbUJckffv2zezZ\ns38WYkUAACAASURBVHPggQduE+pOO+20xo9ramrSoUOHEuMBAAA70ODBQzN48NA3fG306K++4fau\nXd+T66///s4cCwAAABpVNDQ0NJQeojmoGT679AgAALDbmzyqd+kR2E1YygloalyXgKbGdQm2z5st\nfWkNFwAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAlqVHqC5uH9ifw/WBJoMD/sF\nmhrXJQAAAKA5ckcdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU\nINQBAAAAAABAAUIdAAAAAAAAFNCq9ADNRc3w2aVHAACAJmHyqN6lRwAAAIAmwR11AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAZ9QBAABFPfTQ3MyYMTUVFRVp27ZtLrzwklRX92h8ffToS1NZWZmL\nLx6ZJHn66f/Nd74zMevWrc/WrVtyxhmD8+lP9y01PgAAAPzDhDoAAKCYF174Q773vW/nllump7Ky\nMo8//rOMHn1p7rnngSTJ9Ok/yIIFv0rv3p9KkjQ0NGTMmBG57LKv5Kij/iVLly7JkCFnpkePD6Zr\n1/eUPBUAAADYbs021M2fPz/nnXde5syZk6qqqiTJhAkT8v73vz9f+cpXcvjhh6ehoSFr167N4MGD\n079//9xzzz35zne+k65du2br1q2pqKjIl770pRx99NGFzwYAAN6Z9tijdUaOvCKVlZVJkurqHlm+\nfFk2bdqUX//6ycyf/3j69z85q1evSpJs3LgxQ4b8W4466l+SJJ0775999tkn9fVLhToAAADecZpt\nqEuS1q1b57LLLsutt96aioqKxu0dOnTI1KlTkySrV6/Opz/96fTr1y9JcuKJJ+aSSy5Jkrz88ss5\n44wzMm3atHTq1GnXnwAAALzDVVUdkKqqA5K8drfcpEnX5qMfPTYrV67It789IRMnXp/Zs3/YuH+b\nNm1y4omfbfx89ux7snbt2hx66Ad3+ewAAADwdrUoPUBJPXv2TIcOHTJ9+vQ33WfNmjXZe++9twl5\nf1ZZWZlPf/rTeeyxx3bilAAAsPtbt25drrhiVBYvXpThwy/LV786Ol/+8vDGO+3eyNSpUzJ58n9k\n/Phr06ZN2104LQAAAOwYzfqOuiSpq6vLKaecko997GON21auXJna2tps3bo1zz77bGpra9/0+I4d\nO+aVV17ZFaMCAMBuoVOn9tt8/uKLL2bYsC+kW7dumTlzep5++uksWfKn3HDDt5O8tpLFli1b0qJF\nQ6666qps3Lgxo0aNym9/+9vceeed6dKlS4nToBn4/39WAUpzXQKaGtclePuafajbd999M3r06Iwc\nOTJHHHFEkm2XvlyzZk0+//nP55hjjnnD41988cX06NFjl80LAADvdPX1qxs/XrVqZYYOrU2fPidm\nyJBzs3r1pnTp0j133z2ncZ9bbvmPrFy5IhdeODL19aszcuRF2bp1a66//ua0abPnNu8HO0qnTu39\nbAFNiusS0NS4LsH2ebOw3ayXvvyz3r1758ADD8ysWbNe99pee+2V9u3bZ9OmTa97benSpfnxj3+c\n4447bleMCQAAu51Zs+7OkiUvZd68x3LWWac3/lm5csUb7r9gwf/k5z//v1m8eFG++MWhjfvPn//4\nLp4cAAAA3r5mf0fdn40ZMyZPPPFEkr8sfZkkGzduzIc+9KH07Nkzs2bNypw5c/Lkk0+mRYsWaWho\nyDXXXJN99tmn5OgAAPCONXjw0AwePPQt9xk69N8bP/7wh/8pP/vZL3b2WAAAALBLVDQ0NDSUHqI5\nqBk+u/QIAADQJEwe1bv0CPA3WcoJaGpcl4CmxnUJto+lLwEAAAAAAKAJEeoAAAAAAACgAKEOAAAA\nAAAACmhVeoDm4v6J/a3XCzQZ1hAHmhrXJQAAAKA5ckcdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAA\nABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAGtSg/QXNQM\nn116BAAAmpjJo3qXHgEAAAAoyB11AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAZ9QBAEAT8dBD\nczNjxtRUVFSkbdu2ufDCS3Lgge/PxInj88wzT2Xr1ob06HFohg8fmTZt2jYeN2fO7Myb91i+8Y1r\nC04PAAAAbK/dItTNnz8/F154Ybp3754kefXVV9OlS5dMmDAhRxxxRA4//PDGfbt165a6uro3fJ9J\nkyalsrIyp5122jbbp02blunTp+f8889P3759s2DBgpx++umZMWNGPvzhD++08wIAoPl44YU/5Hvf\n+3ZuuWV6Kisr8/jjP8vo0ZfmM5/512zZsiVTpsxMQ0NDxo69IlOnTsk553whq1atzH/8x3fz0ENz\nc8QRR5Y+BQAAAGA77RahLkl69uyZa6/9y28QDx8+PD/5yU/SoUOHTJ069W2998MPP5zrrrsuBx98\ncJLkzjvvzNlnny3UAQCww+yxR+uMHHlFKisrkyTV1T2yfPmy/NM/HZH/83+q0qLFa6vWf+ADB+f3\nv/9dkuQnP/lROnaszJe+dGEef/xnxWYHAAAA/jG7Taj7axs3bszSpUvToUOH7T72kUceyYMPPpj1\n69fn8ssvz9NPP52nnnoqY8aMybXXXpv99tsvTzzxRB544IHU1NRk+fLl2W+//XbCWQAA0JxUVR2Q\nqqoDkiQNDQ2ZNOnafPSjx+af/7ln4z4vvfSn3HnnzIwYMSZJ8tnPfi5JMnfu/bt+YAAAAOBt221C\n3RNPPJHa2tosW7YsLVq0yKmnnpqjjz46K1euTG1tbeN+I0eOzAc/+ME3fZ93v/vdGTt2bH7zm99k\nxIgRmTVrVubMmZO6urp07do1d911Vz71qU+lTZs26dOnT+6+++6ce+65u+IUAQBoBtatW5errqrL\n0qVLMnHipMbtzzzzdEaPviQnn3xqevX6WMEJAQAAgB1ltwl1f1768pVXXsmQIUPSpUuXJNnupS+P\nOuqoJMlBBx2U+vr6171+1113pWXLlhk6dGjWr1+fl156Keecc07jUkQAAPD36tSp/Tafv/jiixk2\n7Avp1q1bZs6cnrZt2yZJHnjggXzta1/LFVdckZqamte9T/v2bdO6davXvR/w9vg3BTQ1rktAU+O6\nBG/fbhPq/mzffffNN7/5zQwaNCj33nvvdh+/YMGC1NTUZOHChTnggAO2eW3hwoXZsmVL7rzzzsZt\nZ599dh599NEcf/zxb3t2AACal/r61Y0fr1q1MkOH1qZPnxMzZMi5Wb16U1av3pRHH30kEyeOz8SJ\nk1Jd3WObY/5s9er12bhx8xu+BvxjOnVq798U0KS4LgFNjesSbJ83C9u7XahLku7du6e2tjZXXnnl\ndh+7ePHiDBo0KBs3bszYsWO3ee2uu+5K//79t9l2yimnZPr06UIdAABvy6xZd2fJkpcyb95jmTfv\nscbt69evS9KQr3/9L/+3/dCHDsvw4SN3/ZAAAADADlXR0NDQUHqI5qBm+OzSIwAA0MRMHtW79AjA\nm/Ab4kBT47oENDWuS7B9mtUddX/LsGHDsnLlym22tWvXLjfccEOhiQAAAAAAAGhummWou/7660uP\nAAAAAAAAQDPXovQAAAAAAAAA0BwJdQAAAAAAAFBAs1z6soT7J/b3YE2gyfCwX6CpcV0CAAAAmiN3\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAf+PvXuP9rqu8z3++gFyURSJ\nm1w6msB4iWkddDBETcNjJ3FQM0VpsVlKjcscMPECKNZsSbyFYAPlHJeQCjiiJXltYWDkspDM00ST\nSkzmKI4CoYKCsLns80enXYyBm2Tz2e79ePz129/f9/vz/dtr+Vms9dzfzxcAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAA\nAIAChDoAAAAAAAAoQKgDAAAAAACAAlqVHqC5GHr5g6VHAAD4UJg1YXDpEQAAAAD2CnfUAQAAAAAA\nQAFCHQAAAAAAABQg1AEAAAAAAEABnlEHAECjtmDBY7nnntmpVCpp27ZtLr30ivTte1imT5+Wn/1s\nSbZt25bhw0fkzDPP3uG6Rx55ME8+uTg33zyt0OQAAAAAu9YkQt3SpUtz6aWXpk+fPkmSDRs2pFev\nXpkyZUqOOuqo9O/fv+7c3r17p7q6+i9+zvTp09O5c+cMHz58h+Nz5szJ3LlzM2bMmIwbN67u8zZt\n2pTjjz8+l1xySSqVSsN8OQCAZuzll1/Kt7/9zcycOTedO3fOkiVP5eqrr8yIEedn5cqXc/fd87Jx\n48ZcdNEF+Zu/OTxHHtkv69evy//5P9/KggWP5aij/q70VwAAAADYqSYR6pJk4MCBmTbtT38tffnl\nl+eJJ55Ihw4dMnv27A/02Y8//nhuvfXWHHbYYZk8eXLd59XW1uaf/umfMmfOnFRVVX2g/wYAAO+1\nzz6tM378V9O5c+ckyeGHH5k33libH/1oYT73uXPSqlWrHHDAATn55M/k8cd/kCOP7JcnnvhhOnXq\nnH/8x0uzZMlThb8BAAAAwM41yWfU1dTUZPXq1enQocNuX7tw4cKMHDkyw4YNy7JlyzJv3rw899xz\nmThxYl555ZUdzq1UKrngggvy2GOP7anRAQD4M92798igQccn+cMfSU2fPi3HH/+prF37+3Tt2q3u\nvK5du2X16tVJkjPPPDujRl2YNm3aFJkZAAAAoL6azB11Tz/9dKqqqrJ27dq0aNEiw4YNy7HHHpt1\n69btcLfb+PHj069fv51+Ts+ePTNp0qSsWLEi48aNy/z58/PII4+kuro6H/3oR99zfufOnfPmm282\nyHcCAGiOunTZ/z3HNm7cmAkTJmTVqtdzxx135JxzzknHjvvWnbv//m3Trl3rHa7df/+2ad261V/8\nPID6sH4AjY11CWhsrEvwwTWZUPfHrS/ffPPNjBo1Kr169UqS3d76csCAAUmSvn37Zs2aNe97/quv\nvpqDDjrorxsaAID3WLPm7R1+fv311zN+/NgccsghmTr1W9m8uZJOnbrmP/7j5fTs2TtJ8uKLL6dD\nh4/scO3bb29KTc3W93weQH106bK/9QNoVKxLQGNjXYLds7Ow3eS2vuzYsWO+8Y1v5Jprrqnb/mh3\nLFu2LEmyfPny9OjRY5fnbt++PbNmzcppp532V80KAMCurV+/LmPGXJgTT/x0rr32hrRp0zZJcsIJ\nn8qjjz6UrVu35u23386iRY/nhBNOKjssAAAAwG5qMnfU/bk+ffqkqqoq11133W5fu3LlyowcOTI1\nNTWZNGnSe97/41aalUolW7duzaBBg3L22WfvibEBAPhv5s//blatej1PPrk4Tz65uO741KnT8+qr\nr+b887+QrVu35PTTz0r//keXGxQAAADgr1Cpra2tLT1EczD08gdLjwAA8KEwa8Lg0iMA2MoJaHSs\nS0BjY12C3bOzrS+b5B1172f06NFZt27dDsfat2+f2267rdBEAAAAAAAANDfNMtTNmDGj9AgAAAAA\nAAA0cy1KDwAAAAAAAADNkVAHAAAAAAAABTTLrS9LePiWMzxYE2g0POwXaGysSwAAAEBz5I46AAAA\nAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAA\nAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAoQ6AAAA\nAAAAKECoAwAAAAAAgALqFeqWLVuW73znO6mpqcmoUaMycODALFiwoKFnAwAAAAAAgCarXqHuuuuu\nS79+/bJgwYK0bds28+fPz+23397QswEAAAAAAECTVa9Qt3379gwYMCCLFy/OZz7zmXTv3j3btm1r\n6NkAAAAAAACgyapXqGvXrl1mzZqVp59+Op/+9Kdz1113Zb/99mvo2QAAAAAAAKDJqleomzJlSjZu\n3JgZM2akQ4cOWb16dW655ZaGng0AAAAAAACarHqFum7dumXgwIF54YUXUlNTk5NOOikHHXRQQ88G\nAAAAAAAATVa9Qt1dd92Vb37zm7nzzjuzYcOGfO1rX8vMmTMbejYAAAAAAABosuoV6ubPn5+ZM2em\nXbt26dixY7773e/me9/7XkPPBgAAAAAAAE1WvUJdixYt0rp167qf27Rpk5YtWzbYUAAAAAAAANDU\ntarPScccc0xuuummvPvuu1m4cGHmzZuXgQMHNvRsAAAAAAAA0GTV6466cePG5eCDD85hhx2W73//\n+znxxBMzfvz4hp4NAAAAAAAAmqx63VH3pS99KbNmzcp5553X0PMAAAAAAABAs1CvO+o2bdqU1157\nraFnAQAAAAAAgGajXnfUvfHGGxk8eHA6deqUNm3apLa2NpVKJYsWLWro+QAAAAAAAKBJqleomzlz\nZkPPAQAAAAAAAM1KvULdM8888xeP9+zZc48OAwAAAAAAAM1FvULd0qVL615v2bIlzz77bP7u7/4u\nZ555ZoMNBgAAAAAAAE1ZvULdDTfcsMPPb731VsaOHdsgAwEAAAAAAEBz0OKvuWjffffNq6++uqdn\nAQAAAAAAgGajXnfUVVVVpVKpJElqa2uzcuXKfOpTn2rQwQAAAAAAAKApq1eoGzNmTN3rSqWSjh07\npk+fPg02FAAAAAAAADR19dr6csGCBTnmmGNyzDHHZMCAAenTp0/Gjx/f0LMBAAAAAABAk7XLO+om\nTpyYV155Jf/+7/+eFStW1B3funVr3n777QYfDgAAAAAAAJqqXYa6L3/5y3n11VczefLkjB49uu54\ny5Yt07t37wYfDgAAAAAAAJqqXYa6Xr16pVevXnnooYfy1ltv5d13301tbW22bduW559/Pscee+ze\nmhMAAAAAAACalF2Guj+aOnVq5s6dm61bt+bAAw/M6tWr069fv9x///0NPR8AAAAAAAA0SS3qc9Ij\njzySH//4xxkyZEhmz56d73znO/nIRz7S0LMBAAAAAABAk1WvUNe1a9e0b98+ffv2zQsvvJCBAwfm\n97//fUPPBgAAAAAAAE1Wvba+bN++fb7//e/n4x//eObMmZOuXbtm/fr1DT0bAAAAAAAANFn1uqNu\n8uTJeeONN/LJT34yPXv2zNe+9rVceumlDT0bAAAAAAAANFn1uqOuW7duOe+88/LCCy9k3Lhx2bRp\nU/bdd9+Gng0AAAAAAACarHrdUbdkyZKcccYZufjii/P73/8+J598cp566qmGng0AAAAAAACarHqF\nuqlTp+aee+7JAQcckK5du2b27Nm5+eabG3o2AAAAAAAAaLLqFeq2b9+eLl261P3cp0+fBhsIAAAA\nAAAAmoN6PaPuoIMOyo9+9KNUKpWsX78+c+fOTY8ePRp6NgAAAAAAAGiydnlH3apVq5IkkyZNysMP\nP5zXXnstp5xySp5//vlMmjRprwwIAAAAAAAATdEu76i76KKLMn/+/HTq1Cn9+vXL1KlT99ZcAAAA\nAAAA0KTt8o662trautcPP/xwgw8DAAAAAAAAzcUuQ12lUql7/efRDgAAAAAAAPhgdhnq/tyfRzsA\nAAAAAADgg9nlM+pWrFiRk08+OUmyatWqute1tbWpVCpZtGhRw08IAAAAAAAATdAuQ92CBQv21hwA\nAAAAAADQrOwy1PXs2XNvzQEAAAAAAADNSr2fUQcAAAAAAADsOUIdAAAAAAAAFCDUAQAAAAAAQAFC\nHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFC\nHQAAAAAAABQg1AEAAAAAAEABrUoP0FwMvfzB0iMAADRaD99yRukRAAAAAPY6d9QBAAAAAABAAUId\nAAAAAAAAFCDUAQAAAAAAQAGeUQcAQKOzYMFjueee2alUKmnbtm0uvfSK9O17WKZPn5af/WxJtm3b\nluHDR+TMM89Okrzyysu54YZJWb9+Xdq1a5drrpmUgw8+pOyXAAAAAHgfDRLqfvKTn+TGG2/Md7/7\n3bRp0yarVq3Kl770pdxxxx35+c9/nrlz5yZJWrZsmcMPPzxXXnllWrduncGDB6d79+6pVCrZuHFj\nTj311PzDP/zDHpnphz/8YT7xiU+kW7duf/H96dOnp3Pnzhk+fPgOx+fMmZO5c+dmzJgxGTduXPr3\n758k2bRpU44//vhccsklqVQqe2RGAACSl19+Kd/+9jczc+bcdO7cOUuWPJWrr74yI0acn5UrX87d\nd8/Lxo0bc9FFF+Rv/ubwHHlkv0yadE3OOecL+cxnPpslS36SiRPHZfbsef6dBgAAADRqDbL15XHH\nHZcTTjgh119/fbZs2ZKxY8dmwoQJeeGFF3LfffflX/7lX3LPPffk7rvvTqVSyfe///26a2fNmpU5\nc+bk3nvvzbx587J27do9MtPdd9+dd955Z7eve/zxx3PrrbdmyJAh6dChQ2bPnp3Zs2fnvvvuy9q1\nazNnzpw9Mh8AAH+wzz6tM378V9O5c+ckyeGHH5k33libH/1oYYYMOT2tWrXKAQcckJNP/kwef/wH\nWbNmdf7zP/8z/+t/fSZJcuyxx2XTpnfzm98sL/k1AAAAAN5Xgz2jbuzYsfn1r3+dL3/5yxk0Cr3i\nuAAAIABJREFUaFCOO+64zJ49O+PGjcsBBxyQJKlUKrnqqqsybNiw91y/adOmtGrVKm3bts2WLVty\nxRVX5Lzzzss555yTxx57LEny3HPPZfjw4RkxYkS++MUv5r/+67+yefPmXHTRRRkxYkQ+//nP56mn\nnsrixYvz/PPPZ/z48ampqdnpzAsXLszIkSMzbNiwLFu2LPPmzctzzz2XiRMn5pVXXtnh3Eqlkgsu\nuKBuFgAA9ozu3Xtk0KDjkyS1tbWZPn1ajj/+U1m79vfp2vVPuyN07dotq1evzqpVq9K5c+e0aPGn\nf9p26dI1a9as2uuzAwAAAOyOBntG3T777JNzzz031dXVmTRpUpJk5cqVOfjgg5Mkv/jFLzJ16tRs\n2bIl3bt3z7Rp05Iko0aNSqVSyYsvvpgTTzwx++67b+bOnZuPfOQjmTJlSt55552cddZZGThwYK65\n5ppMnjw5RxxxRBYuXJgbb7wxY8aMyVtvvZU77rgja9euzUsvvZSTTjopRxxxRKqrq9O6deudztyz\nZ89MmjQpK1asyLhx4zJ//vw88sgjqa6uzkc/+tH3nN+5c+e8+eabDfDbAwBofrp02X+Hnzdu3JgJ\nEyZk1arXc8cdd+Scc85Jx4771p23//5t065d63To0DYtW7bY4fp99mmZjh3bv+czAXaHNQRobKxL\nQGNjXYIPrsFC3cqVK3PHHXfkyiuvzJVXXpm777473bt3z8qVK3P44Yenf//+mT17dn7729+murq6\n7rpZs2alTZs2qampyYUXXpiHHnoov/3tbzNo0KAkSfv27dO7d++88sorWb16dY444ogkyYABA3LL\nLbekb9++Offcc3PZZZdl69atqaqqqvfMAwYMSJL07ds3a9ased/zX3311Rx00EG78VsBAGBn1qx5\nu+7166+/nvHjx+aQQw7J1KnfyubNlXTq1DX/8R8vp2fP3kmSF198OR06fCRt2hyQNWvWZPXq9XXP\npHvttdfTuvX+O3wmwO7o0sUaAjQu1iWgsbEuwe7ZWdhukK0va2pqMnbs2Fx99dU5//zz071798yY\nMSMjRozIzTffnLff/tP/vD/72c/+4me0bt06nTp1ypYtW9K7d+/8/Oc/T5K88847+c1vfpNevXql\na9eueeGFF5IkzzzzTA455JAsX748GzZsyO23354bb7wxX//615P8YavK2traXc69bNmyJMny5cvT\no0ePXZ67ffv2zJo1K6eddlr9fikAANTL+vXrMmbMhTnxxE/n2mtvSJs2bZMkJ5zwqTz66EPZunVr\n3n777Sxa9HhOOOGkdO3aLT169MqiRY8nSZYuXZJKpZLevfuU/BoAAAAA76tB7qi76aabcvTRR+fE\nE09MklRXV9dtV3nuuefm4osvTpJs2LAhffr0qYtpyR+2vmzRokW2bduW7t275/TTT0+SfPWrX83w\n4cOzefPmjB49Op06dcp1112Xr3/966mtrU3Lli1z/fXXp2vXrvnWt76VH/zgB9m+fXsuueSSJEn/\n/v0zbty4zJo1KwceeOBfnHvlypUZOXJkampq6rbr/HPr1q1LVVVVKpVKtm7dmkGDBuXss8/eo787\nAIDmbv7872bVqtfz5JOL8+STi+uOT506Pa+++mrOP/8L2bp1S04//az07390kuTaa6/PTTddl7vu\nmpnWrdvk61+/aYdn1gEAAAA0RpXa97vNjD1i6OUPlh4BAKDReviWM2yZAjQqtnICGhvrEtDYWJdg\n9+xs68sGe0ZdYzV69OisW7duh2Pt27fPbbfdVmgiAAAAAAAAmqNmF+pmzJhRegQAAAAAAACIB3cA\nAAAAAABAAUIdAAAAAAAAFNDstr4s5eFbzvBgTaDR8LBfAAAAAIDy3FEHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAA\nUECr0gM0F0Mvf7D0CAAARcyaMLj0CAAAAACNkjvqAAAAAAAAoAChDgAAAAAAAAqw9SUAAEXU1tbm\n+uuvzcc+1jtf+crFWb9+XaZMuTErVixPu3btMmTI0Jx99nn53e9ezLXXXlN33fbt2/Lii7/N5Mk3\n58QTbasJAAAAfHgJdQAA7HUvvfS7TJ16U37961/li1/snST553+emnbt2mXOnPuzffv2XHXV5ene\nvWeOO+6E3HnnPXXXTp8+LYce2kekAwAAAD70mvXWl0uXLs3RRx+d1157re7YlClT8sADD6Rfv36p\nqqrKiBEjctZZZ+XBBx/c4drq6uqceeaZe3tkAIAm4YEH7suQIUMzePApdceWL38+//t/D0nLli2z\nzz775Nhjj8/ixYt2uO6Xv/xFFi9elCuvvGpvjwwAAACwxzXrUJckrVu3zlVXXZXa2todjnfo0CGz\nZ8/OnDlzctddd+Wmm26qO+fdd9/Ns88+m969e2fp0qUlxgYA+FC77LLx+exnT9vh2JFH9suCBY9l\n69at2bhxY3784yeydu3vdzhnxoxbc+GFF2e//drvzXEBAAAAGkSzD3UDBw5Mhw4dMnfu3J2e8847\n7+SAAw5IpVJJkvzgBz/Isccem8997nO7vA4AgPobPXpsKpVKLrjgC7n66isyYMAn06rVPnXv/+pX\nv8y6dW/llFM+W3BKAAAAgD3HM+ryh20szznnnJxwwgl1x9atW5eqqqps3749v/nNb1JVVVX33v33\n359Jkyald+/eqa6uzqpVq9KtW7cSowMANHpduuy/0/fatt0n7du3+f+vk69+9eoceOCBSZLbb789\nffseWnf9T3+6OJ///Fnp1q1DQ48MkGTX6xdACdYloLGxLsEHJ9Ql6dixY66++uqMHz8+Rx11VJI/\nbX2Z/OGOuvPOOy+DBg1Kx44ds2LFitx4441Jkkqlkn/913/NpZdeWmx+AIDGbM2at3f63qZNW/LO\nO5uTJLNm3Z0NG97JZZeNzxtvrM29985LdfXkuuuXLFmasWPH7fLzAPaULl32t94AjYp1CWhsrEuw\ne3YWtpv91pd/NHjw4HzsYx/L/Pnz3/Pefvvtl/333z9btmzJ/fffn7Fjx2bmzJmZOXNm7rrrrnzv\ne99LTU1NgakBAJqOqqrzs2bN6lRVDcsll3w5o0ZdmCOO+Hjd+ytXvpzu3bsXnBAAAABgz3JH3Z+Z\nOHFinn766SR/2voySWpqavK3f/u3Ofroo3PllVfmoYceqrumR48eOfzww7NgwYIMHTq0yNwAAB9W\nEydW173ed9/9csMNt+z03IULn9oLEwEAAADsPZXa2tra0kM0B0Mvf7D0CAAARcyaMPh9z7FlCtDY\nWJeAxsa6BDQ21iXYPba+BAAAAAAAgEZEqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACAAlqVHqC5\nePiWMzxYE2g0POwXAAAAAKA8d9QBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAa1KD9BcDL38wdIjAAAUMWvC4NIjAAAAADRK7qgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAI8ow4AgCJqa2tz/fXX5mMf652vfOXirF+/LlOm3JgV\nK5anXbt2GTJkaM4++7z87ncv5tprr6m7bvv2bXnxxd9m8uSbc+KJnn8HAAAAfHgJdQAA7HUvvfS7\nTJ16U37961/li1/snST553+emnbt2mXOnPuzffv2XHXV5enevWeOO+6E3HnnPXXXTp8+LYce2kek\nAwAAAD70mkSoW7p0aS699NL06dMnSbJhw4b06tUrU6ZMyVFHHZX+/fvXndu7d+9UV1f/xc+ZPn16\nOnfunOHDh+9wfM6cOZk7d27GjBmTyZMn5yc/+Unde08++WQee+yx3HjjjXv+iwEANFEPPHBfhgwZ\nmm7dDqo7tnz58xk7dlxatmyZli1b5thjj8/ixYty3HEn1J3zy1/+IosXL8rdd99bYmwAAACAPapJ\nhLokGThwYKZNm1b38+WXX54nnngiHTp0yOzZsz/QZz/++OO59dZbc9hhh2Xy5MkfdFQAgGbvssvG\nJ0meffaZumNHHtkvCxY8lk984n+mpqYmP/7xE2nVasd/rs6YcWsuvPDi7Ldf+706LwAAAEBDaFF6\ngIZQU1OT1atXp0OHDrt97cKFCzNy5MgMGzYsy5Yty7x58/Lcc89l4sSJeeWVVxpgWgAAkmT06LGp\nVCq54IIv5Oqrr8iAAZ9Mq1b71L3/q1/9MuvWvZVTTvlswSkBAAAA9pwmc0fd008/naqqqqxduzYt\nWrTIsGHDcuyxx2bdunWpqqqqO2/8+PHp16/fTj+nZ8+emTRpUlasWJFx48Zl/vz5eeSRR1JdXZ2P\nfvSj7/m8t956Kx//+Mcb9LsBAHyYdemy/07fa9t2n7Rv3+b/v06++tWrc+CBByZJbr/99vTte2jd\n9T/96eJ8/vNnpVu33f9jLIC/xq7WL4ASrEtAY2Ndgg+uyYS6P259+eabb2bUqFHp1atXkuz21pcD\nBgxIkvTt2zdr1qx5z/v//fP++Iw6AAD+sjVr3t7pe5s2bck772xOksyadXc2bHgnl102Pm+8sTb3\n3jsv1dWT665fsmRpxo4dt8vPA9hTunTZ33oDNCrWJaCxsS7B7tlZ2G5yW1927Ngx3/jGN3LNNddk\n9erVu339smXLkiTLly9Pjx499vR4AADsRFXV+VmzZnWqqoblkku+nFGjLswRR/xp54KVK19O9+7d\nC04IAAAAsGc1mTvq/lyfPn1SVVWV6667brevXblyZUaOHJmamppMmjSpAaYDAOCPJk6srnu97777\n5YYbbtnpuQsXPrUXJgIAAADYeyq1tbW1pYdoDoZe/mDpEQAAipg1YfD7nmPLFKCxsS4BjY11CWhs\nrEuwe3a29WWTvKPu/YwePTrr1q3b4Vj79u1z2223FZoIAAAAAACA5qZZhroZM2aUHgEAAAAAAIBm\nrkXpAQAAAAAAAKA5EuoAAAAAAACggGa59WUJD99yhgdrAo2Gh/0CAAAAAJTnjjoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgD\nAAAAAACAAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAooFXp\nAZqLoZc/WHoEAKCZmjVhcOkRAAAAAPgL3FEHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAV4Rh0A\nQDNUW1ub66+/Nh/7WO984QtV2bZtW6ZNuzn/9m//N0kycOBx+cd//EoqlUrWr1+XadO+kZdeejGb\nN2/OyJGj8tnPnlb4GwAAAAB8+LmjDgCgmXnppd/lK1/5cp544od1xxYseCwvv/yfueuue3Pnnf+a\nf/u3/5sf/WhRkmTy5Op06dI13/nOPbn11m/n1lunZPXqVaXGBwAAAGgymnyoW7p0aQ477LA8+uij\nOxwfOnRoJkyYkMGDB2fz5s07vPfAAw/kpJNOSlVVVaqqqnLuuefmscceq3t/8+bNOe6443LHHXfs\nle8AALAnPfDAfRkyZGgGDz6l7tj27dvy7rvvZsuWLampqcmWLVvSunXrrF+/Ls8887OMGnVhkqRr\n1265/fY7c8ABHUqNDwAAANBkNIutLw899NA8+uijOe20P2zRtHz58rz77ru7vObv//7vc8UVVyRJ\n3nrrrZx++uk59dRTU6lUsmDBggwZMiTz58/PqFGj0qJFk++dAEATctll45Mkzz77TN2xU08dmiee\nWJQzzzw127ZtyzHHfDLHH/+pPPfcv6dTp8659945Wbr0p6mp2ZLhw0fkf/yPg0uNDwAAAPD/2Lv3\nIK/r+97jr+UibOSmYcUaqRI9FqM5h0ZsTIw9p5vWy8oiUUKUsqvV0oyjCQG1omgCxqyX4qUhc5xq\nBCKIFcwKSoxRizEnmWSteo62NmqpQTEiriZBVleue/7odOsOYGsD+/mx+3jMOLO/z/f7+877N64f\nHJ9+v78eo1cUptGjR+fVV1/Nxo0bkyT33Xdf6uvr/9Pv37hxYwYOHJiqqqokybJly3LGGWdk9OjR\neeyxx/bIzAAA3WnBgtuy337Dcv/9D+Xeex/IW2+9lbvuWpytW7dm3bpfZt99B+WWW+ZnzpymzJt3\nY5577uelRwYAAADY6/WKO+qS5MQTT8xDDz2U008/Pc8880ymTp2adevW7fL8lStX5umnn05VVVWq\nq6tz/fXXJ0nWrFmT9vb2jB49OmeccUbmz5+fP/qjP+qujwEA8IHV1Aze6frAgf0zaNCA1NQMzk9+\n8liuuOKKHHTQ/kmSSZMm5gc/+EE+97lxSZLGxrMyaNCg1NR8LGPHjs3atatzwgl/0C1zApRiXwIq\njX0JqDT2Jfjt9ZpQV19fn9mzZ2fkyJEZO3bsf3j+ex99+V7Lli1Le3t7zjvvvCTJU089lZdeeimH\nHOLxTwBAZWpt3bjT9Xff3ZK2tk1pbd2Yj370v+Xee+/LYYcdla1bt+b7338oRxwxOgMHDssRR4zO\nokV3ZeLEM/OrX72ZJ598KhMnTt7ldf8ramoG79brAfy27EtApbEvAZXGvgQfzK7Cdq8JdSNHjsw7\n77yTRYsWZcaMGVm7du0HvsaWLVvywAMP5N57782wYcOSJLfcckuWLFmSyy67bHePDADQbb785Rm5\n6aa/yuTJZ6RPn74ZO/bYTJlyTpKkqWlubrzxuixf3pyOju0555w/z5FHHlV2YAAAAIAeoNeEuiSp\nq6vLihUrMmrUqC6h7qyzzur8ub6+PkOHDt3p+x999NEcddRRnZEuSU4//fScdtpp+cpXvpLq6uo9\nNzwAwG42a9bszp+HDh2W2bO/sdPzDjzwwFx//U3dNBUAAABA71HV0dHRUXqI3qD+ohWlRwAAeqn5\nM2tLj/Af8sgUoNLYl4BKY18CKo19CT6YXT36sk83zwEAAAAAAABEqAMAAAAAAIAihDoAAAAAAAAo\noF/pAXqL+284zfN6gYrhGeIAAAAAAOW5ow4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACgAKEOAAAAAAAAChDqAAAA\nAAAAoAChDgAAAAAAAAoQ6gAAAAAAAKAAoQ4AAAAAAAAKEOoAAAAAAACggH6lB+gt6i9aUXoEAOg2\n82fWlh4BAAAAACqeO+oAAAAAAACgAKEOAAAAAAAAChDqAAAAAAAAoADfUQcAdIuOjo40Nc3JqFGH\nZfLkhiTJuHF/nOHDD+g8Z/Lkhpx44in5+c+fzTe/eUPa29/N9u3b8qd/enZOOqmu1OgAAAAAsEf0\n6DvqWlpaMn369M7XDz74YMaNG5fGxsZceOGFXc49/vjjkyTNzc2pra1NW1tb57Hp06enpaUlr7zy\nSiZNmtTlfXfddVfmzZu3Bz8FAOz91qz5RaZNOz+rVj3cufbyy2syaNCQLFy4pPOvE088JR0dHZk1\n6y9z7rlfzMKFSzJ37jczb95NWbv25YKfAAAAAAB2vx4d6t5r5cqVufXWW7Nw4cIcdNBBefLJJ7N8\n+fKdntve3p6mpqZunhAAeq7m5qWpq6tPbe2fdK79wz88k759++RLX/pizj77zCxYcFu2bduWzZs3\n59xzp+bYYz+ZJDnggBEZNmxYWltfLzU+AAAAAOwRvSLULV++PAsXLsyCBQsyfPjwJMmMGTMyb968\nvPbaazucP2HChLz44ot59NFHu3tUAOiRZsy4NCeffGqXtW3btuXYYz+ZG26Yl29967Y8/vhP893v\n3p0BAwZk3LgJneetWNGcd955J0cddXR3jw0AAAAAe1SP/466J554IuvXr8+GDRuybdu2zvURI0Zk\n2rRpmTVrVm6//fYu7+nbt2+uvfbaTJ06NWPGjOlybPXq1WloaOh8/frrr2fcuHF79kMWjjXoAAAg\nAElEQVQAQA80fvznOn/eZ5998oUv/GnuuefuTJo0uXN90aKFueeeuzJ37rwMGDCwxJgAAAAAsMf0\n+FBXU1OTBQsWZNmyZbnkkkty2223dR4bP358HnnkkSxZsmSH9x166KFpbGzMnDlzUlVV1bl++OGH\nZ9GiRZ2v77rrrrzxxht79kMAwF6mpmbwTtcHDuyfQYMGpKZmcJYvX57Ro0dn9OjRSZLBgwemuvpf\nj23evDkzZ87M6tWrs3Tp0hx88MHdOT6F7Or3BqAU+xJQaexLQKWxL8Fvr8eHukMOOSQDBgzIlClT\n8uMf/zi33HJLl+OzZ8/OpEmT8vbbb+/w3ilTpuSRRx7JCy+8kDPPPLO7RgaAvV5r68adrr/77pa0\ntW1Ka+vGPP30s1m58oFcffX12bp1SxYs+E5OPPGUtLZuzKWXTs/27dvzrW99OwMGVO/yevQcNTWD\n/X0GKop9Cag09iWg0tiX4IPZVdjuFd9R92+amppy9913p6WlpXNt//33z8yZM9Pe3r7D+VVVVbnm\nmmuyefPm7hwTAHqFc8/9iwwePCRnn31mzj77rHz84/8j9fUT8swz/y8/+cn/ySuvrM3555+Xc86Z\nnHPOmZyWlp+WHhkAAAAAdquqjo6OjtJD9Ab1F60oPQIAdJv5M2tLj8Bexv+JCVQa+xJQaexLQKWx\nL8EH4446AAAAAAAAqCBCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAU0K/0AL3F/Tec5os1gYrh\ny34BAAAAAMpzRx0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg\n1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABAAf1KD9Bb1F+0ovQIANDF/Jm1pUcAAAAAgF7NHXUA\nAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQBwB06ujoyDe+MTtLliza4djll1+SG2+8bof1V1/9\nZU45pTbPPfdP3TEiAAAAAPQY/UoPsKe1tLSksbExN954Y0499dTO9fr6+hx11FF5/PHH8/3vfz8D\nBgzoPNbc3JxvfvObGTlyZJJk8+bNOfvss1NXV5eGhoa0t7enuro6W7ZsycEHH5xZs2Zlv/326/bP\nBgC705o1v8iNN16XZ5/9h5x33mFdjt1553fyzDP/N7W1f9JlfdOmTfn616/M1q1bunNUAAAAAOgR\nenyoS5KPfvSj+d73vtcZ6p5//vm0t7e/73vGjRuXiy++OEnym9/8JuPHj88pp5ySJLnuuuty2GH/\n+h8w77vvvnz1q1/NvHnz9uAnAIA9r7l5aerq6jNixIFd1p966om0tPw0p512RjZufKvLsRtvvC6n\nnFKfO+6Y352jAgAAAECP0CsefTl69Oi8+uqr2bhxY5J/jWv19fX/6fdv3LgxAwcOTFVV1Q7Hxo8f\nn2effTabNm3abfMCQAkzZlyak08+tcvaG2+05q//em6++tWr06dP139tuP/+5dm6dWvGj/9cd44J\nAAAAAD1Gr7ijLklOPPHEPPTQQzn99NPzzDPPZOrUqVm3bt0uz1+5cmWefvrpVFVVpbq6Otdff/0u\nzx0yZEjeeuut1NTU7InRAWCPqKkZvNP1gQP7Z9CgARk2bGC+8pUrc+WVV+TII0flkUcGZPPmfVJT\nMzjPPvtsVq68N3feeWeqq6vTt2+fDBv2oV1eE/4z/P4Alca+BFQa+xJQaexL8NvrNaGuvr4+s2fP\nzsiRIzN27Nj/8Pz3Pvry/XR0dOSNN97Ihz/84d0xJgB0m9bWjTtdf/fdLWlr25Qf//jxvPzy2lx9\ndVOS5Fe/ejPbt2/Lhg1tqa7+UDZs2JiJEyclSdavX5/p02fkggum5TOf+Z/d9hnoOWpqBu/ydxKg\nBPsSUGnsS0ClsS/BB7OrsN1rQt3IkSPzzjvvZNGiRZkxY0bWrl27W657zz335LjjjtvhcWAAsLc7\n+uj/nubm73W+vv32v8mGDb/JjBmXJkmmTbuo89jEifX52teuzujRH+v2OQEAAABgb9VrQl2S1NXV\nZcWKFRk1alSXUHfWWWd1/lxfX5+hQ4e+73UuvfTSVFdXJ0lGjBiRr33ta3tmYAAAAAAAAHqsqo6O\njo7SQ/QG9RetKD0CAHQxf2Zt6RGgk0emAJXGvgRUGvsSUGnsS/DB7OrRl57XCAAAAAAAAAUIdQAA\nAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQQL/SA/QW999wmi/WBCqGL/sFAAAAACjPHXUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABfQrPUBvUX/RitIjANBN5s+sLT0CAAAAALAXcEcdAAAAAAAAFCDUAQAAAAAAQAFC\nHQAAAAAAABTgO+oAoJt0dHSkqWlORo06LJMnN6StrS3XXntVXnppTTo6OnLyyadmypRzkiRr176c\na665Km+9tSHV1dW54oqrcsghhxadHwAAAADYvXrtHXUtLS055phjsm7dus61uXPnprm5OUcffXQa\nGhoyZcqUnH766VmxYkWSpLm5OXPnzu1ynenTp6elpaVbZwdg77NmzS8ybdr5WbXq4c61b3/7ltTU\njMiiRUtz2213ZPny7+Yf//GZJMlVV12RCRMmZvHiZTn33C9m1qy/TEdHR6nxAQAAAIA9oFffUbfP\nPvvksssuy4IFC1JVVdW5PnTo0CxatChJsnHjxpx00kkZP358qTEB6AGam5emrq4+I0Yc2Lk2bdrF\n2bZtW5LkzTffyJYtm7PvvoPS2vp6XnrppfzxH5+YJPnUp47PDTdcmxdeeD6/93uji8wPAAAAAOx+\nvfaOuiQ57rjjMnTo0Nx55527PKetrS1DhgzpEvIA4IOaMePSnHzyqV3Wqqqq0q9fv1x11ZVpbPxC\nxow5Jr/7u4dk/fr1GT58ePr0+fc/pmtqDkhr6/ruHhsAAAAA2IN69R11STJ79ux8/vOfzwknnNC5\ntmHDhjQ0NGT79u154YUX0tDQ0Hls5cqVefrppztfr169OmeeeWa3zgxAZaupGbzLYwMH9s+gQQO6\nnDNv3s15++238+UvfzlLl96Rz3zmM+nbt0+Xc/r375v99hv0vteGvZ3fb6DS2JeASmNfAiqNfQl+\ne70+1O233365/PLLc+mll+YTn/hEkq6Pvmxra8uZZ56ZT3/600mScePG5eKLL+58//Tp07t/aAAq\nWmvrxl0ee/fdLWlr25TW1o1paflpDjvs8AwfXpMk+cM//Gx++MNV+exn69La2prXX3+r847udete\nyz77DH7fa8PerKbG7zdQWexLQKWxLwGVxr4EH8yuwnavfvTlv6mtrc2oUaNy77337nBs3333zeDB\ng7Nly5YCkwHQk61a9XDmz781HR0d2bx5c1atejjHHDM2BxwwIgcddHD+7u8eSpK0tPw0VVVVOeyw\nwwtPDAAAAADsTr3+jrp/M2vWrPzsZz9L8u+PvkySzZs35+Mf/3iOO+64nYY8APivuvDC6Zk7tymN\njV9IVVVVTjjhf+Xznz8rSTJnTlOuu+7qfOc7t2effQbk61+/rst31gEAAAAAe7+qjo6OjtJD9Ab1\nF60oPQIA3WT+zNrSI8BexyNTgEpjXwIqjX0JqDT2JfhgPPoSAAAAAAAAKohQBwAAAAAAAAUIdQAA\nAAAAAFCAUAcAAAAAAAAF9Cs9QG9x/w2n+WJNoGL4sl8AAAAAgPLcUQcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\ngFAHAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQ\nQL/SA/QW9RetKD0CwG43f2Zt6REAAAAAAPZa7qgDAAAAAACAAoQ6AAAAAAAAKMCjLwHYrTo6OtLU\nNCejRh2WyZMbsm3btsybd1Mef/yn2bZtW846a0omTJiYJHnrrQ256aa/ypo1L2bTpk1pbDw3J598\nauFPAAAAAADQPdxRB8Bus2bNLzJt2vlZterhzrUVK5rzyisv54477s5tt92RpUvvyj/90z8mSb7x\njdmpqTkgCxYsyc03/+/cfPPcvP76+lLjAwAAAAB0qx4d6lpaWjJ9+vTO1w8++GDGjRuXxsbGXHjh\nhV3OPf7445Mkzc3Nqa2tTVtbW+ex6dOnp6WlJa+88ko+8YlPpKGhIVOmTMmkSZOyePHi7vkwAHuB\n5ualqaurT23tn3Su/ehHj6aubnz69euXIUOG5LOfPTEPPfT9vPXWhvz93z+ec8/9iyTJAQeMyK23\nLsyQIUNLjQ8AAAAA0K16dKh7r5UrV+bWW2/NwoULc9BBB+XJJ5/M8uXLd3pue3t7mpqadnrs8MMP\nz6JFi7J48eLceeed+dGPfpRVq1btydEB9hozZly6w6MrX399fQ44YETn6wMOGJHXX389r7yyNh/+\n8PD87d8uzvnnn5vzzmvICy88l4EDB3b32AAAAAAARfSKULd8+fIsXLgwCxYsyPDhw5MkM2bMyLx5\n8/Laa6/tcP6ECRPy4osv5tFHH33f6/bv3z+NjY154IEH9sjcAD3B9u0dO6z16dMnW7duzbp1v8y+\n+w7KLbfMz5w5TZk378Y899zPC0wJAAAAAND9+pUeYE974oknsn79+mzYsCHbtm3rXB8xYkSmTZuW\nWbNm5fbbb+/ynr59++baa6/N1KlTM2bMmPe9/vDhw/PrX/96j8wOUOlqagbvdH3gwP4ZNGhAamoG\nZ+TIj2Tr1rc7z33nnQ055JCDc8QRhyZJGhvPyqBBg1JT87GMHTs2a9euzgkn/EF3fQSgguxqTwEo\nxb4EVBr7ElBp7Evw2+vxoa6mpiYLFizIsmXLcskll+S2227rPDZ+/Pg88sgjWbJkyQ7vO/TQQ9PY\n2Jg5c+akqqpql9f/5S9/mQMPPHCPzA5Q6VpbN+50/d13t6StbVNaWzfmk588PkuW3J2jjx6b9vb2\n3Hff/bn44ssycOCwHHHE6CxadFcmTjwzv/rVm3nyyacyceLkXV4X6Llqagb7Zx+oKPYloNLYl4BK\nY1+CD2ZXYbvHP/rykEMOyYABAzJlypT0798/t9xyS5fjs2fPzvz58/P222/v8N4pU6bk17/+dX72\ns5/t9NqbN2/OHXfckVNPPXWnxwFIJkyYmI985OCcc87kTJ3amFNPPS2///vHJEmamubm8cdbMmXK\npHzpS1/MOef8eY488qjCEwMAAAAAdI8ef0fdezU1NWXChAnp27dv6urqkiT7779/Zs6cmQsuuGCH\n86uqqnLNNdekvr6+c2316tVpaGhIVVVVtm7dmvr6+nz605/uts8AsDeYNWt258/9+vXLtGkX7fS8\nAw88MNdff1M3TQUAAAAAUFmqOjo6OkoP0RvUX7Si9AgAu938mbWlRwB6CI9MASqNfQmoNPYloNLY\nl+CD6bWPvgQAAAAAAIBKJNQBAAAAAABAAUIdAAAAAAAAFCDUAQAAAAAAQAH9Sg/QW9x/w2m+WBOo\nGL7sFwAAAACgPHfUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUINQBAAAAAABA\nAUIdAAAAAAAAFCDUAQAAAAAAQAH9Sg/QW9RftKL0CEAFmT+ztvQIAAAAAAAU5o46AAAAAAAAKECo\nAwAAAAAAgAKEOgAAAAAAACjAd9QBVIDHHns08+f/Taqq+mTw4MGZOfPKDB48OHPnXpt//ufnU11d\nnbq6+kyceGbpUQEAAAAA2E2EOoDCNm16N1//+pVZuPCuHHzwyNx99525+ea/ytChw1JdXZ3Fi5dl\n+/btueyyi/I7v/ORHH/8CaVHBgAAAABgN+jxj75saWnJ9OnTO18/+OCDGTduXBobG3PhhRd2Off4\n449PkjQ3N6e2tjZtbW2dx6ZPn56WlpbO1w888EDGjBmT9evX7+FPAPR027ZtT0dHR+ee097enn32\n2SfPP//znHRSXfr27Zv+/fvnU5/6TH74w78rPC0AAAAAALtLjw9177Vy5crceuutWbhwYQ466KA8\n+eSTWb58+U7PbW9vT1NT0y6vtWzZsjQ0NGTp0qV7alygl/jQhz6Uiy++LOeff25OO+3kfPe7S3P+\n+V/Oxz52dH7wgweydevWvPPOO3nssVV58803So8LAAAAAMBu0mtC3fLly7Nw4cIsWLAgw4cPT5LM\nmDEj8+bNy2uvvbbD+RMmTMiLL76YRx99dIdja9euzYYNGzJ16tSsWLEiW7Zs2ePzAz3Xv/zL6ixc\n+O0sXrwsK1Y8mMbGczNr1l/mggu+kqqqqvzZn03O5ZdfnGOP/WT69etfelwAAAAAAHaTXvEddU88\n8UTWr1+fDRs2ZNu2bZ3rI0aMyLRp0zJr1qzcfvvtXd7Tt2/fXHvttZk6dWrGjBnT5dg999yTM844\nI0OGDMmYMWPy8MMPp66urls+C9Az1NQM7vz5vvueyrHHjs2YMUfm/7d3b7FV1vkeh7+L1gpyEHDU\nUfEAiBHHEHRGvTCauDWgJhVH8RjBiAckOmrcNOABLAGtDbp15AJmPMbqBKoYkQujoo6HmJio6RiN\naKKgokanGAytWgpd+66z2cZkO1L+3fA8V6x3Hfp7b37p4sP7kiQzZ87IkiX/lUGDKpk37+YMHz48\nSfLXv/4148aN2e69O2oGgP7AXgL6G3sJ6G/sJaC/sZfg19stQt2+++6bhx9+OE888UQaGhpy//33\n9z531llnZc2aNfnb3/72k/cddthhmT59ehYsWJBKpZIk2bZtW1avXp2DDjooL730Ur777rs89thj\nQh3wi/zzn5t7/3zQQaPz6KMt+fDD9Rk5cp/8/e8v5oADDsxDDz2azs6O3HjjnHz77cYsX74ijY23\nb/fef9e++w7dIZ8DsKPYS0B/Yy8B/Y29BPQ39hL8Mj8XtneLUHfooYdmzz33zCWXXJLXX389S5cu\n3e75xsbGnH/++ens7PzJey+55JKsWbMmH330US688MK88sorOfroo3Pffff1vmby5MlZu3Ztjjzy\nyD4/F2DX8/vfH5eLLpqWP/1pZmpr98iwYcPS1HR3fvvb32bhwvmZNu38VKvJjBlXZfz435UeFwAA\nAACAHWS3CHX/0x133JGzzz47NTU1vVfBjRw5MnPnzs0111zzk9dXKpU0NTWlvr4+SdLa2przzjtv\nu9dMnTo1jz/+eBYuXNj3JwDsks499/yce+75Pzne1HR3gWkAAAAAANgZKtVqtVp6iN1B/X+uKj0C\n0I88NPc/iv58tyYA+ht7Cehv7CWgv7GXgP7GXoJf5udufTlgJ88BAAAAAAAARKgDAAAAAACAIoQ6\nAAAAAAAAKECoAwAAAAAAgAJqSw+wu1h99xT/sSYAAAAAAAC9XFEHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABQh1AAAAAAAAUIBQ\nBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAABcoa4ckAAAmjSURB\nVAh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcAAAAAAAAFCHUAAAAAAABQgFAHAAAAAAAA\nBQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFBApVqtVksPAQAAAAAAALsbV9QBAAAAAABAAUId\nAAAAAAAAFCDUAQAAAAAAQAFCHQAAAAAAABQg1AEAAAAAAEABQh0AAAAAAAAUUFt6gF1ZT09PGhsb\n8+GHH6auri6LFi3KoYceWnosYDfyj3/8I3fddVdaWlry6aefZu7cualUKhk3blxuu+22DBgwIK2t\nrVm+fHlqa2sza9asnHLKKaXHBnZB3d3dufnmm/PFF19ky5YtmTVrVg4//HB7CShm27ZtufXWW7Nu\n3bpUKpUsWLAge+65p70EFLVx48acc845eeihh1JbW2snAcX98Y9/zJAhQ5Iko0aNytVXX203wQ4m\n1PWhNWvWZMuWLVmxYkXa2tpy5513ZunSpaXHAnYT999/f5555pkMGjQoSdLU1JQbbrghJ5xwQubP\nn58XX3wxEydOTEtLS1auXJmurq5cfPHFOfHEE1NXV1d4emBX88wzz2T48OFZvHhxNm3alLPPPjtH\nHnmkvQQU8/LLLydJli9fnjfffDP33HNPqtWqvQQU093dnfnz52fgwIFJfIcDyuvq6kq1Wk1LS0vv\nsauvvtpugh3MrS/70Ntvv52TTjopSTJx4sS89957hScCdieHHHJIlixZ0vv4/fffz/HHH58kOfnk\nk/PGG2/k3XffzTHHHJO6uroMHTo0hxxySNauXVtqZGAXdvrpp+f6669PklSr1dTU1NhLQFGnnXZa\nFi5cmCT58ssvM2zYMHsJKKq5uTkXXnhh9ttvvyS+wwHlrV27Nj/88ENmzJiR6dOnp62tzW6CPiDU\n9aGOjo7ey4KTpKamJlu3bi04EbA7mTx5cmpr/3XhdLVaTaVSSZIMHjw4mzdvTkdHR4YOHdr7msGD\nB6ejo2Onzwrs+gYPHpwhQ4ako6Mj1113XW644QZ7CSiutrY2c+bMycKFC1NfX28vAcU89dRTGTly\nZO8/+E58hwPKGzhwYC6//PI8+OCDWbBgQWbPnm03QR8Q6vrQkCFD0tnZ2fu4p6dnu780B9iZBgz4\n18rv7OzMsGHDfrKnOjs7t/vFCmBH+uqrrzJ9+vRMmTIl9fX19hLQLzQ3N+e5557LvHnz0tXV1Xvc\nXgJ2ppUrV+aNN97ItGnT8sEHH2TOnDn59ttve5+3k4ASRo8enbPOOiuVSiWjR4/O8OHDs3Hjxt7n\n7SbYMYS6PnTsscfm1VdfTZK0tbXliCOOKDwRsDs76qij8uabbyZJXn311fzhD3/IhAkT8vbbb6er\nqyubN2/Oxx9/bFcBfaK9vT0zZsxIQ0NDpk6dmsReAsp6+umn85e//CVJMmjQoFQqlRx99NH2ElDE\n448/nsceeywtLS0ZP358mpubc/LJJ9tJQFFPPvlk7rzzziTJ119/nY6Ojpx44ol2E+xglWq1Wi09\nxK6qp6cnjY2N+eijj1KtVnPHHXdk7NixpccCdiMbNmzIjTfemNbW1qxbty7z5s1Ld3d3xowZk0WL\nFqWmpiatra1ZsWJFqtVqZs6cmcmTJ5ceG9gFLVq0KM8++2zGjBnTe+yWW27JokWL7CWgiO+//z43\n3XRT2tvbs3Xr1lx55ZUZO3as35eA4qZNm5bGxsYMGDDATgKK2rJlS2666aZ8+eWXqVQqmT17dkaM\nGGE3wQ4m1AEAAAAAAEABbn0JAAAAAAAABQh1AAAAAAAAUIBQBwAAAAAAAAUIdQAAAAAAAFCAUAcA\nAAAAAAAF1JYeAAAAgP5pw4YNOf300zN27Njtji9btiwHHHBAoakAAAB2HUIdAAAAP2u//fbLqlWr\nSo8BAACwSxLqAAAA+FVWr16dBx54IDU1NRk1alQWL16curq63HXXXVmzZk1qampywQUX5NJLL826\ndesyf/78bNq0KXvttVduueWWTJgwIXPnzs2mTZvy6aefpqGhIb/5zW/S1NSUH3/8MSNGjMiCBQty\n8MEHlz5VAACAHUqoAwAA4Gd98803mTJlSu/j+vr6XHHFFdu95t57701ra2v22Wef3HPPPfnkk0+y\nfv36vPPOO1m9enW6u7tz8cUX58wzz0xDQ0OuuuqqTJo0KW1tbbn++uvz3HPPJUmGDx+eZcuWZcuW\nLZk6dWqWLVuWAw88MK+99lrmzZuXRx55ZGeeOgAAQJ8T6gAAAPhZ/5dbX55yyim56KKLcuqpp2by\n5MkZP358nnjiiZxxxhmpq6tLXV1dVq1alc7Oznz22WeZNGlSkmTixInZe++988knnyRJJkyYkCRZ\nv359Pv/888yaNav3Z3R0dPTRGQIAAJQj1AEAAPCr3HrrrVm7dm1eeeWVNDQ05Nprr01t7fZfNzds\n2JC999471Wp1u+PVajXbtm1LkgwcODBJ0tPTk1GjRvUGwm3btqW9vX0nnAkAAMDONaD0AAAAAPz/\ntXXr1kyaNCkjRozIzJkzM2XKlHzwwQc57rjj8sILL6S7uzs//PBDrrjiirS3t+fggw/O888/nyRp\na2tLe3t7xo0bt91njhkzJt99913eeuutJMnKlSsze/bsnX5uAAAAfc0VdQAAAPzbamtrc9111+Wy\nyy7LwIEDM2zYsDQ3N2f//ffPe++9l3POOSc9PT2ZPn16Ro8encWLF6exsTFLlizJHnvskSVLlqSu\nrm67z6yrq8uf//zn3H777enq6sqQIUPS3Nxc6AwBAAD6TqX6v+87AgAAAAAAAPQ5t74EAAAAAACA\nAoQ6AAAAAAAAKECoAwAAAAAAgAKEOgAAAAAAAChAqAMAAAAAAIAChDoAAAAAAAAoQKgDAAAAAACA\nAoQ6AAAAAAAAKOC/AW1MsKgY3J/sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c10f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "# fit model no training data\n",
    "model = XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=207,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.4,\n",
    "    subsample=0.65,\n",
    "    colsample_bytree=0.85,\n",
    "    objective= 'multi:softprob',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=15)\n",
    "model.fit(X_layer2_train, y_train_df, eval_metric='logloss')\n",
    "# plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "plot_importance(model, ax=ax)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

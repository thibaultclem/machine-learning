{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM FTR HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # visualization library based on matplotlib\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\",\"INFO_Div\"]\n",
    "best_features = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST',\n",
    "       'A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H',\n",
    "       'A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST',\n",
    "       'A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS',\n",
    "       'H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG',\n",
    "       'H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H',\n",
    "       'H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST',\n",
    "       'H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS',\n",
    "       'A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS',\n",
    "       'A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'SVM-best_26_features'\n",
    "target = 'INFO_FTR_H'\n",
    "odd = 'INFO_BbAvH'\n",
    "bet_on = 'H'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25275, 190)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df = (df[df.columns.drop(['index'])])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df['INFO_Date'] = pd.to_datetime(df['INFO_Date'])\n",
    "df['INFO_Date'].dt.month\n",
    "df = df[(df['INFO_Date'].dt.month < 6) | (df['INFO_Date'].dt.month > 10)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a particular league\n",
    "#df = df[(df['INFO_Div'] == 'D1')]\n",
    "# df = df[(df['INFO_Div'] == 'D1')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.552546735452375"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the average odd\n",
    "df[odd].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18027, 190)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing column where odd is too high or too low\n",
    "# df = df.drop(df[df['INFO_BbAvH'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] < 2].index)\n",
    "# df = df.drop(df[df['INFO_BbAvH'] > 10].index)\n",
    "# df = df.drop(df[df['INFO_BbAvA'] > 10].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain. If bet success it's equal to odd -1, else -1 (loose your bet)\n",
    "df['INFO_WIN'] = df[odd]-1\n",
    "df.loc[df.INFO_FTR != bet_on, 'INFO_WIN'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    45.515061\n",
       "A    28.856715\n",
       "D    25.628224\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Statistic about winners\n",
    "display(plt.show(), 100. * df.INFO_FTR.value_counts() / len(df.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03452709824152642"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much did you win/lost per match if bet on all\n",
    "df.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep season 2016/2017 for further test and don't use it for traning\n",
    "import datetime\n",
    "date_start_current_season = datetime.date(2015, 8, 1)\n",
    "df_current_season = df[(df['INFO_Date'] > date_start_current_season)]\n",
    "df = df[(df['INFO_Date'] < date_start_current_season)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4426, 191)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of matches in current season\n",
    "df_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "features_list = best_features\n",
    "X = pd.get_dummies(df[features_list])\n",
    "y = pd.get_dummies(df)[target].astype('bool_')\n",
    "X_current_season = pd.get_dummies(df_current_season[features_list])\n",
    "y_current_season = pd.get_dummies(df_current_season)[target].astype('bool_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X)\n",
    "X = sc_X.transform(X)\n",
    "X_current_season = sc_X.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute of missing values (NaN) with the mean\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp = imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "X_current_season = imp.transform(X_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   56.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.78473806381226"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Grid Search to find the best hyper-parameters for our Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.classification import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "parameters = [{\n",
    "    'C': [0.02],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10]\n",
    "},{\n",
    "    'C': [0.02],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['auto']\n",
    "}]\n",
    "# {'C': 0.02, 'gamma': 0.001, 'kernel': 'linear'}\n",
    "# FINAL\n",
    "parameters = [{\n",
    "    'C': [0.02],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': [1]\n",
    "}]\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=parameters,\n",
    "                           scoring=make_scorer(log_loss, greater_is_better=False),\n",
    "                           cv=8,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.333081888643648"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract best score calculated with the GridSearchCV\n",
    "best_score = grid_search.best_score_\n",
    "display(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.02, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyper-parameter calculated with the GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.261278</td>\n",
       "      <td>1.32651</td>\n",
       "      <td>-13.333082</td>\n",
       "      <td>-13.227347</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{u'kernel': u'linear', u'C': 0.02, u'gamma': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.97801</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.554394</td>\n",
       "      <td>-13.172928</td>\n",
       "      <td>-12.799759</td>\n",
       "      <td>-13.23927</td>\n",
       "      <td>-12.926722</td>\n",
       "      <td>-13.353761</td>\n",
       "      <td>2.474773</td>\n",
       "      <td>0.387395</td>\n",
       "      <td>0.391204</td>\n",
       "      <td>0.057364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0      18.261278          1.32651       -13.333082        -13.227347    0.02   \n",
       "\n",
       "  param_gamma param_kernel                                           params  \\\n",
       "0           1       linear  {u'kernel': u'linear', u'C': 0.02, u'gamma': 1}   \n",
       "\n",
       "   rank_test_score  split0_test_score       ...         split5_test_score  \\\n",
       "0                1          -13.97801       ...                -13.554394   \n",
       "\n",
       "   split5_train_score  split6_test_score  split6_train_score  \\\n",
       "0          -13.172928         -12.799759           -13.23927   \n",
       "\n",
       "   split7_test_score  split7_train_score  std_fit_time  std_score_time  \\\n",
       "0         -12.926722          -13.353761      2.474773        0.387395   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.391204         0.057364  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all results of Grid Search\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.to_csv('./tuning/'+model_name+'-'+target+'_'+start_date+'.csv')\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a new classifier using the best parameters found by the grid search\n",
    "clf = SVC(random_state=0,\n",
    "          C=best_params['C'],\n",
    "          kernel=best_params['kernel'],\n",
    "          gamma=best_params['gamma'],\n",
    "         probability=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict target values\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.295955875027975"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61482084690553751, 0.40744738262277386, 0.49010061668289512, None)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1755</td>\n",
       "      <td>473</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1098</td>\n",
       "      <td>755</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2853</td>\n",
       "      <td>1228</td>\n",
       "      <td>4081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  False  True   All\n",
       "Actual                      \n",
       "False       1755   473  2228\n",
       "True        1098   755  1853\n",
       "All         2853  1228  4081"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the confusion Matrix\n",
    "df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFlCAYAAAAZGcpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCaxkwSwwxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd83550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test.ravel(), y_probs[:, 1].ravel())\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL DATASET TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on all the dataset\n",
    "X_pred = clf.predict(X)\n",
    "df['pred'] = X_pred\n",
    "df_bet_all_seasons = df.drop(df[df.pred == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4230, 192)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many bet I did\n",
    "df_bet_all_seasons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    61.276596\n",
       "D    21.938534\n",
       "A    16.784870\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_all_seasons.INFO_FTR.value_counts() / len(df_bet_all_seasons.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.235601228649742"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61276595744680851, 0.42036976970483297, 0.49865332820315506, None)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score for all dataset\n",
    "precision_recall_fscore_support(y, X_pred, average='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>5797</td>\n",
       "      <td>1638</td>\n",
       "      <td>7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3574</td>\n",
       "      <td>2592</td>\n",
       "      <td>6166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>9371</td>\n",
       "      <td>4230</td>\n",
       "      <td>13601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  False  True    All\n",
       "Actual                       \n",
       "False       5797  1638   7435\n",
       "True        3574  2592   6166\n",
       "All         9371  4230  13601"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the confusion Matrix\n",
    "df_confusion = pd.crosstab(y, X_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011252955082742247"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_all_seasons.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEASON 2016/2017 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply on current season that is not use for train and test set\n",
    "X_pred_current_season = clf.predict(X_current_season)\n",
    "X_prob_current_season = clf.predict_proba(X_current_season)\n",
    "df_current_season['pred'] = X_pred_current_season\n",
    "df_current_season['prob'] = X_prob_current_season[:,1:]\n",
    "df_current_season['prob_less_bet'] = df_current_season['prob'] - df_current_season[odd].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_current_season.drop(df_current_season[df_current_season.pred == 0].index)\n",
    "df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "# df_bet_away_current_season = df_bet_away_current_season[df_bet_away_current_season[odd] > 2]\n",
    "# df_bet_away_current_season = df_bet_away_current_season[df_bet_away_current_season[odd] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 194)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many bet I did\n",
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4426,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many matches was play\n",
    "X_pred_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    53.211009\n",
       "D    23.669725\n",
       "A    23.119266\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.375474772984182"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross-entropy score\n",
    "log_loss(y_current_season, X_pred_current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62528912875867382, 0.3977439921530162, 0.48621103117505993, None)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score for this current season\n",
    "precision_recall_fscore_support(y_current_season, X_pred_current_season, average='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1901</td>\n",
       "      <td>486</td>\n",
       "      <td>2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1228</td>\n",
       "      <td>811</td>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3129</td>\n",
       "      <td>1297</td>\n",
       "      <td>4426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  False  True   All\n",
       "Actual                      \n",
       "False       1901   486  2387\n",
       "True        1228   811  2039\n",
       "All         3129  1297  4426"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the confusion Matrix\n",
    "df_confusion = pd.crosstab(y_current_season, X_pred_current_season, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07170642201834858"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What I win/lost on each match\n",
    "df_bet_current_season.INFO_WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.707949113338473"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.INFO_BbAvH.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_MEANS_FIVE_AC</th>\n",
       "      <th>A_MEANS_FIVE_AF</th>\n",
       "      <th>A_MEANS_FIVE_AR</th>\n",
       "      <th>A_MEANS_FIVE_AS</th>\n",
       "      <th>A_MEANS_FIVE_AST</th>\n",
       "      <th>A_MEANS_FIVE_AY</th>\n",
       "      <th>A_MEANS_FIVE_FTAG</th>\n",
       "      <th>A_MEANS_FIVE_FTHG</th>\n",
       "      <th>A_MEANS_FIVE_FTR_A</th>\n",
       "      <th>A_MEANS_FIVE_FTR_D</th>\n",
       "      <th>...</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>INFO_HTR</th>\n",
       "      <th>INFO_HomeTeam</th>\n",
       "      <th>INFO_PSA</th>\n",
       "      <th>INFO_PSD</th>\n",
       "      <th>INFO_PSH</th>\n",
       "      <th>INFO_WIN</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>prob_less_bet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Fiorentina</td>\n",
       "      <td>14.26</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>0.775782</td>\n",
       "      <td>-0.030669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <td>3.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Lazio</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.03</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.080027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19937</th>\n",
       "      <td>2.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Derby</td>\n",
       "      <td>5.76</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>True</td>\n",
       "      <td>0.654031</td>\n",
       "      <td>0.040534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19940</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>10.16</td>\n",
       "      <td>5.27</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>True</td>\n",
       "      <td>0.645378</td>\n",
       "      <td>-0.084549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19941</th>\n",
       "      <td>3.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Milton Keynes Dons</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.662764</td>\n",
       "      <td>0.188830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19943</th>\n",
       "      <td>7.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Reading</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.539034</td>\n",
       "      <td>-0.063376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615938</td>\n",
       "      <td>0.069490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19952</th>\n",
       "      <td>5.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>22.40</td>\n",
       "      <td>12.40</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691617</td>\n",
       "      <td>-0.209284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19955</th>\n",
       "      <td>1.6</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.726159</td>\n",
       "      <td>0.050484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19958</th>\n",
       "      <td>5.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.18</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520458</td>\n",
       "      <td>0.065912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>4.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Man United</td>\n",
       "      <td>12.05</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>True</td>\n",
       "      <td>0.539545</td>\n",
       "      <td>-0.212334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19967</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.64</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625268</td>\n",
       "      <td>0.015512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Lille</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566706</td>\n",
       "      <td>-0.025010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>7.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>18.52</td>\n",
       "      <td>7.80</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>True</td>\n",
       "      <td>0.632677</td>\n",
       "      <td>-0.214780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>3.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Milan</td>\n",
       "      <td>5.84</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.69</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.021384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>4.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Celta</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.86</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.634949</td>\n",
       "      <td>0.097315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>3.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Eibar</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.550594</td>\n",
       "      <td>0.074403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>Malaga</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.584685</td>\n",
       "      <td>0.066551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>True</td>\n",
       "      <td>0.510783</td>\n",
       "      <td>-0.174149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>4.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.97</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.717462</td>\n",
       "      <td>-0.045897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>4.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.562011</td>\n",
       "      <td>-0.040399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>4.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>True</td>\n",
       "      <td>0.575097</td>\n",
       "      <td>0.056963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>3.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>5.16</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.514360</td>\n",
       "      <td>-0.073876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>4.4</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Napoli</td>\n",
       "      <td>14.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700711</td>\n",
       "      <td>-0.099289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>6.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Roma</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.96</td>\n",
       "      <td>True</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.056532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>4.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>7.95</td>\n",
       "      <td>4.62</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>True</td>\n",
       "      <td>0.530031</td>\n",
       "      <td>-0.159624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>16.00</td>\n",
       "      <td>6.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>True</td>\n",
       "      <td>0.607107</td>\n",
       "      <td>-0.212565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>4.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>10.34</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644945</td>\n",
       "      <td>-0.112630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20016</th>\n",
       "      <td>5.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.577474</td>\n",
       "      <td>0.191374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <td>3.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Bradford</td>\n",
       "      <td>8.06</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>True</td>\n",
       "      <td>0.536382</td>\n",
       "      <td>-0.148550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25199</th>\n",
       "      <td>5.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Man City</td>\n",
       "      <td>23.10</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>-0.193153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25203</th>\n",
       "      <td>4.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>13.50</td>\n",
       "      <td>7.46</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628350</td>\n",
       "      <td>-0.204983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25211</th>\n",
       "      <td>2.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>14.30</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>True</td>\n",
       "      <td>0.712676</td>\n",
       "      <td>-0.134782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25212</th>\n",
       "      <td>2.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>11.81</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>0.582030</td>\n",
       "      <td>-0.251304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>2.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>8.06</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.39</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.663752</td>\n",
       "      <td>-0.076989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>4.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>9.02</td>\n",
       "      <td>5.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611634</td>\n",
       "      <td>-0.134634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25220</th>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Angers</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545622</td>\n",
       "      <td>0.071688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25221</th>\n",
       "      <td>2.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Guingamp</td>\n",
       "      <td>5.35</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644917</td>\n",
       "      <td>0.042508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25225</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>10.02</td>\n",
       "      <td>5.89</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.598525</td>\n",
       "      <td>-0.164834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25227</th>\n",
       "      <td>2.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>15.44</td>\n",
       "      <td>8.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619653</td>\n",
       "      <td>-0.220683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25231</th>\n",
       "      <td>6.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Napoli</td>\n",
       "      <td>10.77</td>\n",
       "      <td>6.39</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>True</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>-0.255031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25234</th>\n",
       "      <td>1.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>17.22</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>True</td>\n",
       "      <td>0.790467</td>\n",
       "      <td>-0.086726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>3.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>7.75</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>True</td>\n",
       "      <td>0.638871</td>\n",
       "      <td>-0.065354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>5.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>21.02</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.770394</td>\n",
       "      <td>-0.099172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>2.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628652</td>\n",
       "      <td>0.107819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>2.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>27.82</td>\n",
       "      <td>9.31</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.705446</td>\n",
       "      <td>-0.187411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Man United</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.48</td>\n",
       "      <td>True</td>\n",
       "      <td>0.657796</td>\n",
       "      <td>0.254570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>4.4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.68</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.06</td>\n",
       "      <td>True</td>\n",
       "      <td>0.582884</td>\n",
       "      <td>0.097447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25251</th>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>22.02</td>\n",
       "      <td>7.40</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>True</td>\n",
       "      <td>0.665926</td>\n",
       "      <td>-0.181532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25252</th>\n",
       "      <td>7.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Lazio</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2.04</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.536793</td>\n",
       "      <td>0.039280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25253</th>\n",
       "      <td>3.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Milan</td>\n",
       "      <td>9.25</td>\n",
       "      <td>5.27</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624170</td>\n",
       "      <td>-0.105757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25255</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.11</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.585116</td>\n",
       "      <td>0.104346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25257</th>\n",
       "      <td>4.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>40.35</td>\n",
       "      <td>15.58</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.717051</td>\n",
       "      <td>-0.235330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25260</th>\n",
       "      <td>4.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.11</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>0.352320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261</th>\n",
       "      <td>5.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>13.92</td>\n",
       "      <td>7.27</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693621</td>\n",
       "      <td>-0.139713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25265</th>\n",
       "      <td>2.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Atalanta</td>\n",
       "      <td>10.75</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>True</td>\n",
       "      <td>0.599373</td>\n",
       "      <td>-0.188029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25269</th>\n",
       "      <td>4.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Fiorentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.575368</td>\n",
       "      <td>-0.294197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Inter</td>\n",
       "      <td>8.51</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.36</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587883</td>\n",
       "      <td>-0.147411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25272</th>\n",
       "      <td>4.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>Roma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564206</td>\n",
       "      <td>-0.388175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25274</th>\n",
       "      <td>4.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>Torino</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>True</td>\n",
       "      <td>0.553908</td>\n",
       "      <td>-0.063375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1297 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A_MEANS_FIVE_AC  A_MEANS_FIVE_AF  A_MEANS_FIVE_AR  A_MEANS_FIVE_AS  \\\n",
       "19922              4.2             15.4              0.0             13.4   \n",
       "19924              3.6             18.6              0.4             11.2   \n",
       "19937              2.2             13.2              0.0              8.0   \n",
       "19940              3.0             13.0              0.0             10.2   \n",
       "19941              3.4             11.8              0.2              7.6   \n",
       "19943              7.2             10.0              0.2             11.0   \n",
       "19946              4.0             12.0              0.0              9.0   \n",
       "19952              5.4             17.6              0.2             14.4   \n",
       "19955              1.6             10.4              0.0             10.2   \n",
       "19958              5.8              9.6              0.4             10.4   \n",
       "19960              4.4              9.8              0.0              9.2   \n",
       "19967              5.0              9.2              0.0              8.4   \n",
       "19977              2.2             10.0              0.6              7.4   \n",
       "19980              7.2             11.8              0.2             10.4   \n",
       "19982              3.6             16.6              0.6              8.2   \n",
       "19984              4.2             11.0              0.0             10.4   \n",
       "19985              3.2             14.4              0.4              9.0   \n",
       "19987              3.0             12.6              0.2              7.8   \n",
       "19989              4.0              8.0              0.0              9.4   \n",
       "19995              4.8             16.6              0.2             12.2   \n",
       "19998              4.4             15.8              0.0             12.2   \n",
       "20000              4.4             17.2              0.0             12.2   \n",
       "20001              3.4              9.4              0.4              9.8   \n",
       "20004              4.4             13.8              0.0              9.8   \n",
       "20006              6.8             15.0              0.4             10.6   \n",
       "20010              4.4             15.8              0.4             10.2   \n",
       "20011              3.0             15.8              0.2              6.8   \n",
       "20012              4.8             18.4              0.4              6.6   \n",
       "20016              5.4             10.2              0.2              9.4   \n",
       "20017              3.8              6.8              0.0              6.0   \n",
       "...                ...              ...              ...              ...   \n",
       "25199              5.2             13.4              0.0              9.0   \n",
       "25203              4.2             12.8              0.4             10.4   \n",
       "25211              2.2             15.8              0.0             10.6   \n",
       "25212              2.4             11.0              0.0             10.0   \n",
       "25217              2.4             12.4              0.0              8.2   \n",
       "25219              4.6             13.0              0.4              9.8   \n",
       "25220              5.6              9.0              0.2             12.0   \n",
       "25221              2.4             12.0              0.2              8.8   \n",
       "25225              5.0             11.0              0.4              8.0   \n",
       "25227              2.4              9.8              0.2             11.2   \n",
       "25231              6.2             14.4              0.4             16.2   \n",
       "25234              1.2             11.8              0.0              7.0   \n",
       "25239              3.8             14.0              0.2              8.0   \n",
       "25241              5.4             10.0              0.0             10.8   \n",
       "25243              2.6              9.2              0.2              8.4   \n",
       "25244              2.4             16.6              0.2              7.0   \n",
       "25245              5.0             11.0              0.0              9.4   \n",
       "25247              4.4             12.8              0.0              8.4   \n",
       "25251              6.0             13.0              0.0             11.4   \n",
       "25252              7.8             14.8              0.2             15.8   \n",
       "25253              3.4             15.0              0.2              8.0   \n",
       "25255              3.0              9.4              0.2             10.4   \n",
       "25257              4.2             13.8              0.2              9.6   \n",
       "25260              4.4             14.2              0.2              7.8   \n",
       "25261              5.0             14.4              0.4             10.6   \n",
       "25265              2.8             14.8              0.2             10.4   \n",
       "25269              4.4             14.4              0.0             12.0   \n",
       "25270              5.0             12.2              0.0              8.8   \n",
       "25272              4.4             16.2              0.0             10.6   \n",
       "25274              4.8             12.2              0.0              9.0   \n",
       "\n",
       "       A_MEANS_FIVE_AST  A_MEANS_FIVE_AY  A_MEANS_FIVE_FTAG  \\\n",
       "19922               3.8              3.0                0.2   \n",
       "19924               2.4              3.2                0.8   \n",
       "19937               2.6              1.8                0.6   \n",
       "19940               4.0              1.4                1.0   \n",
       "19941               2.8              1.8                0.4   \n",
       "19943               3.4              2.0                0.6   \n",
       "19946               4.0              1.6                0.6   \n",
       "19952               6.4              2.8                2.2   \n",
       "19955               5.0              1.4                1.6   \n",
       "19958               3.6              1.6                0.2   \n",
       "19960               3.4              2.8                0.6   \n",
       "19967               2.4              2.6                0.4   \n",
       "19977               1.6              1.6                0.4   \n",
       "19980               4.2              2.4                0.8   \n",
       "19982               2.0              3.0                0.6   \n",
       "19984               3.2              3.8                0.6   \n",
       "19985               2.0              3.0                0.2   \n",
       "19987               3.0              2.2                1.0   \n",
       "19989               4.8              1.6                0.4   \n",
       "19995               4.4              2.6                1.2   \n",
       "19998               4.8              1.6                1.2   \n",
       "20000               4.6              1.6                1.0   \n",
       "20001               5.2              2.0                2.6   \n",
       "20004               3.2              2.4                1.0   \n",
       "20006               2.4              2.4                0.8   \n",
       "20010               3.6              3.4                1.4   \n",
       "20011               2.0              3.0                1.2   \n",
       "20012               2.8              2.6                1.0   \n",
       "20016               2.8              1.2                0.6   \n",
       "20017               2.6              1.4                0.8   \n",
       "...                 ...              ...                ...   \n",
       "25199               2.2              2.8                0.8   \n",
       "25203               4.2              0.8                0.8   \n",
       "25211               3.4              1.2                0.8   \n",
       "25212               4.6              1.8                3.0   \n",
       "25217               2.6              1.4                0.4   \n",
       "25219               2.8              1.6                0.8   \n",
       "25220               3.2              1.0                0.8   \n",
       "25221               3.8              1.4                1.0   \n",
       "25225               1.8              1.6                0.4   \n",
       "25227               3.0              1.4                1.2   \n",
       "25231               5.0              2.0                1.0   \n",
       "25234               3.4              2.2                0.6   \n",
       "25239               2.8              2.4                0.8   \n",
       "25241               3.4              2.0                0.4   \n",
       "25243               2.8              1.2                0.8   \n",
       "25244               2.0              2.0                0.4   \n",
       "25245               3.0              1.8                1.4   \n",
       "25247               2.0              2.8                0.6   \n",
       "25251               3.8              2.6                1.2   \n",
       "25252               5.6              1.0                2.4   \n",
       "25253               3.0              2.8                0.8   \n",
       "25255               4.2              1.8                1.6   \n",
       "25257               4.0              3.0                1.0   \n",
       "25260               3.2              3.6                0.8   \n",
       "25261               3.6              2.2                0.2   \n",
       "25265               2.4              2.6                0.8   \n",
       "25269               4.2              2.6                0.6   \n",
       "25270               3.4              2.4                1.0   \n",
       "25272               2.8              1.6                0.4   \n",
       "25274               3.4              2.2                1.4   \n",
       "\n",
       "       A_MEANS_FIVE_FTHG  A_MEANS_FIVE_FTR_A  A_MEANS_FIVE_FTR_D  \\\n",
       "19922                1.4                 0.0                 0.2   \n",
       "19924                1.4                 0.2                 0.2   \n",
       "19937                1.6                 0.2                 0.2   \n",
       "19940                1.6                 0.2                 0.2   \n",
       "19941                2.2                 0.0                 0.0   \n",
       "19943                1.6                 0.2                 0.2   \n",
       "19946                2.0                 0.0                 0.2   \n",
       "19952                2.4                 0.2                 0.2   \n",
       "19955                2.6                 0.4                 0.0   \n",
       "19958                2.6                 0.0                 0.2   \n",
       "19960                0.4                 0.6                 0.2   \n",
       "19967                2.0                 0.0                 0.2   \n",
       "19977                2.2                 0.0                 0.0   \n",
       "19980                2.4                 0.0                 0.4   \n",
       "19982                2.0                 0.2                 0.2   \n",
       "19984                1.2                 0.2                 0.2   \n",
       "19985                2.2                 0.0                 0.2   \n",
       "19987                1.4                 0.4                 0.4   \n",
       "19989                3.2                 0.0                 0.0   \n",
       "19995                1.2                 0.6                 0.0   \n",
       "19998                0.8                 0.6                 0.0   \n",
       "20000                1.2                 0.6                 0.0   \n",
       "20001                1.4                 0.6                 0.2   \n",
       "20004                1.4                 0.4                 0.2   \n",
       "20006                2.8                 0.2                 0.0   \n",
       "20010                2.4                 0.4                 0.0   \n",
       "20011                1.6                 0.4                 0.2   \n",
       "20012                0.6                 0.4                 0.4   \n",
       "20016                2.4                 0.2                 0.0   \n",
       "20017                0.8                 0.4                 0.4   \n",
       "...                  ...                 ...                 ...   \n",
       "25199                1.8                 0.0                 0.6   \n",
       "25203                1.2                 0.4                 0.2   \n",
       "25211                1.8                 0.4                 0.2   \n",
       "25212                2.2                 0.4                 0.4   \n",
       "25217                3.0                 0.0                 0.2   \n",
       "25219                2.0                 0.2                 0.0   \n",
       "25220                2.0                 0.2                 0.0   \n",
       "25221                3.0                 0.2                 0.2   \n",
       "25225                2.8                 0.2                 0.0   \n",
       "25227                1.0                 0.4                 0.4   \n",
       "25231                1.2                 0.2                 0.6   \n",
       "25234                3.2                 0.2                 0.0   \n",
       "25239                1.6                 0.0                 0.4   \n",
       "25241                1.2                 0.2                 0.0   \n",
       "25243                1.4                 0.2                 0.6   \n",
       "25244                2.6                 0.0                 0.2   \n",
       "25245                2.0                 0.6                 0.0   \n",
       "25247                2.0                 0.0                 0.4   \n",
       "25251                1.2                 0.6                 0.2   \n",
       "25252                2.2                 0.2                 0.2   \n",
       "25253                1.4                 0.2                 0.2   \n",
       "25255                2.2                 0.4                 0.2   \n",
       "25257                1.0                 0.4                 0.2   \n",
       "25260                1.4                 0.4                 0.0   \n",
       "25261                1.2                 0.0                 0.2   \n",
       "25265                2.4                 0.2                 0.2   \n",
       "25269                2.2                 0.0                 0.2   \n",
       "25270                2.2                 0.2                 0.2   \n",
       "25272                1.8                 0.2                 0.0   \n",
       "25274                1.2                 0.4                 0.4   \n",
       "\n",
       "           ...        INFO_FTR  INFO_HTR       INFO_HomeTeam  INFO_PSA  \\\n",
       "19922      ...               H         H          Fiorentina     14.26   \n",
       "19924      ...               A         A               Lazio      4.17   \n",
       "19937      ...               H         D               Derby      5.76   \n",
       "19940      ...               H         H       Middlesbrough     10.16   \n",
       "19941      ...               H         H  Milton Keynes Dons      3.54   \n",
       "19943      ...               D         A             Reading      6.08   \n",
       "19946      ...               H         H            Coventry      4.45   \n",
       "19952      ...               H         H       Bayern Munich     22.40   \n",
       "19955      ...               A         D          Leverkusen      6.89   \n",
       "19958      ...               A         A         Bournemouth      3.57   \n",
       "19960      ...               H         D          Man United     12.05   \n",
       "19967      ...               H         H            Brighton      5.87   \n",
       "19977      ...               D         D               Lille      6.00   \n",
       "19980      ...               H         H            Paris SG     18.52   \n",
       "19982      ...               D         D               Milan      5.84   \n",
       "19984      ...               A         A               Celta      4.46   \n",
       "19985      ...               H         H               Eibar      4.05   \n",
       "19987      ...               A         D              Malaga      4.43   \n",
       "19989      ...               H         D            Aberdeen      7.00   \n",
       "19995      ...               H         H            Dortmund      9.00   \n",
       "19998      ...               A         D           Liverpool      5.73   \n",
       "20000      ...               H         H                Lyon      4.07   \n",
       "20001      ...               A         A           Marseille      5.16   \n",
       "20004      ...               H         D              Napoli     14.00   \n",
       "20006      ...               H         H                Roma      3.91   \n",
       "20010      ...               H         H          Ath Bilbao      7.95   \n",
       "20011      ...               H         D          Ath Madrid     16.00   \n",
       "20012      ...               H         D           Barcelona     10.34   \n",
       "20016      ...               A         A           Blackpool      2.85   \n",
       "20017      ...               H         H            Bradford      8.06   \n",
       "...        ...             ...       ...                 ...       ...   \n",
       "25199      ...               H         H            Man City     23.10   \n",
       "25203      ...               H         H              Monaco     13.50   \n",
       "25211      ...               H         H       Bayern Munich     14.30   \n",
       "25212      ...               H         H            Dortmund     11.81   \n",
       "25217      ...               D         D          Hoffenheim      8.06   \n",
       "25219      ...               D         D          M'gladbach      9.02   \n",
       "25220      ...               H         D              Angers      3.66   \n",
       "25221      ...               H         H            Guingamp      5.35   \n",
       "25225      ...               H         D           Marseille     10.02   \n",
       "25227      ...               D         H            Paris SG     15.44   \n",
       "25231      ...               H         H              Napoli     10.77   \n",
       "25234      ...               H         H             Sevilla     17.22   \n",
       "25239      ...               H         H             Arsenal      7.75   \n",
       "25241      ...               H         D             Chelsea     21.02   \n",
       "25243      ...               D         A           Leicester      4.35   \n",
       "25244      ...               H         H           Liverpool     27.82   \n",
       "25245      ...               H         H          Man United      3.14   \n",
       "25247      ...               H         A             Swansea      3.67   \n",
       "25251      ...               H         H            Juventus     22.02   \n",
       "25252      ...               A         A               Lazio      3.63   \n",
       "25253      ...               H         D               Milan      9.25   \n",
       "25255      ...               D         H             Udinese      3.81   \n",
       "25257      ...               H         A           Barcelona     40.35   \n",
       "25260      ...               A         A            Valencia      2.32   \n",
       "25261      ...               H         D              Celtic     13.92   \n",
       "25265      ...               H         D            Atalanta     10.75   \n",
       "25269      ...               D         A          Fiorentina       NaN   \n",
       "25270      ...               H         H               Inter      8.51   \n",
       "25272      ...               H         D                Roma       NaN   \n",
       "25274      ...               H         H              Torino      5.04   \n",
       "\n",
       "       INFO_PSD  INFO_PSH  INFO_WIN  pred      prob  prob_less_bet  \n",
       "19922      6.25      1.27      0.24  True  0.775782      -0.030669  \n",
       "19924      3.47      2.03     -1.00  True  0.577540       0.080027  \n",
       "19937      4.20      1.63      0.63  True  0.654031       0.040534  \n",
       "19940      5.27      1.36      0.37  True  0.645378      -0.084549  \n",
       "19941      3.45      2.20      1.11  True  0.662764       0.188830  \n",
       "19943      4.06      1.63     -1.00  True  0.539034      -0.063376  \n",
       "19946      3.80      1.86      0.83  True  0.615938       0.069490  \n",
       "19952     12.40      1.12      0.11  True  0.691617      -0.209284  \n",
       "19955      4.72      1.51     -1.00  True  0.726159       0.050484  \n",
       "19958      3.56      2.18     -1.00  True  0.520458       0.065912  \n",
       "19960      5.25      1.34      0.33  True  0.539545      -0.212334  \n",
       "19967      3.93      1.67      0.64  True  0.625268       0.015512  \n",
       "19977      3.64      1.71     -1.00  True  0.566706      -0.025010  \n",
       "19980      7.80      1.19      0.18  True  0.632677      -0.214780  \n",
       "19982      3.88      1.69     -1.00  True  0.623794       0.021384  \n",
       "19984      3.87      1.86     -1.00  True  0.634949       0.097315  \n",
       "19985      3.27      2.14      1.10  True  0.550594       0.074403  \n",
       "19987      3.64      1.93     -1.00  True  0.584685       0.066551  \n",
       "19989      4.67      1.50      0.46  True  0.510783      -0.174149  \n",
       "19995      5.97      1.35      0.31  True  0.717462      -0.045897  \n",
       "19998      3.99      1.68     -1.00  True  0.562011      -0.040399  \n",
       "20000      3.66      1.97      0.93  True  0.575097       0.056963  \n",
       "20001      4.08      1.70     -1.00  True  0.514360      -0.073876  \n",
       "20004      6.70      1.25      0.25  True  0.700711      -0.099289  \n",
       "20006      3.67      2.03      0.96  True  0.566736       0.056532  \n",
       "20010      4.62      1.48      0.45  True  0.530031      -0.159624  \n",
       "20011      6.33      1.25      0.22  True  0.607107      -0.212565  \n",
       "20012      5.80      1.33      0.32  True  0.644945      -0.112630  \n",
       "20016      3.31      2.69     -1.00  True  0.577474       0.191374  \n",
       "20017      4.42      1.48      0.46  True  0.536382      -0.148550  \n",
       "...         ...       ...       ...   ...       ...            ...  \n",
       "25199     10.39      1.14      0.13  True  0.691803      -0.193153  \n",
       "25203      7.46      1.22      0.20  True  0.628350      -0.204983  \n",
       "25211      8.70      1.20      0.18  True  0.712676      -0.134782  \n",
       "25212      8.38      1.23      0.20  True  0.582030      -0.251304  \n",
       "25217      5.68      1.39     -1.00  True  0.663752      -0.076989  \n",
       "25219      5.86      1.35     -1.00  True  0.611634      -0.134634  \n",
       "25220      3.60      2.11      1.11  True  0.545622       0.071688  \n",
       "25221      4.09      1.68      0.66  True  0.644917       0.042508  \n",
       "25225      5.89      1.32      0.31  True  0.598525      -0.164834  \n",
       "25227      8.01      1.20     -1.00  True  0.619653      -0.220683  \n",
       "25231      6.39      1.30      0.27  True  0.532370      -0.255031  \n",
       "25234      9.71      1.16      0.14  True  0.790467      -0.086726  \n",
       "25239      5.29      1.42      0.42  True  0.638871      -0.065354  \n",
       "25241      9.01      1.16      0.15  True  0.770394      -0.099172  \n",
       "25243      3.75      1.91     -1.00  True  0.628652       0.107819  \n",
       "25244      9.31      1.14      0.12  True  0.705446      -0.187411  \n",
       "25245      3.40      2.44      1.48  True  0.657796       0.254570  \n",
       "25247      3.68      2.10      1.06  True  0.582884       0.097447  \n",
       "25251      7.40      1.19      0.18  True  0.665926      -0.181532  \n",
       "25252      3.95      2.04     -1.00  True  0.536793       0.039280  \n",
       "25253      5.27      1.38      0.37  True  0.624170      -0.105757  \n",
       "25255      3.52      2.11     -1.00  True  0.585116       0.104346  \n",
       "25257     15.58      1.07      0.05  True  0.717051      -0.235330  \n",
       "25260      3.74      3.11     -1.00  True  0.685653       0.352320  \n",
       "25261      7.27      1.22      0.20  True  0.693621      -0.139713  \n",
       "25265      6.55      1.28      0.27  True  0.599373      -0.188029  \n",
       "25269       NaN       NaN     -1.00  True  0.575368      -0.294197  \n",
       "25270      5.60      1.37      0.36  True  0.587883      -0.147411  \n",
       "25272       NaN       NaN      0.05  True  0.564206      -0.388175  \n",
       "25274      4.51      1.65      0.62  True  0.553908      -0.063375  \n",
       "\n",
       "[1297 rows x 194 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_bet_current_season.to_csv('SVM_2016_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2a89d0937e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Learning Curve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-2a89d0937e38>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(\n\u001b[0;32m---> 16\u001b[0;31m         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1')\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             verbose, parameters=None, fit_params=None, return_train_score=True)\n\u001b[0;32m--> 772\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m             for n_train_samples in train_sizes_abs)\n\u001b[1;32m    774\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plot a leqrning curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(clf, 'Learning Curve', X, y, cv=4, n_jobs=-1).show()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

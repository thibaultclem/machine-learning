{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "#season_list = [2016]\n",
    "season_list = [2014, 2015, 2016]\n",
    "#league_list = ['D1', 'E0', 'E1', 'E2', 'F1', 'I1', 'SP1', 'SC0']\n",
    "league_list = ['D1']\n",
    "historical_training_year_list = [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'hidden_layer_sizes': (160, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 1.4,\n",
    "    'max_iter': 260\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\",\"INFO_Div\"]\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26988, 190)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (exclude)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month > 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, historical_training_year, features):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'].dt.month < 6) | (df_test['INFO_Date'].dt.month > 10)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    sc_X = StandardScaler().fit(X)\n",
    "    X = sc_X.transform(X)\n",
    "    X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(y, pred, probs):\n",
    "    # Compute cross-entropy score\n",
    "    ll = log_loss(y, probs)\n",
    "    # Compute accuracy score\n",
    "    acc = accuracy_score(y, pred)\n",
    "    # Compute precision score\n",
    "    prec = precision_score(y, pred, average=None)\n",
    "    prec_A = prec[0]\n",
    "    prec_D = prec[1]\n",
    "    prec_H = prec[2]\n",
    "    # Compute recall score\n",
    "    rec = recall_score(y, pred, average=None)\n",
    "    rec_A = rec[0]\n",
    "    rec_D = rec[1]\n",
    "    rec_H = rec[2]\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y, pred, average=None)\n",
    "    f1_A = f1[0]\n",
    "    f1_D = f1[1]\n",
    "    f1_H = f1[2]\n",
    "    return {\n",
    "        'll': ll, \n",
    "        'acc': acc, \n",
    "        'prec_A': prec_A, \n",
    "        'prec_D': prec_D, \n",
    "        'prec_H': prec_H, \n",
    "        'rec_A': rec_A, \n",
    "        'rec_D': rec_D, \n",
    "        'rec_H': rec_H, \n",
    "        'f1_A': f1_A, \n",
    "        'f1_D': f1_D, \n",
    "        'f1_H': f1_H\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_money(df_test, pred_season, prob_season):\n",
    "    # Join odd and prediction together\n",
    "    df_test_season = df_test\n",
    "    df_test_season['probs_A'] = prob_season[:,0]\n",
    "    df_test_season['probs_D'] = prob_season[:,1]\n",
    "    df_test_season['probs_H'] = prob_season[:,2]\n",
    "    df_test_season['probs'] = df_test_season[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "    df_test_season['pred'] = pred_season\n",
    "    df_test_season['WIN'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN'] = df_test_season['INFO_WIN']-1\n",
    "    df_test_season['WIN_P'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN_P'] = df_test_season['INFO_WIN_P']-1\n",
    "    df_test_season['INFO_ODD'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'INFO_ODD_BET'] = df_test_season[odd_A]\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'INFO_ODD_BET'] = df_test_season[odd_D]\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'INFO_ODD_BET'] = df_test_season[odd_H]\n",
    "    df_test_season['prob_less_bet'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_A].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_D].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_H].apply(lambda x: 1/x)\n",
    "    # calculate money I can get following different scenario\n",
    "    # Bet on all\n",
    "    bet_all = df_test_season.WIN.mean()\n",
    "    # Bet under 1.9\n",
    "    bet_lte_19 = df_test_season[df_test_season['INFO_ODD_BET'] < 1.9].WIN.mean()\n",
    "    # Bet under 4\n",
    "    bet_lte_4 = df_test_season[df_test_season['INFO_ODD_BET'] < 4].WIN.mean()\n",
    "    # Bet between 1.9 and 4\n",
    "    bet_btw_19_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.9 and 5\n",
    "    bet_btw_19_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet between 1.5 and 4\n",
    "    bet_btw_15_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.5 and 5\n",
    "    bet_btw_15_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet prob higher than 50%\n",
    "    bet_pred_gte_50 = df_test_season[df_test_season.probs > 0.5].WIN.mean()\n",
    "    # Bet prob higher than 60%\n",
    "    bet_pred_gte_60 = df_test_season[df_test_season.probs > 0.6].WIN.mean()\n",
    "    # Bet prob higher than 70%\n",
    "    bet_pred_gte_70 = df_test_season[df_test_season.probs > 0.7].WIN.mean()\n",
    "    return {\n",
    "        'bet_all': bet_all,\n",
    "        'bet_lte_19': bet_lte_19,\n",
    "        'bet_lte_4': bet_lte_4,\n",
    "        'bet_btw_19_4': bet_btw_19_4,\n",
    "        'bet_btw_19_5': bet_btw_19_5,\n",
    "        'bet_btw_15_4': bet_btw_15_4,\n",
    "        'bet_btw_15_5': bet_btw_15_5,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season', \n",
    "    'historical_training_year', \n",
    "    'features',\n",
    "    'hidden_layer_sizes',\n",
    "    'activation',\n",
    "    'solver',\n",
    "    'alpha',\n",
    "    'max_iter',\n",
    "    'll',\n",
    "    'acc',\n",
    "    'prec_A',\n",
    "    'prec_D',\n",
    "    'prec_H',\n",
    "    'rec_A',\n",
    "    'rec_D',\n",
    "    'rec_H',\n",
    "    'f1_A',\n",
    "    'f1_D',\n",
    "    'f1_H',\n",
    "    'bet_all',\n",
    "    'bet_lte_19',\n",
    "    'bet_lte_4',\n",
    "    'bet_btw_19_4',\n",
    "    'bet_btw_19_5',\n",
    "    'bet_btw_15_4',\n",
    "    'bet_btw_15_5'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 2014 9 best_features_MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 2015 9 best_features_MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 2016 9 best_features_MLP\n"
     ]
    }
   ],
   "source": [
    "for league in league_list:\n",
    "    for season in season_list:\n",
    "        for historical_training_year in historical_training_year_list:\n",
    "            for features in features_list:\n",
    "                print league,str(season),str(historical_training_year),features[0]\n",
    "                df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, historical_training_year, features[1])\n",
    "                # train model\n",
    "                clf = MLPClassifier(\n",
    "                    random_state=0 ,\n",
    "                    hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "                    activation=best_params['activation'],\n",
    "                    solver=best_params['solver'],\n",
    "                    alpha=best_params['alpha'],\n",
    "                    max_iter=best_params['max_iter']\n",
    "                )\n",
    "                clf.fit(X, y)\n",
    "                # Predict target values\n",
    "                y_pred = clf.predict(X_test_season)\n",
    "                # Predict probabilities\n",
    "                y_probs = clf.predict_proba(X_test_season)\n",
    "                # get scores\n",
    "                score_dict = get_score(y_test_season, y_pred, y_probs)\n",
    "                # get money earned\n",
    "                money_dict = get_money(df_test, y_pred, y_probs)\n",
    "                # Keep result for further analyis\n",
    "                df_result = df_result.append(df_test)\n",
    "                # Add all info to result dataframe\n",
    "                result_df.loc[len(result_df.index)] = [\n",
    "                    league, \n",
    "                    season, \n",
    "                    historical_training_year, \n",
    "                    features[0],\n",
    "                    best_params['hidden_layer_sizes'],\n",
    "                    best_params['activation'],\n",
    "                    best_params['solver'],\n",
    "                    best_params['alpha'],\n",
    "                    best_params['max_iter'],\n",
    "                    score_dict['ll'],\n",
    "                    score_dict['acc'],\n",
    "                    score_dict['prec_A'],\n",
    "                    score_dict['prec_D'],\n",
    "                    score_dict['prec_H'],\n",
    "                    score_dict['rec_A'],\n",
    "                    score_dict['rec_D'],\n",
    "                    score_dict['rec_H'],\n",
    "                    score_dict['f1_A'],\n",
    "                    score_dict['f1_D'],\n",
    "                    score_dict['f1_H'],\n",
    "                    money_dict['bet_all'],\n",
    "                    money_dict['bet_lte_19'],\n",
    "                    money_dict['bet_lte_4'],\n",
    "                    money_dict['bet_btw_19_4'],\n",
    "                    money_dict['bet_btw_19_5'],\n",
    "                    money_dict['bet_btw_15_4'],\n",
    "                    money_dict['bet_btw_15_5']\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./report/MLP_FTR_BYLEAGUE_BEST_HYPERPARAM_LOG_LOSS_VALIDATION.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "\n",
    "- E0: 2_2016\n",
    "- E1: 1_2016\n",
    "- E2: 1_2015\n",
    "- D1: 1_2014 \n",
    "- F1: 1_2015\n",
    "- I1: 1_2016\n",
    "- SP1: 1_2016\n",
    "- SCO0: 1_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params_d1 = {\n",
    "    'hidden_layer_sizes': (160, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 1.4,\n",
    "    'max_iter': 260\n",
    "}\n",
    "\n",
    "best_params_e0 = {\n",
    "    'hidden_layer_sizes': (100, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 1.2,\n",
    "    'max_iter': 210\n",
    "}\n",
    "\n",
    "best_params_e1 = {\n",
    "    'hidden_layer_sizes': (70, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 2.3,\n",
    "    'max_iter': 180\n",
    "}\n",
    "\n",
    "best_params_e2 = {\n",
    "    'hidden_layer_sizes': (90, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 1.1,\n",
    "    'max_iter': 160\n",
    "}\n",
    "\n",
    "best_params_f1 = {\n",
    "    'hidden_layer_sizes': (170, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 1.3,\n",
    "    'max_iter': 150\n",
    "}\n",
    "\n",
    "best_params_i1 = {\n",
    "    'hidden_layer_sizes': (120, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 2.2,\n",
    "    'max_iter': 200\n",
    "}\n",
    "\n",
    "best_params_sp1 = {\n",
    "    'hidden_layer_sizes': (60, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 0.3,\n",
    "    'max_iter': 190\n",
    "}\n",
    "\n",
    "best_params_sc0 = {\n",
    "    'hidden_layer_sizes': (220, ),\n",
    "    'activation': 'logistic',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 0.8,\n",
    "    'max_iter': 270\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('./report/D1-nooct-last-3-seasons-MLP-9-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

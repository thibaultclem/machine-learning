{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "season_list = [2014, 2015, 2016]\n",
    "league = 'E1'\n",
    "classes = ['A', 'D', 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "best_features_NB = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP],\n",
    "    ['all_features', all_features],\n",
    "    ['best_features_NB', best_features_NB]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter for layer 1\n",
    "best_params = {\n",
    "    'C': 8.291,\n",
    "    'penalty': 'l2',\n",
    "    'class_weight': None,\n",
    "    'solver': 'sag',\n",
    "    'max_iter': 270,\n",
    "    'multi_class': 'multinomial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct base layer\n",
    "base_layer = [\n",
    "    ['XGBoost', False, 'no', 9, XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=160,\n",
    "        max_depth=8,\n",
    "        min_child_weight=7,\n",
    "        gamma=0.28,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6,\n",
    "        objective='multi:softprob',\n",
    "        reg_alpha=0.87,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=15), \n",
    "     ['all_features', all_features]\n",
    "    ],\n",
    "    ['NB', True, 'no', 9, GaussianNB(), ['best_features_NB', best_features_NB]],\n",
    "    ['MLP', True, 'no', 7, MLPClassifier(\n",
    "        random_state=0,\n",
    "        activation='logistic', \n",
    "        alpha=2.3, \n",
    "        hidden_layer_sizes=(70,),\n",
    "        max_iter=180, \n",
    "        solver='sgd'),\n",
    "     ['best_features_MLP', best_features_MLP]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure number of fold\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30912, 190)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month >= 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, calibration, historical_training_year, features):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'].dt.month < 6) | (df_test['INFO_Date'].dt.month > 10)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    # TODO drop NaN instead of replacing ith means \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    if calibration:\n",
    "        sc_X = StandardScaler().fit(X)\n",
    "        X = sc_X.transform(X)\n",
    "        X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out of fold prediction\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "    oof_train = np.zeros((x_train.shape[0],3))\n",
    "    oof_test = np.zeros((x_test.shape[0],3))\n",
    "    oof_test_skf = np.empty((NFOLDS, x_test.shape[0], 3))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        # Calibrate model\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_columns(layer, classes):\n",
    "    cols = []\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, clf, features in layer:\n",
    "        for result in classes:\n",
    "            cols.append(clf_name+result)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer1_df(X, X_test_season, base_layer, cols):\n",
    "    X_train_layer1 = np.zeros((X.shape[0], len(base_layer)*3))\n",
    "    X_train_layer1 = pd.DataFrame(X_train_layer1, columns=cols)\n",
    "    X_test_layer1 = np.zeros((X_test_season.shape[0], len(base_layer)*3))\n",
    "    X_test_layer1 = pd.DataFrame(X_test_layer1, columns=cols)\n",
    "    return X_train_layer1, X_test_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(y, pred, probs):\n",
    "    # Compute cross-entropy score\n",
    "    ll = log_loss(y, probs)\n",
    "    # Compute accuracy score\n",
    "    acc = accuracy_score(y, pred)\n",
    "    # Compute precision score\n",
    "    prec = precision_score(y, pred, average=None)\n",
    "    prec_A = prec[0]\n",
    "    prec_D = prec[1]\n",
    "    prec_H = prec[2]\n",
    "    # Compute recall score\n",
    "    rec = recall_score(y, pred, average=None)\n",
    "    rec_A = rec[0]\n",
    "    rec_D = rec[1]\n",
    "    rec_H = rec[2]\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y, pred, average=None)\n",
    "    f1_A = f1[0]\n",
    "    f1_D = f1[1]\n",
    "    f1_H = f1[2]\n",
    "    return {\n",
    "        'll': ll, \n",
    "        'acc': acc, \n",
    "        'prec_A': prec_A, \n",
    "        'prec_D': prec_D, \n",
    "        'prec_H': prec_H, \n",
    "        'rec_A': rec_A, \n",
    "        'rec_D': rec_D, \n",
    "        'rec_H': rec_H, \n",
    "        'f1_A': f1_A, \n",
    "        'f1_D': f1_D, \n",
    "        'f1_H': f1_H\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_money(df_test, pred_season, prob_season):\n",
    "    # Join odd and prediction together\n",
    "    df_test_season = df_test\n",
    "    df_test_season['probs_A'] = prob_season[:,0]\n",
    "    df_test_season['probs_D'] = prob_season[:,1]\n",
    "    df_test_season['probs_H'] = prob_season[:,2]\n",
    "    df_test_season['probs'] = df_test_season[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "    #df_test_season['pred'] = le.inverse_transform(pred_season)\n",
    "    df_test_season['pred'] = pred_season\n",
    "    df_test_season['WIN'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN'] = df_test_season['INFO_WIN']-1\n",
    "    df_test_season['WIN_P'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN_P'] = df_test_season['INFO_WIN_P']-1\n",
    "    df_test_season['INFO_ODD_BET'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'INFO_ODD_BET'] = df_test_season[odd_A]\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'INFO_ODD_BET'] = df_test_season[odd_D]\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'INFO_ODD_BET'] = df_test_season[odd_H]\n",
    "    df_test_season['prob_less_bet'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_A].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_D].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_H].apply(lambda x: 1/x)\n",
    "    # calculate money I can get following different scenario\n",
    "    # Bet on all\n",
    "    bet_all = df_test_season.WIN.mean()\n",
    "    # Bet under 1.9\n",
    "    bet_lte_19 = df_test_season[df_test_season['INFO_ODD_BET'] < 1.9].WIN.mean()\n",
    "    # Bet under 4\n",
    "    bet_lte_4 = df_test_season[df_test_season['INFO_ODD_BET'] < 4].WIN.mean()\n",
    "    # Bet between 1.9 and 4\n",
    "    bet_btw_19_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.9 and 5\n",
    "    bet_btw_19_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet between 1.5 and 4\n",
    "    bet_btw_15_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.5 and 5\n",
    "    bet_btw_15_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet prob higher than 50%\n",
    "    bet_pred_gte_50 = df_test_season[df_test_season.probs > 0.5].WIN.mean()\n",
    "    # Bet prob higher than 60%\n",
    "    bet_pred_gte_60 = df_test_season[df_test_season.probs > 0.6].WIN.mean()\n",
    "    # Bet prob higher than 70%\n",
    "    bet_pred_gte_70 = df_test_season[df_test_season.probs > 0.7].WIN.mean()\n",
    "    return {\n",
    "        'bet_all': bet_all,\n",
    "        'bet_lte_19': bet_lte_19,\n",
    "        'bet_lte_4': bet_lte_4,\n",
    "        'bet_btw_19_4': bet_btw_19_4,\n",
    "        'bet_btw_19_5': bet_btw_19_5,\n",
    "        'bet_btw_15_4': bet_btw_15_4,\n",
    "        'bet_btw_15_5': bet_btw_15_5\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season',\n",
    "    'C',\n",
    "    'penalty',\n",
    "    'class_weight',\n",
    "    'solver',\n",
    "    'max_iter',\n",
    "    'multi_class',\n",
    "    'll',\n",
    "    'acc',\n",
    "    'prec_A',\n",
    "    'prec_D',\n",
    "    'prec_H',\n",
    "    'rec_A',\n",
    "    'rec_D',\n",
    "    'rec_H',\n",
    "    'f1_A',\n",
    "    'f1_D',\n",
    "    'f1_H',\n",
    "    'bet_all',\n",
    "    'bet_lte_19',\n",
    "    'bet_lte_4',\n",
    "    'bet_btw_19_4',\n",
    "    'bet_btw_19_5',\n",
    "    'bet_btw_15_4',\n",
    "    'bet_btw_15_5'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 2014\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 2015\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n",
      "E1 2016\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n"
     ]
    }
   ],
   "source": [
    "for season in season_list:\n",
    "    print league,str(season)\n",
    "    \n",
    "    # Prepare the layer 1\n",
    "    df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, False, 9, all_features)\n",
    "    cols = get_layer_columns(base_layer, classes)\n",
    "    X_layer1, X_layer1_test_season = get_layer1_df(X, X_test_season, base_layer, cols)\n",
    "    \n",
    "    # train base layer\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, classifier, features in base_layer:\n",
    "        \n",
    "        #Get the dataset\n",
    "        df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, calibration, 9, features[1])\n",
    "        \n",
    "        print \"Processing model:\",clf_name\n",
    "        # Check if we need to recalibrate the prediction\n",
    "        if calibration == 'sigmoid':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "        elif calibration == 'isotonic':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "        elif calibration == 'no':\n",
    "            clf = classifier\n",
    "        # obtain out-of-fold predictions for this model\n",
    "        oof_train, oof_test = get_oof(clf, X, y, X_test_season)\n",
    "        X_layer1.loc[:, [clf_name+result for result in classes]] = oof_train\n",
    "        \n",
    "        # Base Layer for test season\n",
    "        #Get the dataset\n",
    "        df2, df_test, X2, y2, X_test_season, y_test_season = get_dataset(league, season, calibration, historical_training_year, features[1])\n",
    "        clf_test = classifier\n",
    "        clf_test.fit(X, y)\n",
    "        predict_probs_test = clf.predict_proba(X_test_season)\n",
    "        X_layer1_test_season.loc[:, [clf_name+result for result in classes]] = predict_probs_test\n",
    "\n",
    "    # train stacking model\n",
    "    clf_1 = LogisticRegression()\n",
    "    clf_1.fit(X_layer1, y)\n",
    "    # Predict target values\n",
    "    y_pred = clf_1.predict(X_layer1_test_season)\n",
    "    # Predict probabilities\n",
    "    y_probs = clf_1.predict_proba(X_layer1_test_season)\n",
    "    # get scores\n",
    "    score_dict = get_score(y_test_season, y_pred, y_probs)\n",
    "    # get money earned\n",
    "    money_dict = get_money(df_test, y_pred, y_probs)\n",
    "    # Keep result for further analyis\n",
    "    df_result = df_result.append(df_test)\n",
    "    # Add all info to result dataframe\n",
    "    result_df.loc[len(result_df.index)] = [\n",
    "        league, \n",
    "        season, \n",
    "        best_params['C'],\n",
    "        best_params['penalty'],\n",
    "        best_params['class_weight'],\n",
    "        best_params['solver'],\n",
    "        best_params['max_iter'],\n",
    "        best_params['multi_class'],\n",
    "        score_dict['ll'],\n",
    "        score_dict['acc'],\n",
    "        score_dict['prec_A'],\n",
    "        score_dict['prec_D'],\n",
    "        score_dict['prec_H'],\n",
    "        score_dict['rec_A'],\n",
    "        score_dict['rec_D'],\n",
    "        score_dict['rec_H'],\n",
    "        score_dict['f1_A'],\n",
    "        score_dict['f1_D'],\n",
    "        score_dict['f1_H'],\n",
    "        money_dict['bet_all'],\n",
    "        money_dict['bet_lte_19'],\n",
    "        money_dict['bet_lte_4'],\n",
    "        money_dict['bet_btw_19_4'],\n",
    "        money_dict['bet_btw_19_5'],\n",
    "        money_dict['bet_btw_15_4'],\n",
    "        money_dict['bet_btw_15_5']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result_df.to_csv('./report/STACKING_1_FTR_E0_BEST_VALIDATION.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('./report/E1-last-3-seasons-oct-7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "Best is with ??? and ??? years of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_result\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.probs <= 0.4].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred != 'H'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred == 'D'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.prob_less_bet <= 0].index)\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] > 2]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    76.382792\n",
       "A    23.617208\n",
       "Name: pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.pred.value_counts() / len(df_bet_current_season.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    44.073749\n",
       "A    29.587357\n",
       "D    26.338894\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05968393327480241"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03668129938542583"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 202)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_Date</th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>probs</th>\n",
       "      <th>prob_less_bet</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.347021</td>\n",
       "      <td>0.309792</td>\n",
       "      <td>0.343187</td>\n",
       "      <td>0.347021</td>\n",
       "      <td>0.083863</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.408577</td>\n",
       "      <td>0.283466</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.408577</td>\n",
       "      <td>-0.086473</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>0.280665</td>\n",
       "      <td>0.465033</td>\n",
       "      <td>0.465033</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.379230</td>\n",
       "      <td>0.294171</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.379230</td>\n",
       "      <td>-0.063248</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.220963</td>\n",
       "      <td>0.257720</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.423454</td>\n",
       "      <td>0.275772</td>\n",
       "      <td>0.300774</td>\n",
       "      <td>0.423454</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.245202</td>\n",
       "      <td>0.278066</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>0.070228</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.360879</td>\n",
       "      <td>0.296994</td>\n",
       "      <td>0.342127</td>\n",
       "      <td>0.360879</td>\n",
       "      <td>-0.059290</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.282838</td>\n",
       "      <td>0.279421</td>\n",
       "      <td>0.437741</td>\n",
       "      <td>0.437741</td>\n",
       "      <td>-0.091360</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.279059</td>\n",
       "      <td>0.261254</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>0.277134</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.442183</td>\n",
       "      <td>0.442183</td>\n",
       "      <td>-0.215711</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.472008</td>\n",
       "      <td>0.263924</td>\n",
       "      <td>0.264068</td>\n",
       "      <td>0.472008</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.365674</td>\n",
       "      <td>0.297452</td>\n",
       "      <td>0.336874</td>\n",
       "      <td>0.365674</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.255947</td>\n",
       "      <td>0.516374</td>\n",
       "      <td>0.516374</td>\n",
       "      <td>0.065924</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.344609</td>\n",
       "      <td>0.283807</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>-0.220132</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.387251</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.318129</td>\n",
       "      <td>0.387251</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.316071</td>\n",
       "      <td>0.282204</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.044703</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.373006</td>\n",
       "      <td>0.292020</td>\n",
       "      <td>0.334974</td>\n",
       "      <td>0.373006</td>\n",
       "      <td>0.042973</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.365008</td>\n",
       "      <td>0.289888</td>\n",
       "      <td>0.345104</td>\n",
       "      <td>0.365008</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.236259</td>\n",
       "      <td>0.250380</td>\n",
       "      <td>0.513361</td>\n",
       "      <td>0.513361</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.449760</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>0.449760</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>0.192929</td>\n",
       "      <td>0.257765</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>-0.100045</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>0.320524</td>\n",
       "      <td>0.279896</td>\n",
       "      <td>0.399580</td>\n",
       "      <td>0.399580</td>\n",
       "      <td>-0.093030</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>0.374552</td>\n",
       "      <td>0.296112</td>\n",
       "      <td>0.329336</td>\n",
       "      <td>0.374552</td>\n",
       "      <td>-0.023854</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.434671</td>\n",
       "      <td>0.285414</td>\n",
       "      <td>0.279915</td>\n",
       "      <td>0.434671</td>\n",
       "      <td>0.050056</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.324194</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>0.379254</td>\n",
       "      <td>0.379254</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.349622</td>\n",
       "      <td>0.295409</td>\n",
       "      <td>0.354969</td>\n",
       "      <td>0.354969</td>\n",
       "      <td>-0.135227</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.272210</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>-0.049402</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.324823</td>\n",
       "      <td>0.285525</td>\n",
       "      <td>0.389652</td>\n",
       "      <td>0.389652</td>\n",
       "      <td>-0.035880</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.207086</td>\n",
       "      <td>0.244481</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>-0.010226</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.228796</td>\n",
       "      <td>0.277371</td>\n",
       "      <td>0.493833</td>\n",
       "      <td>0.493833</td>\n",
       "      <td>-0.055618</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.265368</td>\n",
       "      <td>0.285432</td>\n",
       "      <td>0.449201</td>\n",
       "      <td>0.449201</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.278375</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.430921</td>\n",
       "      <td>0.430921</td>\n",
       "      <td>-0.029909</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0.316927</td>\n",
       "      <td>0.292390</td>\n",
       "      <td>0.390683</td>\n",
       "      <td>0.390683</td>\n",
       "      <td>-0.135632</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>0.198036</td>\n",
       "      <td>0.268787</td>\n",
       "      <td>0.533177</td>\n",
       "      <td>0.533177</td>\n",
       "      <td>-0.147095</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>0.291245</td>\n",
       "      <td>0.289211</td>\n",
       "      <td>0.419544</td>\n",
       "      <td>0.419544</td>\n",
       "      <td>0.080561</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>0.343405</td>\n",
       "      <td>0.291883</td>\n",
       "      <td>0.364712</td>\n",
       "      <td>0.364712</td>\n",
       "      <td>0.079812</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.233239</td>\n",
       "      <td>0.267046</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.083048</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.373958</td>\n",
       "      <td>0.284339</td>\n",
       "      <td>0.341703</td>\n",
       "      <td>0.373958</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>0.293409</td>\n",
       "      <td>0.360895</td>\n",
       "      <td>0.360895</td>\n",
       "      <td>-0.108589</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.528805</td>\n",
       "      <td>0.528805</td>\n",
       "      <td>-0.092313</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.276036</td>\n",
       "      <td>0.296186</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>-0.090357</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.278236</td>\n",
       "      <td>0.284752</td>\n",
       "      <td>0.437012</td>\n",
       "      <td>0.437012</td>\n",
       "      <td>-0.229655</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.295793</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.408524</td>\n",
       "      <td>0.408524</td>\n",
       "      <td>0.152114</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.309659</td>\n",
       "      <td>0.297993</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>0.392348</td>\n",
       "      <td>-0.074942</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.215404</td>\n",
       "      <td>0.261315</td>\n",
       "      <td>0.523281</td>\n",
       "      <td>0.523281</td>\n",
       "      <td>-0.152394</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.330433</td>\n",
       "      <td>0.290827</td>\n",
       "      <td>0.378741</td>\n",
       "      <td>0.378741</td>\n",
       "      <td>-0.011884</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>0.206734</td>\n",
       "      <td>0.276070</td>\n",
       "      <td>0.517196</td>\n",
       "      <td>0.517196</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.309868</td>\n",
       "      <td>0.304098</td>\n",
       "      <td>0.386033</td>\n",
       "      <td>0.386033</td>\n",
       "      <td>0.106704</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.265425</td>\n",
       "      <td>0.293912</td>\n",
       "      <td>0.440662</td>\n",
       "      <td>0.440662</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.248920</td>\n",
       "      <td>0.278166</td>\n",
       "      <td>0.472913</td>\n",
       "      <td>0.472913</td>\n",
       "      <td>0.085316</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.211371</td>\n",
       "      <td>0.248307</td>\n",
       "      <td>0.540322</td>\n",
       "      <td>0.540322</td>\n",
       "      <td>0.091891</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.256467</td>\n",
       "      <td>0.282677</td>\n",
       "      <td>0.460856</td>\n",
       "      <td>0.460856</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>0.561629</td>\n",
       "      <td>0.561629</td>\n",
       "      <td>-0.238371</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.220032</td>\n",
       "      <td>0.275513</td>\n",
       "      <td>0.504455</td>\n",
       "      <td>0.504455</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.224292</td>\n",
       "      <td>0.278168</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>-0.135372</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.333140</td>\n",
       "      <td>0.277534</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.183986</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.331927</td>\n",
       "      <td>0.289837</td>\n",
       "      <td>0.378236</td>\n",
       "      <td>0.378236</td>\n",
       "      <td>-0.047296</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.206105</td>\n",
       "      <td>0.266258</td>\n",
       "      <td>0.527637</td>\n",
       "      <td>0.527637</td>\n",
       "      <td>0.193189</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.230961</td>\n",
       "      <td>0.253150</td>\n",
       "      <td>0.515889</td>\n",
       "      <td>0.515889</td>\n",
       "      <td>0.028084</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1139 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFO_Date   probs_A   probs_D   probs_H     probs  prob_less_bet pred  \\\n",
       "0   2014-11-01  0.347021  0.309792  0.343187  0.347021       0.083863    A   \n",
       "1   2014-11-01  0.408577  0.283466  0.307958  0.408577      -0.086473    A   \n",
       "2   2014-11-01  0.254302  0.280665  0.465033  0.465033      -0.061283    H   \n",
       "3   2014-11-01  0.379230  0.294171  0.326600  0.379230      -0.063248    A   \n",
       "4   2014-11-01  0.220963  0.257720  0.521317  0.521317      -0.034239    H   \n",
       "5   2014-11-01  0.423454  0.275772  0.300774  0.423454       0.025048    A   \n",
       "6   2014-11-01  0.245202  0.278066  0.476732  0.476732       0.070228    H   \n",
       "7   2014-11-01  0.360879  0.296994  0.342127  0.360879      -0.059290    A   \n",
       "8   2014-11-01  0.282838  0.279421  0.437741  0.437741      -0.091360    H   \n",
       "9   2014-11-01  0.279059  0.261254  0.459687  0.459687      -0.001143    H   \n",
       "10  2014-11-01  0.277134  0.280682  0.442183  0.442183      -0.215711    H   \n",
       "11  2014-11-04  0.472008  0.263924  0.264068  0.472008       0.027564    A   \n",
       "12  2014-11-04  0.365674  0.297452  0.336874  0.365674       0.002037    A   \n",
       "13  2014-11-04  0.227678  0.255947  0.516374  0.516374       0.065924    H   \n",
       "14  2014-11-04  0.344609  0.283807  0.371584  0.371584      -0.220132    H   \n",
       "15  2014-11-04  0.387251  0.294621  0.318129  0.387251       0.032641    A   \n",
       "16  2014-11-04  0.316071  0.282204  0.401726  0.401726      -0.044703    H   \n",
       "17  2014-11-04  0.373006  0.292020  0.334974  0.373006       0.042973    A   \n",
       "18  2014-11-04  0.365008  0.289888  0.345104  0.365008      -0.009524    A   \n",
       "19  2014-11-04  0.236259  0.250380  0.513361  0.513361       0.015849    H   \n",
       "20  2014-11-04  0.449760  0.270355  0.279885  0.449760       0.011163    A   \n",
       "21  2014-11-05  0.192929  0.257765  0.549306  0.549306      -0.100045    H   \n",
       "22  2014-11-05  0.320524  0.279896  0.399580  0.399580      -0.093030    H   \n",
       "23  2014-11-07  0.374552  0.296112  0.329336  0.374552      -0.023854    A   \n",
       "24  2014-11-08  0.434671  0.285414  0.279915  0.434671       0.050056    A   \n",
       "25  2014-11-08  0.324194  0.296552  0.379254  0.379254      -0.101516    H   \n",
       "26  2014-11-08  0.349622  0.295409  0.354969  0.354969      -0.135227    H   \n",
       "27  2014-11-08  0.272210  0.294100  0.433689  0.433689      -0.049402    H   \n",
       "28  2014-11-08  0.324823  0.285525  0.389652  0.389652      -0.035880    H   \n",
       "29  2014-11-08  0.207086  0.244481  0.548433  0.548433      -0.010226    H   \n",
       "..         ...       ...       ...       ...       ...            ...  ...   \n",
       "342 2017-04-22  0.228796  0.277371  0.493833  0.493833      -0.055618    H   \n",
       "343 2017-04-22  0.265368  0.285432  0.449201  0.449201      -0.001250    H   \n",
       "344 2017-04-22  0.278375  0.290704  0.430921  0.430921      -0.029909    H   \n",
       "345 2017-04-23  0.316927  0.292390  0.390683  0.390683      -0.135632    H   \n",
       "346 2017-04-24  0.198036  0.268787  0.533177  0.533177      -0.147095    H   \n",
       "347 2017-04-25  0.291245  0.289211  0.419544  0.419544       0.080561    H   \n",
       "348 2017-04-28  0.343405  0.291883  0.364712  0.364712       0.079812    H   \n",
       "349 2017-04-29  0.233239  0.267046  0.499715  0.499715       0.083048    H   \n",
       "350 2017-04-29  0.373958  0.284339  0.341703  0.373958       0.008994    A   \n",
       "351 2017-04-29  0.345697  0.293409  0.360895  0.360895      -0.108589    H   \n",
       "352 2017-04-29  0.208338  0.262857  0.528805  0.528805      -0.092313    H   \n",
       "353 2017-04-29  0.276036  0.296186  0.427778  0.427778      -0.090357    H   \n",
       "354 2017-04-29  0.278236  0.284752  0.437012  0.437012      -0.229655    H   \n",
       "355 2017-04-29  0.295793  0.295682  0.408524  0.408524       0.152114    H   \n",
       "356 2017-04-29  0.309659  0.297993  0.392348  0.392348      -0.074942    H   \n",
       "357 2017-04-29  0.215404  0.261315  0.523281  0.523281      -0.152394    H   \n",
       "358 2017-04-29  0.330433  0.290827  0.378741  0.378741      -0.011884    H   \n",
       "359 2017-04-29  0.206734  0.276070  0.517196  0.517196      -0.006365    H   \n",
       "360 2017-05-07  0.309868  0.304098  0.386033  0.386033       0.106704    H   \n",
       "361 2017-05-07  0.265425  0.293912  0.440662  0.440662       0.030826    H   \n",
       "362 2017-05-07  0.248920  0.278166  0.472913  0.472913       0.085316    H   \n",
       "363 2017-05-07  0.211371  0.248307  0.540322  0.540322       0.091891    H   \n",
       "364 2017-05-07  0.256467  0.282677  0.460856  0.460856      -0.002107    H   \n",
       "365 2017-05-07  0.177734  0.260637  0.561629  0.561629      -0.238371    H   \n",
       "366 2017-05-07  0.220032  0.275513  0.504455  0.504455      -0.094348    H   \n",
       "367 2017-05-07  0.224292  0.278168  0.497540  0.497540      -0.135372    H   \n",
       "368 2017-05-07  0.333140  0.277534  0.389325  0.389325       0.183986    H   \n",
       "369 2017-05-07  0.331927  0.289837  0.378236  0.378236      -0.047296    H   \n",
       "370 2017-05-07  0.206105  0.266258  0.527637  0.527637       0.193189    H   \n",
       "371 2017-05-07  0.230961  0.253150  0.515889  0.515889       0.028084    H   \n",
       "\n",
       "    INFO_FTR   WIN  \n",
       "0          H -1.00  \n",
       "1          A  1.02  \n",
       "2          H  0.90  \n",
       "3          H -1.00  \n",
       "4          H  0.80  \n",
       "5          D -1.00  \n",
       "6          H  1.46  \n",
       "7          A  1.38  \n",
       "8          H  0.89  \n",
       "9          D -1.00  \n",
       "10         D -1.00  \n",
       "11         H -1.00  \n",
       "12         H -1.00  \n",
       "13         H  1.22  \n",
       "14         H  0.69  \n",
       "15         H -1.00  \n",
       "16         D -1.00  \n",
       "17         H -1.00  \n",
       "18         D -1.00  \n",
       "19         H  1.01  \n",
       "20         A  1.28  \n",
       "21         D -1.00  \n",
       "22         A -1.00  \n",
       "23         H -1.00  \n",
       "24         D -1.00  \n",
       "25         D -1.00  \n",
       "26         H  1.04  \n",
       "27         H  1.07  \n",
       "28         H  1.35  \n",
       "29         H  0.79  \n",
       "..       ...   ...  \n",
       "342        H  0.82  \n",
       "343        D -1.00  \n",
       "344        D -1.00  \n",
       "345        H  0.90  \n",
       "346        H  0.47  \n",
       "347        A -1.00  \n",
       "348        A -1.00  \n",
       "349        D -1.00  \n",
       "350        H -1.00  \n",
       "351        H  1.13  \n",
       "352        A -1.00  \n",
       "353        H  0.93  \n",
       "354        D -1.00  \n",
       "355        A -1.00  \n",
       "356        D -1.00  \n",
       "357        D -1.00  \n",
       "358        H  1.56  \n",
       "359        H  0.91  \n",
       "360        D -1.00  \n",
       "361        A -1.00  \n",
       "362        A -1.00  \n",
       "363        A -1.00  \n",
       "364        A -1.00  \n",
       "365        H  0.25  \n",
       "366        H  0.67  \n",
       "367        H  0.58  \n",
       "368        D -1.00  \n",
       "369        A -1.00  \n",
       "370        D -1.00  \n",
       "371        H  1.05  \n",
       "\n",
       "[1139 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season[['INFO_Date', 'probs_A','probs_D','probs_H', 'probs', 'prob_less_bet', 'pred', 'INFO_FTR', 'WIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

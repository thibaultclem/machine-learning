{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import datetime\n",
    "import time\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "now = datetime.datetime.now()\n",
    "start_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "today = now.strftime(\"%Y-%m-%d\")\n",
    "season = 2017\n",
    "classes = ['A', 'D', 'H']\n",
    "PHANTOMJS_PATH = './phantomjs'\n",
    "browser = webdriver.PhantomJS(PHANTOMJS_PATH)\n",
    "base_layer = ['XGBoost', 'NB', 'MLP']\n",
    "\n",
    "league_list = ['E0', 'E1', 'E2', 'SP1', 'D1', 'F1', 'I1', 'SC0']\n",
    "#league_list = ['E0', 'E1', 'E2', 'F1', 'SC0']\n",
    "league_stacking = ['E0', 'E1', 'E2', 'SP1', 'SC0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary of team name\n",
    "team_name_dict = {\n",
    "    'West Ham United': \"West Ham\",\n",
    "    'Chelsea': \"Chelsea\",\n",
    "    'Huddersfield Town': \"Huddersfield\",\n",
    "    'Manchester City': \"Man City\",\n",
    "    'Newcastle United FC': \"Newcastle\",\n",
    "    'Stoke City FC': \"Stoke\",\n",
    "    'Swansea City': \"Swansea\",\n",
    "    'Southampton FC': \"Southampton\",\n",
    "    'Everton': \"Everton\",\n",
    "    'Tottenham Hotspur': \"Tottenham\",\n",
    "    'Brighton and Hove Albion': \"Brighton\",\n",
    "    'Watford FC': \"Watford\",\n",
    "    'Manchester United FC': \"Man United\",\n",
    "    'Burnley FC': \"Burnley\",\n",
    "    'Crystal Palace FC': \"Crystal Palace\",\n",
    "    'Bournemouth AFC': \"Bournemouth\",\n",
    "    'Leicester City': \"Leicester\",\n",
    "    'West Bromwich Albion FC': \"West Brom\",\n",
    "    'Arsenal': \"Arsenal\",\n",
    "    'Liverpool': \"Liverpool\",\n",
    "    'Aston Villa': \"Aston Villa\",\n",
    "    'Fulham': \"Fulham\",\n",
    "    'Barnsley FC': \"Barnsley\",\n",
    "    'Hull City AFC': \"Hull\",\n",
    "    'Bolton Wanderers': \"Bolton\",\n",
    "    'Queens Park Rangers FC': \"QPR\", \n",
    "    'Brentford': \"Brentford\",\n",
    "    'Sunderland': \"Sunderland\",\n",
    "    'Bristol City FC': \"Bristol City\",\n",
    "    'Leeds United': \"Leeds\",\n",
    "    'Derby County': \"Derby\",\n",
    "    'Sheffield Wednesday FC': \"Sheffield Weds\",\n",
    "    'Middlesbrough FC': \"Middlesbrough\",\n",
    "    'Cardiff City FC': \"Cardiff\",\n",
    "    'Nottingham Forest': \"Nott'm Forest\",\n",
    "    'Burton Albion': \"Burton\",\n",
    "    'Sheffield United FC': \"Sheffield United\",\n",
    "    'Reading': \"Reading\",\n",
    "    'Wolverhampton Wanderers': \"Wolves\",\n",
    "    'Preston North End FC': \"Preston\",\n",
    "    'Millwall': \"Millwall\",\n",
    "    'Birmingham City FC': \"Birmingham\",\n",
    "    'Ipswich Town FC': \"Ipswich\",\n",
    "    'Norwich City FC': \"Norwich\",\n",
    "    'AFC Wimbledon' : \"AFC Wimbledon\",\n",
    "    'Plymouth Argyle FC' : \"Plymouth\",\n",
    "    'Blackburn Rovers' : \"Blackburn\",\n",
    "    'Portsmouth' : \"Portsmouth\",\n",
    "    'Blackpool FC' : \"Blackpool\",\n",
    "    'Wigan Athletic' : \"Wigan\",\n",
    "    'Bradford City' : \"Bradford\",\n",
    "    'Charlton Athletic FC' : \"Charlton\",\n",
    "    'Doncaster Rovers' : \"Doncaster\",\n",
    "    'Walsall' : \"Walsall\",\n",
    "    'Gillingham' : \"Gillingham\",\n",
    "    'Northampton Town' : \"Northampton\",\n",
    "    'Milton Keynes Dons FC' : \"Milton Keynes Dons\",\n",
    "    'Oldham Athletic' : \"Oldham\",\n",
    "    'Oxford United' : \"Oxford\",\n",
    "    'Rotherham United FC' : \"Rotherham\",\n",
    "    'Rochdale' : \"Rochdale\",\n",
    "    'Bristol Rovers' : \"Bristol Rvs\",\n",
    "    'Scunthorpe United' : \"Scunthorpe\",\n",
    "    'Peterborough United' : \"Peterboro\",\n",
    "    'Shrewsbury Town' : \"Shrewsbury\",\n",
    "    'Fleetwood Town' : \"Fleetwood Town\",\n",
    "    'Southend United' : \"Southend\",\n",
    "    'Bury' : \"Bury\",\n",
    "    'Levante' : \"Levante\",\n",
    "    'Getafe' : \"Getafe\",\n",
    "    'Real Betis' : \"Betis\",\n",
    "    'Alaves' : \"Alaves\",\n",
    "    'Valencia CF' : \"Valencia\",\n",
    "    'Sevilla FC' : \"Sevilla\",\n",
    "    'FC Barcelona' : \"Barcelona\",\n",
    "    'Malaga CF' : \"Malaga\",\n",
    "    'Villarreal CF' : \"Villarreal\",\n",
    "    'U.D. Las Palmas de Gran Canaria' : \"Las Palmas\",\n",
    "    'Celta de Vigo' : \"Celta\",\n",
    "    'Atletico Madrid' : \"Ath Madrid\",\n",
    "    'Leganes' : \"Leganes\",\n",
    "    'Athletic Bilbao' : \"Ath Bilbao\",\n",
    "    'Real Madrid' : \"Real Madrid\",\n",
    "    'Eibar' : \"Eibar\",\n",
    "    'Real Sociedad' : \"Sociedad\",\n",
    "    'RCD Espanyol' : \"Espanol\",\n",
    "    'Deportivo La Coruna' : \"La Coruna\",\n",
    "    'Girona FC' : \"Girona\",\n",
    "    'Hearts Of Midlothian FC' : \"Hearts\",\n",
    "    'St. Johnstone' : \"St Johnstone\",\n",
    "    'Partick Thistle' : \"Partick\",\n",
    "    'Dundee FC' : \"Dundee\",\n",
    "    'Ross County' : \"Ross County\",\n",
    "    'Hamilton Academicals FC' : \"Hamilton\",\n",
    "    'Hibernian FC' : \"Hibernian\",\n",
    "    'Aberdeen FC' : \"Aberdeen\",\n",
    "    'Celtic FC' : \"Celtic\",\n",
    "    'Motherwell' : \"Motherwell\",\n",
    "    'Glasgow Rangers FC' : \"Rangers\",\n",
    "    'Kilmarnock' : \"Kilmarnock\",\n",
    "    'FC Schalke 04' : \"Schalke 04\",\n",
    "    '1. FSV Mainz 05' : \"Mainz\",\n",
    "    'Borussia Monchengladbach' : \"M'gladbach\",\n",
    "    'Bayer 04 Leverkusen' : \"Leverkusen\",\n",
    "    'Eintracht Frankfurt' : \"Ein Frankfurt\",\n",
    "    'Borussia Dortmund' : \"Dortmund\",\n",
    "    'FC Augsburg' : \"Augsburg\",\n",
    "    'Hannover 96' : \"Hannover\",\n",
    "    'RB Leipzig' : \"RB Leipzig\",\n",
    "    'VfB Stuttgart' : \"Stuttgart\",\n",
    "    'Hamburger SV' : \"Hamburg\",\n",
    "    'FC Bayern Munchen' : \"Bayern Munich\",\n",
    "    '1. FC Koln' : \"FC Koln\",\n",
    "    'SV Werder Bremen' : \"Werder Bremen\",\n",
    "    'SC Freiburg' : \"Freiburg\",\n",
    "    'Hertha BSC Berlin' : \"Hertha\",\n",
    "    'VfL Wolfsburg' : \"Wolfsburg\",\n",
    "    'TSG 1899 Hoffenheim' : \"Hoffenheim\",\n",
    "    'AS St. Etienne' : \"St Etienne\",\n",
    "    'Montpellier HSC' : \"Montpellier\",\n",
    "    'AS Monaco' : \"Monaco\",\n",
    "    'Stade Caen' : \"Caen\",\n",
    "    'Angers SCO' : \"Angers\",\n",
    "    'FC Toulouse' : \"Toulouse\",\n",
    "    'FC Metz' : \"Metz\",\n",
    "    'Dijon FCO' : \"Dijon\",\n",
    "    'FC Nantes' : \"Nantes\",\n",
    "    'EA Guingamp' : \"Guingamp\",\n",
    "    'SC Amiens' : \"Amiens\",\n",
    "    'FC Girondins de Bordeaux' : \"Bordeaux\",\n",
    "    'Stade Rennes FC' : \"Rennes\",\n",
    "    'OSC Lille' : \"Lille\",\n",
    "    'OGC Nice' : \"Nice\",\n",
    "    'Racing Club Strasbourg' : \"Strasbourg\",\n",
    "    'AC Troyes AC' : \"Troyes\",\n",
    "    'Olympique Lyonnais' : \"Lyon\",\n",
    "    'Olympique Marseille' : \"Marseille\",\n",
    "    'Paris Saint-Germain FC' : \"Paris SG\",\n",
    "    'Crotone' : \"Crotone\",\n",
    "    'Napoli' : \"Napoli\",\n",
    "    'Chievo Verona' : \"Chievo\",\n",
    "    'AC Milan' : \"Milan\",\n",
    "    'Genoa' : \"Genoa\",\n",
    "    'Bologna F.C.' : \"Bologna\",\n",
    "    'Benevento' : \"Benevento\",\n",
    "    'AC Fiorentina' : \"Fiorentina\",\n",
    "    'SPAL 1907 Ferrara' : \"Spal\",\n",
    "    'Sassuolo' : \"Sassuolo\",\n",
    "    'Torino FC' : \"Torino\",\n",
    "    'AS Roma' : \"Roma\",\n",
    "    'Udinese Calcio' : \"Udinese\",\n",
    "    'Juventus FC' : \"Juventus\",\n",
    "    'SS Lazio' : \"Lazio\",\n",
    "    'Cagliari' : \"Cagliari\",\n",
    "    'Internazionale Milano' : \"Inter\",\n",
    "    'Sampdoria' : \"Sampdoria\",\n",
    "    'Atalanta Bergamo' : \"Atalanta\",\n",
    "    'Hellas Verona' : \"Verona\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for betBrain url by league\n",
    "betbrain_url_dict = {\n",
    "    'E0': 'https://www.betbrain.com/football/england/premier-league/#/matches/',\n",
    "    'E1': 'https://www.betbrain.com/football/england/championship/#/matches/',\n",
    "    'E2': 'https://www.betbrain.com/football/england/league-1/#/matches/',\n",
    "    'SP1': 'https://www.betbrain.com/football/spain/primera-division/#/matches/',\n",
    "    'SC0': 'https://www.betbrain.com/football/scotland/premiership/#/matches/',\n",
    "    'D1': 'https://www.betbrain.com/football/germany/bundesliga/#/matches/',\n",
    "    'F1': 'https://www.betbrain.com/football/france/ligue-1/#/matches/',\n",
    "    'I1': 'https://www.betbrain.com/football/italy/serie-a/#/matches/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature list to use\n",
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "best_features_NB = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP],\n",
    "    ['all_features', all_features],\n",
    "    ['best_features_NB', best_features_NB]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct base layer\n",
    "base_layer = [\n",
    "    ['XGBoost' ,['all_features', all_features]],\n",
    "    ['NB', ['best_features_NB', best_features_NB]],\n",
    "    ['MLP', ['best_features_MLP', best_features_MLP]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_short_team_name(name):\n",
    "    return team_name_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract next match list with odds\n",
    "def get_next_matches(div):\n",
    "    url = betbrain_url_dict[div]\n",
    "    # Browse the url\n",
    "    browser.get(url)\n",
    "    # Wait the page to load\n",
    "    time.sleep(15)\n",
    "    # Click on Home Draw Away\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"app\"]/div/section/section/main/div[3]/div[1]/a[3]').click()\n",
    "    except:\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"app\"]/div/section/section/main/div[4]/div[1]/a[3]').click()\n",
    "    # Wait page to load\n",
    "    time.sleep(10)\n",
    "    # let's parse our html\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    # configure a panda dataframe for save matches\n",
    "    columns = ['Div','Date','HomeTeam','AwayTeam','INFO_BbAvH','INFO_BbAvD','INFO_BbAvA']\n",
    "    matches_df = pd.DataFrame(columns=columns)\n",
    "    # add all the matches in the dataframe\n",
    "    matches = soup.find_all(\"li\", \"Match\")\n",
    "    for match in matches:\n",
    "        average_odds = match.find_all('span', 'AverageOdds')\n",
    "        match_detail = match.find('a', 'MatchTitleLink')\n",
    "        match_date = match.find('time').text\n",
    "        match_date_datetime = datetime.datetime.strptime(match_date, '%d/%m/%Y %H:%M')\n",
    "        if (match_date_datetime-now).days > 4:\n",
    "            break\n",
    "        home_team = get_short_team_name(match_detail.find_all('span')[1].text)\n",
    "        away_team = get_short_team_name(match_detail.find_all('span')[3].text)\n",
    "        if len(average_odds) < 1:\n",
    "            break\n",
    "        home_odd = average_odds[0].find_all('span')[1].text\n",
    "        draw_odd = average_odds[1].find_all('span')[1].text\n",
    "        away_odd = average_odds[2].find_all('span')[1].text\n",
    "        df_temp = pd.DataFrame([[div, match_date, home_team, away_team, home_odd, draw_odd, away_odd]],columns=columns)\n",
    "        matches_df = pd.concat([matches_df,df_temp])\n",
    "    return matches_df         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all data for pre match on away team\n",
    "def homeData( date, team, div, nb_matches, nb_matches_string ):\n",
    "    # Dataframe to return with all info\n",
    "    dic = {}\n",
    "    # Home team query\n",
    "    #TODO Recuperer aussi combien de buts ils se sont pris dans la tronche et tout et tout\n",
    "    queryHome = '''\n",
    "            SELECT Date, FTHG, FTR, HTHG, HTR, HS, HST, HF, HC, HY, HR, FTAG, HTAG, `AS`, AST, AF, AC, AY, AR\n",
    "            FROM cur_season_matchs_raw\n",
    "            WHERE Date < ? AND HomeTeam = ? AND Div = ? ORDER BY Date DESC LIMIT ?'''\n",
    "    # Get the previous home game of the Home Team\n",
    "    df_home = pd.read_sql(queryHome, conn, params=[datetime.datetime.strptime(date, '%d/%m/%Y %H:%M').strftime('%Y-%m-%d'), team, div, nb_matches])\n",
    "    # Hot-encode Category Full Time Result and Half Time Result\n",
    "    df_home = pd.get_dummies(df_home, columns=['FTR', 'HTR'])\n",
    "    # Calculate the mean of all columns\n",
    "    #display(df_home.head())\n",
    "    dic['H_MEANS_'+nb_matches_string+'_FTHG'] = round(df_home.FTHG.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_FTR_H'] = 0 if 'FTR_H'not in df_home.columns else round(df_home.FTR_H.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_FTR_D'] = 0 if 'FTR_D' not in df_home.columns else round(df_home.FTR_D.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_FTR_A'] = 0 if 'FTR_A' not in df_home.columns else round(df_home.FTR_A.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HTHG'] = round(df_home.HTHG.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HTR_H'] = 0 if 'HTR_H' not in df_home.columns else round(df_home.HTR_H.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HTR_D'] = 0 if 'HTR_D' not in df_home.columns else round(df_home.HTR_D.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HTR_A'] = 0 if 'HTR_A' not in df_home.columns else round(df_home.HTR_A.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HS'] = round(df_home.HS.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HST'] = round(df_home.HST.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HF'] = round( df_home.HF.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HC'] = round(df_home.HC.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HY'] = round(df_home.HY.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HR'] = round(df_home.HR.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_FTAG'] = round(df_home.FTAG.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_HTAG'] = round(df_home.HTAG.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AS'] = round(df_home.AS.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AST'] = round(df_home.AST.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AF'] = round(df_home.AF.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AC'] = round(df_home.AC.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AY'] = round(df_home.AY.mean(), 2)\n",
    "    dic['H_MEANS_'+nb_matches_string+'_AR'] = round(df_home.AR.mean(), 2)\n",
    "    dic['H_STD_'+nb_matches_string+'_FTHG'] = round(df_home.FTHG.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_FTR_H'] = 0 if 'FTR_H'not in df_home.columns else round(df_home.FTR_H.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_FTR_D'] = 0 if 'FTR_D' not in df_home.columns else round(df_home.FTR_D.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_FTR_A'] = 0 if 'FTR_A' not in df_home.columns else round(df_home.FTR_A.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HTHG'] = round(df_home.HTHG.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HTR_H'] = 0 if 'HTR_H' not in df_home.columns else round(df_home.HTR_H.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HTR_D'] = 0 if 'HTR_D' not in df_home.columns else round(df_home.HTR_D.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HTR_A'] = 0 if 'HTR_A' not in df_home.columns else round(df_home.HTR_A.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HS'] = round(df_home.HS.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HST'] = round(df_home.HST.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HF'] = round( df_home.HF.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HC'] = round(df_home.HC.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HY'] = round(df_home.HY.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HR'] = round(df_home.HR.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_FTAG'] = round(df_home.FTAG.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_HTAG'] = round(df_home.HTAG.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AS'] = round(df_home.AS.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AST'] = round(df_home.AST.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AF'] = round(df_home.AF.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AC'] = round(df_home.AC.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AY'] = round(df_home.AY.std(), 3)\n",
    "    dic['H_STD_'+nb_matches_string+'_AR'] = round(df_home.AR.std(), 3)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all data for pre match on away team\n",
    "def awayData( date, team, div, nb_matches, nb_matches_string ):\n",
    "    # Dataframe to return with all info\n",
    "    dic = {}\n",
    "    # away team query\n",
    "    #TODO Recuperer aussi combien de buts ils se sont pris dans la tronche et tout et tout\n",
    "    queryAway = '''\n",
    "            SELECT Date, FTAG, FTR, HTAG, HTR, `AS`, AST, AF, AC, AY, AR, FTHG, HTHG, HS, HST, HF, HC, HY, HR\n",
    "            FROM cur_season_matchs_raw\n",
    "            WHERE Date < ? AND AwayTeam = ? AND Div = ? ORDER BY Date DESC LIMIT ?'''\n",
    "    # Get the previous away game of the away Team\n",
    "    df_away = pd.read_sql(queryAway, conn, params=[datetime.datetime.strptime(date, '%d/%m/%Y %H:%M').strftime('%Y-%m-%d'), team, div, nb_matches])\n",
    "    # Hot-encode Category Full Time Result and Half Time Result\n",
    "    df_away = pd.get_dummies(df_away, columns=['FTR', 'HTR'])\n",
    "    # Calculate the mean of all columns\n",
    "    #display(df_away.head())\n",
    "    dic['A_MEANS_'+nb_matches_string+'_FTAG'] = round(df_away.FTAG.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_FTR_H'] = 0 if 'FTR_H'not in df_away.columns else round(df_away.FTR_H.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_FTR_D'] = 0 if 'FTR_D' not in df_away.columns else round(df_away.FTR_D.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_FTR_A'] = 0 if 'FTR_A' not in df_away.columns else round(df_away.FTR_A.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HTAG'] = round(df_away.HTAG.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HTR_H'] = 0 if 'HTR_H' not in df_away.columns else round(df_away.HTR_H.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HTR_D'] = 0 if 'HTR_D' not in df_away.columns else round(df_away.HTR_D.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HTR_A'] = 0 if 'HTR_A' not in df_away.columns else round(df_away.HTR_A.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AS'] = round(df_away.AS.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AST'] = round(df_away.AST.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AF'] = round(df_away.AF.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AC'] = round(df_away.AC.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AY'] = round(df_away.AY.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_AR'] = round(df_away.AR.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_FTHG'] = round(df_away.FTHG.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HTHG'] = round(df_away.HTHG.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HS'] = round(df_away.HS.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HST'] = round(df_away.HST.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HF'] = round( df_away.HF.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HC'] = round(df_away.HC.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HY'] = round(df_away.HY.mean(), 2)\n",
    "    dic['A_MEANS_'+nb_matches_string+'_HR'] = round(df_away.HR.mean(), 2)\n",
    "    dic['A_STD_'+nb_matches_string+'_FTAG'] = round(df_away.FTAG.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_FTR_H'] = 0 if 'FTR_H'not in df_away.columns else round(df_away.FTR_H.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_FTR_D'] = 0 if 'FTR_D' not in df_away.columns else round(df_away.FTR_D.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_FTR_A'] = 0 if 'FTR_A' not in df_away.columns else round(df_away.FTR_A.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HTAG'] = round(df_away.HTAG.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HTR_H'] = 0 if 'HTR_H' not in df_away.columns else round(df_away.HTR_H.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HTR_D'] = 0 if 'HTR_D' not in df_away.columns else round(df_away.HTR_D.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HTR_A'] = 0 if 'HTR_A' not in df_away.columns else round(df_away.HTR_A.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AS'] = round(df_away.AS.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AST'] = round(df_away.AST.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AF'] = round(df_away.AF.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AC'] = round(df_away.AC.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AY'] = round(df_away.AY.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_AR'] = round(df_away.AR.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_FTHG'] = round(df_away.FTHG.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HTHG'] = round(df_away.HTHG.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HS'] = round(df_away.HS.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HST'] = round(df_away.HST.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HF'] = round( df_away.HF.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HC'] = round(df_away.HC.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HY'] = round(df_away.HY.std(), 3)\n",
    "    dic['A_STD_'+nb_matches_string+'_HR'] = round(df_away.HR.std(), 3)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract feature for each match in the list\n",
    "def get_feature_from_matches_list(match_list_df):\n",
    "    predict_df = pd.DataFrame()\n",
    "    for index, row in match_list_df.iterrows():\n",
    "        match_dict = row.to_dict()\n",
    "        # Add five game home history\n",
    "        match_dict.update(homeData(row['Date'], row['HomeTeam'], league, 5, 'FIVE'))\n",
    "        # Add five game away history\n",
    "        match_dict.update(awayData(row['Date'], row['AwayTeam'], league, 5, 'FIVE'))\n",
    "        # Add three game home history\n",
    "        match_dict.update(homeData(row['Date'], row['HomeTeam'], league, 3, 'THREE'))\n",
    "        # Add three game away history\n",
    "        match_dict.update(awayData(row['Date'], row['AwayTeam'], league, 3, 'THREE'))\n",
    "        # transform value in dict to array of columns and value and add to dataframe\n",
    "        cols = []\n",
    "        vals = []\n",
    "        for key in match_dict:\n",
    "            cols.append(key)\n",
    "            vals.append(match_dict[key])\n",
    "        if predict_df.size == 0:\n",
    "            predict_df = pd.DataFrame([vals],columns=cols)\n",
    "        else:\n",
    "            predict_df = pd.concat([predict_df,pd.DataFrame([vals],columns=cols)])\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_columns(base_layer, classes):\n",
    "    cols = []\n",
    "    for clf_name, features in base_layer:\n",
    "        for result in classes:\n",
    "            cols.append(clf_name+result)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer1_df(X_layer0, base_layer, cols):\n",
    "    X_layer1 = np.zeros((X_layer0.shape[0], len(base_layer)*3))\n",
    "    X_layer1 = pd.DataFrame(X_layer1, columns=cols)\n",
    "    return X_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(df, clf_name, features):\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    imp = joblib.load(model_path+\"imputer\"+clf_name+\".pkl\")\n",
    "    X = imp.transform(X)\n",
    "    # Standardize features\n",
    "    sc_X = joblib.load(model_path+\"scaler\"+clf_name+\".pkl\")\n",
    "    X = sc_X.transform(X)\n",
    "    return df, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_preds(df, preds, probs):\n",
    "    # Copy the df to a new one\n",
    "    concat_df = df\n",
    "    # Add probs to the new def\n",
    "    concat_df['probs_A'] = probs[:,0]\n",
    "    concat_df['probs_D'] = probs[:,1]\n",
    "    concat_df['probs_H'] = probs[:,2]\n",
    "    concat_df['probs'] = concat_df[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "    # Add Bet\n",
    "    concat_df['pred'] = preds\n",
    "    # Add bet get from betBrain\n",
    "    concat_df['INFO_ODD_BET'] = 0\n",
    "    concat_df.loc[concat_df.pred == 'A', 'INFO_ODD_BET'] = concat_df[odd_A]\n",
    "    concat_df.loc[concat_df.pred == 'D', 'INFO_ODD_BET'] = concat_df[odd_D]\n",
    "    concat_df.loc[concat_df.pred == 'H', 'INFO_ODD_BET'] = concat_df[odd_H]\n",
    "    # Add prob less bet\n",
    "    concat_df['prob_less_bet'] = 0\n",
    "    concat_df.loc[concat_df.pred == 'A', 'prob_less_bet'] = concat_df['probs'] - concat_df[odd_A].apply(lambda x: 1/float(x))\n",
    "    concat_df.loc[concat_df.pred == 'D', 'prob_less_bet'] = concat_df['probs'] - concat_df[odd_D].apply(lambda x: 1/float(x))\n",
    "    concat_df.loc[concat_df.pred == 'H', 'prob_less_bet'] = concat_df['probs'] - concat_df[odd_H].apply(lambda x: 1/float(x))\n",
    "    # Add historical difference of goal between Home Team and away Team\n",
    "    concat_df['H-A'] = (concat_df['H_MEANS_FIVE_FTHG'] - concat_df['H_MEANS_FIVE_FTAG']) - (concat_df['A_MEANS_FIVE_FTAG'] - concat_df['A_MEANS_FIVE_FTHG'])\n",
    "    \n",
    "    return concat_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "def make_prediction(base_layer, matches_to_predict_df):\n",
    "\n",
    "    # Prepare structure of layer 1\n",
    "    cols = get_layer_columns(base_layer, classes)\n",
    "    X_layer1 = get_layer1_df(matches_to_predict_df, base_layer, cols)\n",
    "    \n",
    "    # predict for each model of the base layer\n",
    "    for clf_name, features in base_layer:\n",
    "        \n",
    "        # get the dataset\n",
    "        df, X = get_dataset(matches_to_predict_df, clf_name, features[1])\n",
    "\n",
    "        clf_base = joblib.load(model_path+\"model_layer0_\"+clf_name+\".pkl\")\n",
    "        predict_probs = clf_base.predict_proba(X)\n",
    "        X_layer1.loc[:, [clf_name+result for result in classes]] = predict_probs\n",
    "\n",
    "    # predict the stacking layer\n",
    "    clf_1 = joblib.load(model_path+\"model_layer1.pkl\")\n",
    "    # Predict target values\n",
    "    y_pred = clf_1.predict(X_layer1)\n",
    "    # Predict probabilities\n",
    "    y_probs = clf_1.predict_proba(X_layer1)\n",
    "    \n",
    "    return concat_preds(df, y_pred, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "def make_prediction_MLP(matches_to_predict_df):\n",
    "    \n",
    "    # get the dataset\n",
    "    df, X = get_dataset(matches_to_predict_df, '', best_features_MLP)\n",
    "\n",
    "    # get the model\n",
    "    clf = joblib.load(model_path+\"model_MLP.pkl\")\n",
    "    \n",
    "    # Predict target values\n",
    "    y_pred = clf.predict(X)\n",
    "    # Predict probabilities\n",
    "    y_probs = clf.predict_proba(X)\n",
    "    \n",
    "    return concat_preds(df, y_pred, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bet(league, df):\n",
    "    if league == 'E0':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 4]\n",
    "        to_bet_df = to_bet_df[to_bet_df['pred'] == 'H']\n",
    "        to_bet_df = to_bet_df[to_bet_df['prob_less_bet'] >= 0]\n",
    "        return to_bet_df\n",
    "    if league == 'E1':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 1.9]\n",
    "        return to_bet_df\n",
    "    if league == 'E2':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] >= 1.6]\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 2]\n",
    "        to_bet_df = to_bet_df[to_bet_df['pred'] == 'H']\n",
    "        to_bet_df = to_bet_df[to_bet_df['H-A'] >= -0.5]\n",
    "        to_bet_df = to_bet_df[to_bet_df['H-A'] <= 2.5]\n",
    "        return to_bet_df\n",
    "    if league == 'SP1':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 2]\n",
    "        to_bet_df = to_bet_df[to_bet_df['pred'] == 'H']\n",
    "        to_bet_df = to_bet_df[to_bet_df['prob_less_bet'] <= -0.1]\n",
    "        return to_bet_df\n",
    "    if league == 'SC0':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] >= 2]\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 3]\n",
    "        to_bet_df = to_bet_df[to_bet_df['pred'] == 'A']\n",
    "        to_bet_df = to_bet_df[to_bet_df['prob_less_bet'] <= 0.1]\n",
    "        return to_bet_df\n",
    "    if league == 'D1':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 4]\n",
    "        to_bet_df = to_bet_df[to_bet_df['pred'] == 'H']\n",
    "        to_bet_df = to_bet_df[to_bet_df['prob_less_bet'] >= -0.1]\n",
    "        return to_bet_df\n",
    "    if league == 'F1':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 4]\n",
    "        to_bet_df = to_bet_df[to_bet_df['prob_less_bet'] <= -0.1]\n",
    "        return to_bet_df\n",
    "    if league == 'I1':\n",
    "        to_bet_df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        to_bet_df = to_bet_df[to_bet_df['INFO_ODD_BET'] <= 2.8]\n",
    "        to_bet_df = to_bet_df[to_bet_df['H-A'] >= -2]\n",
    "        to_bet_df = to_bet_df[to_bet_df['H-A'] <= 0.2]\n",
    "        return to_bet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0\n",
      "E1\n",
      "E2\n",
      "SP1\n",
      "D1\n",
      "F1\n",
      "I1\n",
      "SC0\n"
     ]
    }
   ],
   "source": [
    "# Get all bets\n",
    "bet_cols = ['Date', 'Div', 'HomeTeam', 'AwayTeam', 'pred','probs' , 'prob_less_bet', 'H-A', 'INFO_ODD_BET']\n",
    "all_bets_df = pd.DataFrame(columns=bet_cols)\n",
    "for league in league_list:\n",
    "    print league\n",
    "    filename = './predict/'+today+'_'+league\n",
    "    model_path = '../MODELING/models/'+league+'/'+league+'_'+str(season)+'_'\n",
    "    # Get match coming with odd on Betbrain\n",
    "    match_list_df = get_next_matches(league)\n",
    "    # Extract feature from historical data\n",
    "    to_predict_df = get_feature_from_matches_list(match_list_df)\n",
    "    to_predict_df = to_predict_df.reset_index()\n",
    "    # Make prediction\n",
    "    if league in league_stacking:\n",
    "        result_df = make_prediction(base_layer, to_predict_df)\n",
    "    else:\n",
    "        result_df = make_prediction_MLP(to_predict_df)\n",
    "    # Apply post prediction manual filter\n",
    "    bet_df = get_bet(league, result_df)\n",
    "    bet_df[bet_cols].to_csv('./predict/'+today+'_'+league+'.csv')\n",
    "    all_bets_df = pd.concat([all_bets_df,bet_df[bet_cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bets_df.to_csv('./predict/'+today+'_ALL.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "season_list = [2014, 2015, 2016]\n",
    "league = 'D1'\n",
    "classes = ['A', 'D', 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "best_features_NB = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP],\n",
    "    ['all_features', all_features],\n",
    "    ['best_features_NB', best_features_NB]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct base layer\n",
    "base_layer = [\n",
    "    ['XGBoost', False, 'no', 9, XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=200,\n",
    "        max_depth=4,\n",
    "        min_child_weight=1,\n",
    "        gamma=0.41,\n",
    "        subsample=0.76,\n",
    "        colsample_bytree=0.4,\n",
    "        objective='multi:softprob',\n",
    "        reg_alpha=0.46,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=15), \n",
    "     ['all_features', all_features]\n",
    "    ],\n",
    "    ['NB', True, 'no', 9, GaussianNB(), ['best_features_NB', best_features_NB]],\n",
    "    ['MLP', True, 'no', 7, MLPClassifier(\n",
    "        random_state=0,\n",
    "        activation='logistic', \n",
    "        alpha=1.4, \n",
    "        hidden_layer_sizes=(160,),\n",
    "        max_iter=260, \n",
    "        solver='sgd'),\n",
    "     ['best_features_MLP', best_features_MLP]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure number of fold\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30912, 190)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month >= 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, calibration, historical_training_year, features):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # reset index\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    df_test.reset_index(inplace=True,drop=True)\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    # TODO drop NaN instead of replacing ith means \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    if calibration:\n",
    "        sc_X = StandardScaler().fit(X)\n",
    "        X = sc_X.transform(X)\n",
    "        X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_columns(layer, classes):\n",
    "    cols = []\n",
    "    for clf_name, preprocess, calibration, historical_training_year, clf, features in layer:\n",
    "        for result in classes:\n",
    "            cols.append(clf_name+result)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer1_df(base_layer, cols):\n",
    "    X_train_layer1 = np.zeros((0, len(base_layer)*3))\n",
    "    X_train_layer1 = pd.DataFrame(X_train_layer1, columns=cols)\n",
    "    y_train_layer1 = pd.DataFrame()\n",
    "    return X_train_layer1, y_train_layer1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season', \n",
    "    'historical_training_year', \n",
    "    'best_score',\n",
    "    'C',\n",
    "    'penalty',\n",
    "    'class_weight',\n",
    "    'solver',\n",
    "    'max_iter',\n",
    "    'multi_class'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the layer 1\n",
    "cols = get_layer_columns(base_layer, classes)\n",
    "X_layer1, y_layer1 = get_layer1_df(base_layer, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 2014 XGBoost 9\n",
      "D1 2014 NB 9\n",
      "D1 2014 MLP 7\n",
      "D1 2015 XGBoost 9\n",
      "D1 2015 NB 9\n",
      "D1 2015 MLP 7\n",
      "D1 2016 XGBoost 9\n",
      "D1 2016 NB 9\n",
      "D1 2016 MLP 7\n"
     ]
    }
   ],
   "source": [
    "for season in season_list:\n",
    "    \n",
    "    # Temporary result for this season to add after to X_layer1\n",
    "    df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, False, 9, all_features)\n",
    "    X_layer_temp = np.zeros((X_test_season.shape[0], len(base_layer)*3))\n",
    "    X_layer_temp = pd.DataFrame(X_layer_temp, columns=X_layer1.columns)\n",
    "        \n",
    "    for clf_name, preprocess, calibration, historical_training_year, classifier, features in base_layer:\n",
    "        print league,str(season),clf_name,str(historical_training_year)\n",
    "        \n",
    "        #Get the dataset\n",
    "        df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, calibration, historical_training_year, features[1])\n",
    "        \n",
    "        # Check if we need to recalibrate the prediction\n",
    "        if calibration == 'sigmoid':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "        elif calibration == 'isotonic':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "        elif calibration == 'no':\n",
    "            clf = classifier\n",
    "        \n",
    "        # Calibrate the model\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        # Predict probabilities of the test season\n",
    "        y_probs = clf.predict_proba(X_test_season)\n",
    "        \n",
    "        # Add this model prediction to layer 1 dataset\n",
    "        X_layer_temp.loc[:, [clf_name+result for result in classes]] = y_probs\n",
    "        \n",
    "    # Add this season to X_layer1\n",
    "    X_layer1 = X_layer1.append(X_layer_temp)\n",
    "    y_layer1 = y_layer1.append(pd.DataFrame(y_test_season))\n",
    "\n",
    "# reset the index\n",
    "X_layer1.reset_index(inplace=True,drop=True)\n",
    "y_layer1.reset_index(inplace=True,drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'best_score',\n",
    "    'C',\n",
    "    'penalty',\n",
    "    'class_weight',\n",
    "    'solver',\n",
    "    'max_iter',\n",
    "    'multi_class'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 100 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    8.3s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C': np.arange(0.001, 10, 0.01).tolist(),\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "    'max_iter': np.arange(100,500,10).tolist(),\n",
    "    'multi_class': ['ovr', 'multinomial']\n",
    "}\n",
    "classifier = LogisticRegression()\n",
    "clf = RandomizedSearchCV(\n",
    "    estimator=classifier,\n",
    "    param_distributions=parameters,\n",
    "    #scoring=make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
    "    scoring='accuracy',\n",
    "    cv=8,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    n_iter=100)\n",
    "le = LabelEncoder()\n",
    "le.fit(y_layer1)\n",
    "clf.fit(X_layer1, le.transform(y_layer1))\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "# Add all info to result dataframe\n",
    "result_df.loc[len(result_df.index)] = [\n",
    "    league, \n",
    "    best_score,\n",
    "    best_params['C'],\n",
    "    best_params['penalty'],\n",
    "    best_params['class_weight'],\n",
    "    best_params['solver'],\n",
    "    best_params['max_iter'],\n",
    "    best_params['multi_class'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('./report/STACKING_1_FTR_D1_BEST_HYPERPARAM_LOG_LOSS-NOOOF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "Best is with ??? and ??? years of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>best_score</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>solver</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>0.528477</td>\n",
       "      <td>8.291</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>sag</td>\n",
       "      <td>270</td>\n",
       "      <td>multinomial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  league  best_score      C penalty class_weight solver max_iter  multi_class\n",
       "0     D1    0.528477  8.291      l2         None    sag      270  multinomial"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

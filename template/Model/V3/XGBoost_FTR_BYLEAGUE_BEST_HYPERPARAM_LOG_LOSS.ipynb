{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "#season_list = [2016]\n",
    "season_list = [2014, 2015, 2016]\n",
    "#league_list = ['D1', 'E0', 'E1', 'E2', 'F1', 'I1', 'SP1', 'SC0']\n",
    "league_list = ['SC0']\n",
    "historical_training_year_list = [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "features_list = [\n",
    "    ['all_features', all_features]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30912, 190)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month >= 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, historical_training_year, features):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    sc_X = StandardScaler().fit(X)\n",
    "    X = sc_X.transform(X)\n",
    "    X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season', \n",
    "    'historical_training_year', \n",
    "    'features',\n",
    "    'best_score',\n",
    "    'learning_rate',\n",
    "    'n_estimators',\n",
    "    'max_depth',\n",
    "    'min_child_weight',\n",
    "    'gamma',\n",
    "    'subsample',\n",
    "    'colsample_bytree',\n",
    "    'objective',\n",
    "    'scale_pos_weight',\n",
    "    'reg_alpha'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC0 2014 9 all_features\n",
      "Fitting 8 folds for each of 30 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC0 2015 9 all_features\n",
      "Fitting 8 folds for each of 30 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC0 2016 9 all_features\n",
      "Fitting 8 folds for each of 30 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 25.0min finished\n"
     ]
    }
   ],
   "source": [
    "for league in league_list:\n",
    "    for season in season_list:\n",
    "        for historical_training_year in historical_training_year_list:\n",
    "            for features in features_list:\n",
    "                print league,str(season),str(historical_training_year),features[0]\n",
    "                df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, historical_training_year, features[1])\n",
    "                # train model\n",
    "                parameters = {\n",
    "                    'learning_rate': [0.01],\n",
    "                    'n_estimators': np.arange(100, 600, 30).tolist(),\n",
    "                    'max_depth': np.arange(3, 9).tolist(),\n",
    "                    'min_child_weight': np.arange(1, 9).tolist(),\n",
    "                    'gamma': np.arange(0.01,1,0.03).tolist(),\n",
    "                    'subsample': np.arange(0.5,1,0.05).tolist(),\n",
    "                    'colsample_bytree': np.arange(0.5,1,0.05).tolist(),\n",
    "                    'objective': ['multi:softprob'],\n",
    "                    'scale_pos_weight': [1],\n",
    "                    'reg_alpha': np.arange(0,1,0.03).tolist()\n",
    "                }\n",
    "                classifier = XGBClassifier(nthread=4, seed=15)\n",
    "                clf = RandomizedSearchCV(\n",
    "                    estimator=classifier,\n",
    "                    param_distributions=parameters,\n",
    "                    #scoring=make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
    "                    scoring='accuracy',\n",
    "                    cv=8,\n",
    "                    #n_jobs=-1,\n",
    "                    verbose=1,\n",
    "                    n_iter=30)\n",
    "                clf.fit(X, y)\n",
    "                best_score = clf.best_score_\n",
    "                best_params = clf.best_params_\n",
    "                # Add all info to result dataframe\n",
    "                result_df.loc[len(result_df.index)] = [\n",
    "                    league, \n",
    "                    season, \n",
    "                    historical_training_year, \n",
    "                    features[0],\n",
    "                    best_score,\n",
    "                    best_params['learning_rate'],\n",
    "                    best_params['n_estimators'],\n",
    "                    best_params['max_depth'],\n",
    "                    best_params['min_child_weight'],\n",
    "                    best_params['gamma'],\n",
    "                    best_params['subsample'],\n",
    "                    best_params['colsample_bytree'],\n",
    "                    best_params['objective'],\n",
    "                    best_params['scale_pos_weight'],\n",
    "                    best_params['reg_alpha'],\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('./report/XGBoost_FTR_BYLEAGUE_BEST_HYPERPARAM_LOG_LOSS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "Best is with ??? and ??? years of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

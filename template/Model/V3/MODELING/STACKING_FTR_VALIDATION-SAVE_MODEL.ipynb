{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from IPython.display import display # Manage multiple output per cell\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_H = 'INFO_BbAvH'\n",
    "odd_A = 'INFO_BbAvA'\n",
    "odd_D = 'INFO_BbAvD'\n",
    "target = 'INFO_FTR'\n",
    "start_date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "season_list = [2016]\n",
    "league = 'E0'\n",
    "classes = ['A', 'D', 'H']\n",
    "filename = './models/'+league+'/'+league+'_'+str(season_list[0])+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_MLP = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "all_features = [\"A_MEANS_FIVE_AC\",\"A_MEANS_FIVE_AF\",\"A_MEANS_FIVE_AR\",\"A_MEANS_FIVE_AS\",\"A_MEANS_FIVE_AST\",\"A_MEANS_FIVE_AY\",\"A_MEANS_FIVE_FTAG\",\"A_MEANS_FIVE_FTHG\",\"A_MEANS_FIVE_FTR_A\",\"A_MEANS_FIVE_FTR_D\",\"A_MEANS_FIVE_FTR_H\",\"A_MEANS_FIVE_HC\",\"A_MEANS_FIVE_HF\",\"A_MEANS_FIVE_HR\",\"A_MEANS_FIVE_HS\",\"A_MEANS_FIVE_HST\",\"A_MEANS_FIVE_HTAG\",\"A_MEANS_FIVE_HTHG\",\"A_MEANS_FIVE_HTR_A\",\"A_MEANS_FIVE_HTR_D\",\"A_MEANS_FIVE_HTR_H\",\"A_MEANS_FIVE_HY\",\"H_MEANS_FIVE_AC\",\"H_MEANS_FIVE_AF\",\"H_MEANS_FIVE_AR\",\"H_MEANS_FIVE_AS\",\"H_MEANS_FIVE_AST\",\"H_MEANS_FIVE_AY\",\"H_MEANS_FIVE_FTAG\",\"H_MEANS_FIVE_FTHG\",\"H_MEANS_FIVE_FTR_A\",\"H_MEANS_FIVE_FTR_D\",\"H_MEANS_FIVE_FTR_H\",\"H_MEANS_FIVE_HC\",\"H_MEANS_FIVE_HF\",\"H_MEANS_FIVE_HR\",\"H_MEANS_FIVE_HS\",\"H_MEANS_FIVE_HST\",\"H_MEANS_FIVE_HTAG\",\"H_MEANS_FIVE_HTHG\",\"H_MEANS_FIVE_HTR_A\",\"H_MEANS_FIVE_HTR_D\",\"H_MEANS_FIVE_HTR_H\",\"H_MEANS_FIVE_HY\",\"A_MEANS_THREE_AC\",\"A_MEANS_THREE_AF\",\"A_MEANS_THREE_AR\",\"A_MEANS_THREE_AS\",\"A_MEANS_THREE_AST\",\"A_MEANS_THREE_AY\",\"A_MEANS_THREE_FTAG\",\"A_MEANS_THREE_FTHG\",\"A_MEANS_THREE_FTR_A\",\"A_MEANS_THREE_FTR_D\",\"A_MEANS_THREE_FTR_H\",\"A_MEANS_THREE_HC\",\"A_MEANS_THREE_HF\",\"A_MEANS_THREE_HR\",\"A_MEANS_THREE_HS\",\"A_MEANS_THREE_HST\",\"A_MEANS_THREE_HTAG\",\"A_MEANS_THREE_HTHG\",\"A_MEANS_THREE_HTR_A\",\"A_MEANS_THREE_HTR_D\",\"A_MEANS_THREE_HTR_H\",\"A_MEANS_THREE_HY\",\"H_MEANS_THREE_AC\",\"H_MEANS_THREE_AF\",\"H_MEANS_THREE_AR\",\"H_MEANS_THREE_AS\",\"H_MEANS_THREE_AST\",\"H_MEANS_THREE_AY\",\"H_MEANS_THREE_FTAG\",\"H_MEANS_THREE_FTHG\",\"H_MEANS_THREE_FTR_A\",\"H_MEANS_THREE_FTR_D\",\"H_MEANS_THREE_FTR_H\",\"H_MEANS_THREE_HC\",\"H_MEANS_THREE_HF\",\"H_MEANS_THREE_HR\",\"H_MEANS_THREE_HS\",\"H_MEANS_THREE_HST\",\"H_MEANS_THREE_HTAG\",\"H_MEANS_THREE_HTHG\",\"H_MEANS_THREE_HTR_A\",\"H_MEANS_THREE_HTR_D\",\"H_MEANS_THREE_HTR_H\",\"H_MEANS_THREE_HY\",\"A_STD_FIVE_AC\",\"A_STD_FIVE_AF\",\"A_STD_FIVE_AR\",\"A_STD_FIVE_AS\",\"A_STD_FIVE_AST\",\"A_STD_FIVE_AY\",\"A_STD_FIVE_FTAG\",\"A_STD_FIVE_FTHG\",\"A_STD_FIVE_FTR_A\",\"A_STD_FIVE_FTR_D\",\"A_STD_FIVE_FTR_H\",\"A_STD_FIVE_HC\",\"A_STD_FIVE_HF\",\"A_STD_FIVE_HR\",\"A_STD_FIVE_HS\",\"A_STD_FIVE_HST\",\"A_STD_FIVE_HTAG\",\"A_STD_FIVE_HTHG\",\"A_STD_FIVE_HTR_A\",\"A_STD_FIVE_HTR_D\",\"A_STD_FIVE_HTR_H\",\"A_STD_FIVE_HY\",\"H_STD_FIVE_AC\",\"H_STD_FIVE_AF\",\"H_STD_FIVE_AR\",\"H_STD_FIVE_AS\",\"H_STD_FIVE_AST\",\"H_STD_FIVE_AY\",\"H_STD_FIVE_FTAG\",\"H_STD_FIVE_FTHG\",\"H_STD_FIVE_FTR_A\",\"H_STD_FIVE_FTR_D\",\"H_STD_FIVE_FTR_H\",\"H_STD_FIVE_HC\",\"H_STD_FIVE_HF\",\"H_STD_FIVE_HR\",\"H_STD_FIVE_HS\",\"H_STD_FIVE_HST\",\"H_STD_FIVE_HTAG\",\"H_STD_FIVE_HTHG\",\"H_STD_FIVE_HTR_A\",\"H_STD_FIVE_HTR_D\",\"H_STD_FIVE_HTR_H\",\"H_STD_FIVE_HY\",\"A_STD_THREE_AC\",\"A_STD_THREE_AF\",\"A_STD_THREE_AR\",\"A_STD_THREE_AS\",\"A_STD_THREE_AST\",\"A_STD_THREE_AY\",\"A_STD_THREE_FTAG\",\"A_STD_THREE_FTHG\",\"A_STD_THREE_FTR_A\",\"A_STD_THREE_FTR_D\",\"A_STD_THREE_FTR_H\",\"A_STD_THREE_HC\",\"A_STD_THREE_HF\",\"A_STD_THREE_HR\",\"A_STD_THREE_HS\",\"A_STD_THREE_HST\",\"A_STD_THREE_HTAG\",\"A_STD_THREE_HTHG\",\"A_STD_THREE_HTR_A\",\"A_STD_THREE_HTR_D\",\"A_STD_THREE_HTR_H\",\"A_STD_THREE_HY\",\"H_STD_THREE_AC\",\"H_STD_THREE_AF\",\"H_STD_THREE_AR\",\"H_STD_THREE_AS\",\"H_STD_THREE_AST\",\"H_STD_THREE_AY\",\"H_STD_THREE_FTAG\",\"H_STD_THREE_FTHG\",\"H_STD_THREE_FTR_A\",\"H_STD_THREE_FTR_D\",\"H_STD_THREE_FTR_H\",\"H_STD_THREE_HC\",\"H_STD_THREE_HF\",\"H_STD_THREE_HR\",\"H_STD_THREE_HS\",\"H_STD_THREE_HST\",\"H_STD_THREE_HTAG\",\"H_STD_THREE_HTHG\",\"H_STD_THREE_HTR_A\",\"H_STD_THREE_HTR_D\",\"H_STD_THREE_HTR_H\",\"H_STD_THREE_HY\"]\n",
    "best_features_NB = ['A_MEANS_FIVE_AC', 'A_MEANS_FIVE_AS', 'A_MEANS_FIVE_AST','A_MEANS_FIVE_FTAG', 'A_MEANS_FIVE_FTHG', 'A_MEANS_FIVE_FTR_H','A_MEANS_FIVE_HC', 'A_MEANS_FIVE_HS', 'A_MEANS_FIVE_HST','A_MEANS_FIVE_HTR_A', 'H_MEANS_FIVE_AC', 'H_MEANS_FIVE_AS','H_MEANS_FIVE_AST', 'H_MEANS_FIVE_AY', 'H_MEANS_FIVE_FTAG','H_MEANS_FIVE_FTHG', 'H_MEANS_FIVE_FTR_A', 'H_MEANS_FIVE_FTR_H','H_MEANS_FIVE_HC', 'H_MEANS_FIVE_HS', 'H_MEANS_FIVE_HST','H_MEANS_FIVE_HTR_H', 'A_MEANS_THREE_AC', 'A_MEANS_THREE_AS','A_MEANS_THREE_FTHG', 'A_MEANS_THREE_HS', 'H_MEANS_THREE_AS','A_STD_FIVE_HF', 'H_STD_FIVE_HC', 'H_STD_FIVE_HST']\n",
    "features_list = [\n",
    "    ['best_features_MLP', best_features_MLP],\n",
    "    ['all_features', all_features],\n",
    "    ['best_features_NB', best_features_NB]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter for layer 1\n",
    "best_params = {\n",
    "    'C': 8.291,\n",
    "    'penalty': 'l2',\n",
    "    'class_weight': None,\n",
    "    'solver': 'sag',\n",
    "    'max_iter': 270,\n",
    "    'multi_class': 'multinomial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct base layer\n",
    "base_layer = [\n",
    "    ['XGBoost', True, 'no', 9, XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=160,\n",
    "        max_depth=8,\n",
    "        min_child_weight=7,\n",
    "        gamma=0.28,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6,\n",
    "        objective='multi:softprob',\n",
    "        reg_alpha=0.87,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=15), \n",
    "     ['all_features', all_features]\n",
    "    ],\n",
    "    ['NB', True, 'no', 9, GaussianNB(), ['best_features_NB', best_features_NB]],\n",
    "    ['MLP', True, 'no', 9, MLPClassifier(\n",
    "        random_state=0,\n",
    "        activation='logistic', \n",
    "        alpha=0.8, \n",
    "        hidden_layer_sizes=(220,),\n",
    "        max_iter=270, \n",
    "        solver='sgd'),\n",
    "     ['best_features_MLP', best_features_MLP]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure number of fold\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB Sqlite connection\n",
    "import sqlite3\n",
    "db = \"/Users/thibaultclement/Project/ligue1-predict/src/notebook/data/db/soccer_predict.sqlite\"\n",
    "conn = sqlite3.connect(db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37907, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all prematch data\n",
    "df_all = pd.read_sql_query(\"SELECT * FROM pre_matchs ORDER BY INFO_Date ASC;\", conn)\n",
    "df_all = (df_all[df_all.columns.drop(['index'])])\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30912, 190)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all game between June (include) and October (include)\n",
    "df_all['INFO_Date'] = pd.to_datetime(df_all['INFO_Date'])\n",
    "df_all['INFO_Date'].dt.month\n",
    "df_all = df_all[(df_all['INFO_Date'].dt.month < 6) | (df_all['INFO_Date'].dt.month >= 10)]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a INFO_WIN column containing the gain if you bet the good result\n",
    "df_all['INFO_WIN'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN'] = df_all[odd_H]\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN'] = df_all[odd_A]\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN'] = df_all[odd_D]\n",
    "df_all['INFO_WIN_P'] = 0\n",
    "df_all.loc[df_all.INFO_FTR == 'H', 'INFO_WIN_P'] = df_all['INFO_PSH']\n",
    "df_all.loc[df_all.INFO_FTR == 'A', 'INFO_WIN_P'] = df_all['INFO_PSA']\n",
    "df_all.loc[df_all.INFO_FTR == 'D', 'INFO_WIN_P'] = df_all['INFO_PSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(league, season, preprocessing, historical_training_year, features, clf_name):\n",
    "    # Filter by league\n",
    "    df = df_all[(df_all['INFO_Div'] == league)]\n",
    "    # Keep season for test and filter by number of historical season used to train\n",
    "    date_start_learn = datetime.date(season-historical_training_year, 8, 1)\n",
    "    date_end_learn = datetime.date(season, 8, 1)\n",
    "    date_start_test_season = datetime.date(season, 8, 1)\n",
    "    date_end_test_season = datetime.date(season+1, 8, 1)\n",
    "    df_test = df[(df['INFO_Date'] > date_start_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'] < date_end_test_season)]\n",
    "    df_test = df_test[(df_test['INFO_Date'].dt.month < 6) | (df_test['INFO_Date'].dt.month > 10)]\n",
    "    df = df[(df['INFO_Date'] > date_start_learn)]\n",
    "    df = df[(df['INFO_Date'] < date_end_learn)]\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    # Filter by feature used to train\n",
    "    X = pd.get_dummies(df[features])\n",
    "    y = df[target]\n",
    "    X_test_season = pd.get_dummies(df_test[features])\n",
    "    y_test_season = df_test[target]\n",
    "    # Impute of missing values (NaN) with the mean\n",
    "    # TODO drop NaN instead of replacing ith means \n",
    "    imp = joblib.load(filename+\"imputer\"+clf_name+\".pkl\")\n",
    "    X = imp.transform(X)\n",
    "    X_test_season = imp.transform(X_test_season)\n",
    "    # Standardize features\n",
    "    if preprocessing:\n",
    "        sc_X = joblib.load(filename+\"scaler\"+clf_name+\".pkl\")\n",
    "        X = sc_X.transform(X)\n",
    "        X_test_season = sc_X.transform(X_test_season)\n",
    "    return df, df_test, X, y, X_test_season, y_test_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out of fold prediction\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "    oof_train = np.zeros((x_train.shape[0],3))\n",
    "    oof_test = np.zeros((x_test.shape[0],3))\n",
    "    oof_test_skf = np.empty((NFOLDS, x_test.shape[0], 3))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        # Calibrate model\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_columns(layer, classes):\n",
    "    cols = []\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, clf, features in layer:\n",
    "        for result in classes:\n",
    "            cols.append(clf_name+result)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer1_df(X, X_test_season, base_layer, cols):\n",
    "    X_train_layer1 = np.zeros((X.shape[0], len(base_layer)*3))\n",
    "    X_train_layer1 = pd.DataFrame(X_train_layer1, columns=cols)\n",
    "    X_test_layer1 = np.zeros((X_test_season.shape[0], len(base_layer)*3))\n",
    "    X_test_layer1 = pd.DataFrame(X_test_layer1, columns=cols)\n",
    "    return X_train_layer1, X_test_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(y, pred, probs):\n",
    "    # Compute cross-entropy score\n",
    "    ll = log_loss(y, probs)\n",
    "    # Compute accuracy score\n",
    "    acc = accuracy_score(y, pred)\n",
    "    # Compute precision score\n",
    "    prec = precision_score(y, pred, average=None)\n",
    "    prec_A = prec[0]\n",
    "    prec_D = prec[1]\n",
    "    prec_H = prec[2]\n",
    "    # Compute recall score\n",
    "    rec = recall_score(y, pred, average=None)\n",
    "    rec_A = rec[0]\n",
    "    rec_D = rec[1]\n",
    "    rec_H = rec[2]\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y, pred, average=None)\n",
    "    f1_A = f1[0]\n",
    "    f1_D = f1[1]\n",
    "    f1_H = f1[2]\n",
    "    return {\n",
    "        'll': ll, \n",
    "        'acc': acc, \n",
    "        'prec_A': prec_A, \n",
    "        'prec_D': prec_D, \n",
    "        'prec_H': prec_H, \n",
    "        'rec_A': rec_A, \n",
    "        'rec_D': rec_D, \n",
    "        'rec_H': rec_H, \n",
    "        'f1_A': f1_A, \n",
    "        'f1_D': f1_D, \n",
    "        'f1_H': f1_H\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_money(df_test, pred_season, prob_season):\n",
    "    # Join odd and prediction together\n",
    "    df_test_season = df_test\n",
    "    df_test_season['probs_A'] = prob_season[:,0]\n",
    "    df_test_season['probs_D'] = prob_season[:,1]\n",
    "    df_test_season['probs_H'] = prob_season[:,2]\n",
    "    df_test_season['probs'] = df_test_season[['probs_A','probs_D','probs_H']].max(axis=1)\n",
    "    #df_test_season['pred'] = le.inverse_transform(pred_season)\n",
    "    df_test_season['pred'] = pred_season\n",
    "    df_test_season['WIN'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN'] = df_test_season['INFO_WIN']-1\n",
    "    df_test_season['WIN_P'] = -1\n",
    "    df_test_season.loc[df_test_season.INFO_FTR == df_test_season.pred, 'WIN_P'] = df_test_season['INFO_WIN_P']-1\n",
    "    df_test_season['INFO_ODD_BET'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'INFO_ODD_BET'] = df_test_season[odd_A]\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'INFO_ODD_BET'] = df_test_season[odd_D]\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'INFO_ODD_BET'] = df_test_season[odd_H]\n",
    "    df_test_season['prob_less_bet'] = 0\n",
    "    df_test_season.loc[df_test_season.pred == 'A', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_A].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'D', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_D].apply(lambda x: 1/x)\n",
    "    df_test_season.loc[df_test_season.pred == 'H', 'prob_less_bet'] = df_test_season['probs'] - df_test_season[odd_H].apply(lambda x: 1/x)\n",
    "    # calculate money I can get following different scenario\n",
    "    # Bet on all\n",
    "    bet_all = df_test_season.WIN.mean()\n",
    "    # Bet under 1.9\n",
    "    bet_lte_19 = df_test_season[df_test_season['INFO_ODD_BET'] < 1.9].WIN.mean()\n",
    "    # Bet under 4\n",
    "    bet_lte_4 = df_test_season[df_test_season['INFO_ODD_BET'] < 4].WIN.mean()\n",
    "    # Bet between 1.9 and 4\n",
    "    bet_btw_19_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.9 and 5\n",
    "    bet_btw_19_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.9) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet between 1.5 and 4\n",
    "    bet_btw_15_4 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 4)].WIN.mean()\n",
    "    # Bet between 1.5 and 5\n",
    "    bet_btw_15_5 = df_test_season[(df_test_season['INFO_ODD_BET'] > 1.5) & (df_test_season['INFO_ODD_BET'] < 5)].WIN.mean()\n",
    "    # Bet prob higher than 50%\n",
    "    bet_pred_gte_50 = df_test_season[df_test_season.probs > 0.5].WIN.mean()\n",
    "    # Bet prob higher than 60%\n",
    "    bet_pred_gte_60 = df_test_season[df_test_season.probs > 0.6].WIN.mean()\n",
    "    # Bet prob higher than 70%\n",
    "    bet_pred_gte_70 = df_test_season[df_test_season.probs > 0.7].WIN.mean()\n",
    "    return {\n",
    "        'bet_all': bet_all,\n",
    "        'bet_lte_19': bet_lte_19,\n",
    "        'bet_lte_4': bet_lte_4,\n",
    "        'bet_btw_19_4': bet_btw_19_4,\n",
    "        'bet_btw_19_5': bet_btw_19_5,\n",
    "        'bet_btw_15_4': bet_btw_15_4,\n",
    "        'bet_btw_15_5': bet_btw_15_5\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'league', \n",
    "    'season',\n",
    "    'C',\n",
    "    'penalty',\n",
    "    'class_weight',\n",
    "    'solver',\n",
    "    'max_iter',\n",
    "    'multi_class',\n",
    "    'll',\n",
    "    'acc',\n",
    "    'prec_A',\n",
    "    'prec_D',\n",
    "    'prec_H',\n",
    "    'rec_A',\n",
    "    'rec_D',\n",
    "    'rec_H',\n",
    "    'f1_A',\n",
    "    'f1_D',\n",
    "    'f1_H',\n",
    "    'bet_all',\n",
    "    'bet_lte_19',\n",
    "    'bet_lte_4',\n",
    "    'bet_btw_19_4',\n",
    "    'bet_btw_19_5',\n",
    "    'bet_btw_15_4',\n",
    "    'bet_btw_15_5'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 2016\n",
      "Processing model: XGBoost\n",
      "Processing model: NB\n",
      "Processing model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for season in season_list:\n",
    "    print league,str(season)\n",
    "    \n",
    "    # Prepare the layer 1\n",
    "    df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, False, 9, all_features, 'XGBoost')\n",
    "    cols = get_layer_columns(base_layer, classes)\n",
    "    X_layer1, X_layer1_test_season = get_layer1_df(X, X_test_season, base_layer, cols)\n",
    "    \n",
    "    # train base layer\n",
    "    for clf_name, preprocessing, calibration, historical_training_year, classifier, features in base_layer:\n",
    "        \n",
    "        #Get the dataset\n",
    "        df, df_test, X, y, X_test_season, y_test_season = get_dataset(league, season, preprocessing, 9, features[1], clf_name)\n",
    "        \n",
    "        print \"Processing model:\",clf_name\n",
    "        # Check if we need to recalibrate the prediction\n",
    "        if calibration == 'sigmoid':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='sigmoid')\n",
    "        elif calibration == 'isotonic':\n",
    "            clf = CalibratedClassifierCV(classifier, cv=4, method='isotonic')\n",
    "        elif calibration == 'no':\n",
    "            clf = classifier\n",
    "        \n",
    "        # Base Layer for test season\n",
    "        #Get the dataset\n",
    "        df2, df_test, X2, y2, X_test_season, y_test_season = get_dataset(league, season, preprocessing, historical_training_year, features[1], clf_name)\n",
    "        #clf_test = classifier\n",
    "        #clf_test.fit(X, y)\n",
    "        clf_test = joblib.load(filename+\"model_layer0_\"+clf_name+\".pkl\")\n",
    "        predict_probs_test = clf_test.predict_proba(X_test_season)\n",
    "        X_layer1_test_season.loc[:, [clf_name+result for result in classes]] = predict_probs_test\n",
    "\n",
    "    # train stacking model\n",
    "    #clf_1 = LogisticRegression()\n",
    "    #clf_1.fit(X_layer1, y)\n",
    "    clf_1 = joblib.load(filename+\"model_layer1.pkl\")\n",
    "    # Predict target values\n",
    "    y_pred = clf_1.predict(X_layer1_test_season)\n",
    "    # Predict probabilities\n",
    "    y_probs = clf_1.predict_proba(X_layer1_test_season)\n",
    "    # get scores\n",
    "    score_dict = get_score(y_test_season, y_pred, y_probs)\n",
    "    # get money earned\n",
    "    money_dict = get_money(df_test, y_pred, y_probs)\n",
    "    # Keep result for further analyis\n",
    "    df_result = df_result.append(df_test)\n",
    "    # Add all info to result dataframe\n",
    "    result_df.loc[len(result_df.index)] = [\n",
    "        league, \n",
    "        season, \n",
    "        best_params['C'],\n",
    "        best_params['penalty'],\n",
    "        best_params['class_weight'],\n",
    "        best_params['solver'],\n",
    "        best_params['max_iter'],\n",
    "        best_params['multi_class'],\n",
    "        score_dict['ll'],\n",
    "        score_dict['acc'],\n",
    "        score_dict['prec_A'],\n",
    "        score_dict['prec_D'],\n",
    "        score_dict['prec_H'],\n",
    "        score_dict['rec_A'],\n",
    "        score_dict['rec_D'],\n",
    "        score_dict['rec_H'],\n",
    "        score_dict['f1_A'],\n",
    "        score_dict['f1_D'],\n",
    "        score_dict['f1_H'],\n",
    "        money_dict['bet_all'],\n",
    "        money_dict['bet_lte_19'],\n",
    "        money_dict['bet_lte_4'],\n",
    "        money_dict['bet_btw_19_4'],\n",
    "        money_dict['bet_btw_19_5'],\n",
    "        money_dict['bet_btw_15_4'],\n",
    "        money_dict['bet_btw_15_5']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result_df.to_csv('./report/STACKING_1_FTR_E0_BEST_VALIDATION.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('../report/'+league+'_'+str(season_list[0])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result\n",
    "Best is with ??? and ??? years of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove games I didn't bet on\n",
    "df_bet_current_season = df_result\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTHG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG < 1].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.A_MEANS_FIVE_FTAG > 3].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.probs <= 0.4].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred != 'H'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.pred == 'D'].index)\n",
    "#df_bet_current_season = df_bet_current_season.drop(df_bet_current_season[df_bet_current_season.prob_less_bet <= 0].index)\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season.prob_less_bet > 0]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] > 2]\n",
    "#df_bet_current_season = df_bet_current_season[df_bet_current_season['INFO_ODD_BET'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    66.45768\n",
       "A    33.54232\n",
       "Name: pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.pred.value_counts() / len(df_bet_current_season.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "H    50.156740\n",
       "A    27.272727\n",
       "D    22.570533\n",
       "Name: INFO_FTR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What will be the real result of games I bet on\n",
    "display(plt.show(), 100. * df_bet_current_season.INFO_FTR.value_counts() / len(df_bet_current_season.INFO_FTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04520376175548588"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057241379310344856"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.WIN_P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 202)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_Date</th>\n",
       "      <th>probs_A</th>\n",
       "      <th>probs_D</th>\n",
       "      <th>probs_H</th>\n",
       "      <th>probs</th>\n",
       "      <th>prob_less_bet</th>\n",
       "      <th>pred</th>\n",
       "      <th>INFO_FTR</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.536471</td>\n",
       "      <td>0.235779</td>\n",
       "      <td>0.227751</td>\n",
       "      <td>0.536471</td>\n",
       "      <td>-0.134670</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.420160</td>\n",
       "      <td>0.291064</td>\n",
       "      <td>0.288776</td>\n",
       "      <td>0.420160</td>\n",
       "      <td>0.103705</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.558122</td>\n",
       "      <td>0.221974</td>\n",
       "      <td>0.219904</td>\n",
       "      <td>0.558122</td>\n",
       "      <td>-0.136322</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.260838</td>\n",
       "      <td>0.563680</td>\n",
       "      <td>0.563680</td>\n",
       "      <td>0.138148</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.207984</td>\n",
       "      <td>0.284806</td>\n",
       "      <td>0.507210</td>\n",
       "      <td>0.507210</td>\n",
       "      <td>0.054721</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>0.542850</td>\n",
       "      <td>0.229994</td>\n",
       "      <td>0.227156</td>\n",
       "      <td>0.542850</td>\n",
       "      <td>-0.181787</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.217436</td>\n",
       "      <td>0.649999</td>\n",
       "      <td>0.649999</td>\n",
       "      <td>0.197511</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>0.134932</td>\n",
       "      <td>0.219189</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>-0.100390</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>0.346544</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.347422</td>\n",
       "      <td>0.347422</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.150292</td>\n",
       "      <td>0.216785</td>\n",
       "      <td>0.632923</td>\n",
       "      <td>0.632923</td>\n",
       "      <td>-0.148327</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.303453</td>\n",
       "      <td>0.294072</td>\n",
       "      <td>0.402476</td>\n",
       "      <td>0.402476</td>\n",
       "      <td>-0.143972</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.199517</td>\n",
       "      <td>0.261886</td>\n",
       "      <td>0.538597</td>\n",
       "      <td>0.538597</td>\n",
       "      <td>-0.094314</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.259943</td>\n",
       "      <td>0.241755</td>\n",
       "      <td>0.498302</td>\n",
       "      <td>0.498302</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.127421</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>0.666472</td>\n",
       "      <td>0.666472</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.330191</td>\n",
       "      <td>0.310582</td>\n",
       "      <td>0.359227</td>\n",
       "      <td>0.359227</td>\n",
       "      <td>-0.143286</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.487575</td>\n",
       "      <td>0.270363</td>\n",
       "      <td>0.242063</td>\n",
       "      <td>0.487575</td>\n",
       "      <td>-0.093821</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-10-16</td>\n",
       "      <td>0.346871</td>\n",
       "      <td>0.280090</td>\n",
       "      <td>0.373040</td>\n",
       "      <td>0.373040</td>\n",
       "      <td>-0.071405</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-10-16</td>\n",
       "      <td>0.100750</td>\n",
       "      <td>0.205399</td>\n",
       "      <td>0.693851</td>\n",
       "      <td>0.693851</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-10-17</td>\n",
       "      <td>0.151479</td>\n",
       "      <td>0.207886</td>\n",
       "      <td>0.640636</td>\n",
       "      <td>0.640636</td>\n",
       "      <td>0.177673</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.135347</td>\n",
       "      <td>0.210565</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>-0.139563</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>0.283664</td>\n",
       "      <td>0.267374</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>-0.058652</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.422564</td>\n",
       "      <td>0.296780</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.422564</td>\n",
       "      <td>-0.179846</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.379026</td>\n",
       "      <td>0.287937</td>\n",
       "      <td>0.333037</td>\n",
       "      <td>0.379026</td>\n",
       "      <td>-0.024200</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.237126</td>\n",
       "      <td>0.270133</td>\n",
       "      <td>0.492741</td>\n",
       "      <td>0.492741</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.134861</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>0.655475</td>\n",
       "      <td>0.655475</td>\n",
       "      <td>-0.125775</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.449691</td>\n",
       "      <td>0.293928</td>\n",
       "      <td>0.256381</td>\n",
       "      <td>0.449691</td>\n",
       "      <td>0.143881</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>0.160817</td>\n",
       "      <td>0.243268</td>\n",
       "      <td>0.595915</td>\n",
       "      <td>0.595915</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0.306286</td>\n",
       "      <td>0.294648</td>\n",
       "      <td>0.399066</td>\n",
       "      <td>0.399066</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0.119247</td>\n",
       "      <td>0.209573</td>\n",
       "      <td>0.671180</td>\n",
       "      <td>0.671180</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>0.504212</td>\n",
       "      <td>0.240596</td>\n",
       "      <td>0.255192</td>\n",
       "      <td>0.504212</td>\n",
       "      <td>-0.073823</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>0.156413</td>\n",
       "      <td>0.228461</td>\n",
       "      <td>0.615126</td>\n",
       "      <td>0.615126</td>\n",
       "      <td>0.252807</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.387376</td>\n",
       "      <td>0.311348</td>\n",
       "      <td>0.301276</td>\n",
       "      <td>0.387376</td>\n",
       "      <td>0.144067</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.218729</td>\n",
       "      <td>0.287977</td>\n",
       "      <td>0.493293</td>\n",
       "      <td>0.493293</td>\n",
       "      <td>-0.135637</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.112862</td>\n",
       "      <td>0.207263</td>\n",
       "      <td>0.679875</td>\n",
       "      <td>0.679875</td>\n",
       "      <td>-0.182194</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0.248843</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>0.505887</td>\n",
       "      <td>0.505887</td>\n",
       "      <td>0.226557</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.118855</td>\n",
       "      <td>0.203135</td>\n",
       "      <td>0.678009</td>\n",
       "      <td>0.678009</td>\n",
       "      <td>-0.011646</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.517260</td>\n",
       "      <td>0.243686</td>\n",
       "      <td>0.239054</td>\n",
       "      <td>0.517260</td>\n",
       "      <td>-0.218034</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.169619</td>\n",
       "      <td>0.227876</td>\n",
       "      <td>0.602505</td>\n",
       "      <td>0.602505</td>\n",
       "      <td>0.081672</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.217375</td>\n",
       "      <td>0.654163</td>\n",
       "      <td>0.654163</td>\n",
       "      <td>-0.158845</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.404373</td>\n",
       "      <td>0.276762</td>\n",
       "      <td>0.318864</td>\n",
       "      <td>0.404373</td>\n",
       "      <td>-0.095627</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.349645</td>\n",
       "      <td>0.255096</td>\n",
       "      <td>0.395259</td>\n",
       "      <td>0.395259</td>\n",
       "      <td>0.175961</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.387833</td>\n",
       "      <td>0.262085</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>0.387833</td>\n",
       "      <td>-0.135727</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.172702</td>\n",
       "      <td>0.243604</td>\n",
       "      <td>0.583695</td>\n",
       "      <td>0.583695</td>\n",
       "      <td>0.098258</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.123137</td>\n",
       "      <td>0.202581</td>\n",
       "      <td>0.674282</td>\n",
       "      <td>0.674282</td>\n",
       "      <td>0.086047</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>0.479364</td>\n",
       "      <td>0.251180</td>\n",
       "      <td>0.269455</td>\n",
       "      <td>0.479364</td>\n",
       "      <td>-0.119438</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>0.117885</td>\n",
       "      <td>0.203896</td>\n",
       "      <td>0.678219</td>\n",
       "      <td>0.678219</td>\n",
       "      <td>-0.128232</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>0.137585</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.647327</td>\n",
       "      <td>0.647327</td>\n",
       "      <td>-0.270104</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>0.117855</td>\n",
       "      <td>0.207096</td>\n",
       "      <td>0.675049</td>\n",
       "      <td>0.675049</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>0.378790</td>\n",
       "      <td>0.300734</td>\n",
       "      <td>0.320476</td>\n",
       "      <td>0.378790</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>0.355324</td>\n",
       "      <td>0.247110</td>\n",
       "      <td>0.397565</td>\n",
       "      <td>0.397565</td>\n",
       "      <td>0.164465</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.112928</td>\n",
       "      <td>0.210609</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>-0.027762</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.341692</td>\n",
       "      <td>0.270070</td>\n",
       "      <td>0.388238</td>\n",
       "      <td>0.388238</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.101696</td>\n",
       "      <td>0.198067</td>\n",
       "      <td>0.700237</td>\n",
       "      <td>0.700237</td>\n",
       "      <td>-0.169328</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.534324</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.235476</td>\n",
       "      <td>0.534324</td>\n",
       "      <td>-0.119271</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.122482</td>\n",
       "      <td>0.214708</td>\n",
       "      <td>0.662810</td>\n",
       "      <td>0.662810</td>\n",
       "      <td>0.141977</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.110434</td>\n",
       "      <td>0.210352</td>\n",
       "      <td>0.679214</td>\n",
       "      <td>0.679214</td>\n",
       "      <td>-0.213643</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.119054</td>\n",
       "      <td>0.211848</td>\n",
       "      <td>0.669098</td>\n",
       "      <td>0.669098</td>\n",
       "      <td>0.265872</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.347960</td>\n",
       "      <td>0.257455</td>\n",
       "      <td>0.394585</td>\n",
       "      <td>0.394585</td>\n",
       "      <td>-0.170386</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.141056</td>\n",
       "      <td>0.220261</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.153246</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>0.225176</td>\n",
       "      <td>0.240193</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>-0.246619</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFO_Date   probs_A   probs_D   probs_H     probs  prob_less_bet pred  \\\n",
       "0   2016-10-01  0.536471  0.235779  0.227751  0.536471      -0.134670    A   \n",
       "1   2016-10-01  0.420160  0.291064  0.288776  0.420160       0.103705    A   \n",
       "2   2016-10-01  0.558122  0.221974  0.219904  0.558122      -0.136322    A   \n",
       "3   2016-10-01  0.175482  0.260838  0.563680  0.563680       0.138148    H   \n",
       "4   2016-10-01  0.207984  0.284806  0.507210  0.507210       0.054721    H   \n",
       "5   2016-10-02  0.542850  0.229994  0.227156  0.542850      -0.181787    A   \n",
       "6   2016-10-02  0.132565  0.217436  0.649999  0.649999       0.197511    H   \n",
       "7   2016-10-02  0.134932  0.219189  0.645878  0.645878      -0.100390    H   \n",
       "8   2016-10-02  0.346544  0.306034  0.347422  0.347422       0.009584    H   \n",
       "9   2016-10-15  0.150292  0.216785  0.632923  0.632923      -0.148327    H   \n",
       "10  2016-10-15  0.303453  0.294072  0.402476  0.402476      -0.143972    H   \n",
       "11  2016-10-15  0.199517  0.261886  0.538597  0.538597      -0.094314    H   \n",
       "12  2016-10-15  0.259943  0.241755  0.498302  0.498302       0.022111    H   \n",
       "13  2016-10-15  0.127421  0.206107  0.666472  0.666472      -0.000195    H   \n",
       "14  2016-10-15  0.330191  0.310582  0.359227  0.359227      -0.143286    H   \n",
       "15  2016-10-15  0.487575  0.270363  0.242063  0.487575      -0.093821    A   \n",
       "16  2016-10-16  0.346871  0.280090  0.373040  0.373040      -0.071405    H   \n",
       "17  2016-10-16  0.100750  0.205399  0.693851  0.693851      -0.025573    H   \n",
       "18  2016-10-17  0.151479  0.207886  0.640636  0.640636       0.177673    H   \n",
       "19  2016-10-22  0.135347  0.210565  0.654088  0.654088      -0.139563    H   \n",
       "20  2016-10-22  0.448962  0.283664  0.267374  0.448962      -0.058652    A   \n",
       "21  2016-10-22  0.422564  0.296780  0.280656  0.422564      -0.179846    A   \n",
       "22  2016-10-22  0.379026  0.287937  0.333037  0.379026      -0.024200    A   \n",
       "23  2016-10-22  0.237126  0.270133  0.492741  0.492741       0.002545    H   \n",
       "24  2016-10-22  0.134861  0.209664  0.655475  0.655475      -0.125775    H   \n",
       "25  2016-10-22  0.449691  0.293928  0.256381  0.449691       0.143881    A   \n",
       "26  2016-10-22  0.160817  0.243268  0.595915  0.595915       0.000676    H   \n",
       "27  2016-10-23  0.306286  0.294648  0.399066  0.399066      -0.053422    H   \n",
       "28  2016-10-23  0.119247  0.209573  0.671180  0.671180       0.000039    H   \n",
       "29  2016-10-29  0.504212  0.240596  0.255192  0.504212      -0.073823    A   \n",
       "..         ...       ...       ...       ...       ...            ...  ...   \n",
       "289 2017-05-06  0.156413  0.228461  0.615126  0.615126       0.252807    H   \n",
       "290 2017-05-07  0.387376  0.311348  0.301276  0.387376       0.144067    A   \n",
       "291 2017-05-07  0.218729  0.287977  0.493293  0.493293      -0.135637    H   \n",
       "292 2017-05-08  0.112862  0.207263  0.679875  0.679875      -0.182194    H   \n",
       "293 2017-05-10  0.248843  0.245270  0.505887  0.505887       0.226557    H   \n",
       "294 2017-05-12  0.118855  0.203135  0.678009  0.678009      -0.011646    H   \n",
       "295 2017-05-12  0.517260  0.243686  0.239054  0.517260      -0.218034    A   \n",
       "296 2017-05-13  0.169619  0.227876  0.602505  0.602505       0.081672    H   \n",
       "297 2017-05-13  0.128462  0.217375  0.654163  0.654163      -0.158845    H   \n",
       "298 2017-05-13  0.404373  0.276762  0.318864  0.404373      -0.095627    A   \n",
       "299 2017-05-13  0.349645  0.255096  0.395259  0.395259       0.175961    H   \n",
       "300 2017-05-13  0.387833  0.262085  0.350082  0.387833      -0.135727    A   \n",
       "301 2017-05-14  0.172702  0.243604  0.583695  0.583695       0.098258    H   \n",
       "302 2017-05-14  0.123137  0.202581  0.674282  0.674282       0.086047    H   \n",
       "303 2017-05-14  0.479364  0.251180  0.269455  0.479364      -0.119438    A   \n",
       "304 2017-05-15  0.117885  0.203896  0.678219  0.678219      -0.128232    H   \n",
       "305 2017-05-16  0.137585  0.215088  0.647327  0.647327      -0.270104    H   \n",
       "306 2017-05-16  0.117855  0.207096  0.675049  0.675049      -0.209907    H   \n",
       "307 2017-05-17  0.378790  0.300734  0.320476  0.378790       0.015153    A   \n",
       "308 2017-05-18  0.355324  0.247110  0.397565  0.397565       0.164465    H   \n",
       "309 2017-05-21  0.112928  0.210609  0.676463  0.676463      -0.027762    H   \n",
       "310 2017-05-21  0.341692  0.270070  0.388238  0.388238      -0.031930    H   \n",
       "311 2017-05-21  0.101696  0.198067  0.700237  0.700237      -0.169328    H   \n",
       "312 2017-05-21  0.534324  0.230200  0.235476  0.534324      -0.119271    A   \n",
       "313 2017-05-21  0.122482  0.214708  0.662810  0.662810       0.141977    H   \n",
       "314 2017-05-21  0.110434  0.210352  0.679214  0.679214      -0.213643    H   \n",
       "315 2017-05-21  0.119054  0.211848  0.669098  0.669098       0.265872    H   \n",
       "316 2017-05-21  0.347960  0.257455  0.394585  0.394585      -0.170386    H   \n",
       "317 2017-05-21  0.141056  0.220261  0.638683  0.638683       0.153246    H   \n",
       "318 2017-05-21  0.534631  0.225176  0.240193  0.534631      -0.246619    A   \n",
       "\n",
       "    INFO_FTR   WIN  \n",
       "0          A  0.49  \n",
       "1          D -1.00  \n",
       "2          A  0.44  \n",
       "3          D -1.00  \n",
       "4          D -1.00  \n",
       "5          A  0.38  \n",
       "6          D -1.00  \n",
       "7          D -1.00  \n",
       "8          H  1.96  \n",
       "9          H  0.28  \n",
       "10         H  0.83  \n",
       "11         H  0.58  \n",
       "12         A -1.00  \n",
       "13         D -1.00  \n",
       "14         H  0.99  \n",
       "15         D -1.00  \n",
       "16         A -1.00  \n",
       "17         H  0.39  \n",
       "18         D -1.00  \n",
       "19         D -1.00  \n",
       "20         D -1.00  \n",
       "21         H -1.00  \n",
       "22         A  1.48  \n",
       "23         H  1.04  \n",
       "24         H  0.28  \n",
       "25         D -1.00  \n",
       "26         H  0.68  \n",
       "27         H  1.21  \n",
       "28         D -1.00  \n",
       "29         A  0.73  \n",
       "..       ...   ...  \n",
       "289        H  1.76  \n",
       "290        H -1.00  \n",
       "291        D -1.00  \n",
       "292        H  0.16  \n",
       "293        A -1.00  \n",
       "294        H  0.45  \n",
       "295        A  0.36  \n",
       "296        H  0.92  \n",
       "297        H  0.23  \n",
       "298        A  1.00  \n",
       "299        A -1.00  \n",
       "300        A  0.91  \n",
       "301        H  1.06  \n",
       "302        H  0.70  \n",
       "303        A  0.67  \n",
       "304        H  0.24  \n",
       "305        H  0.09  \n",
       "306        H  0.13  \n",
       "307        D -1.00  \n",
       "308        A -1.00  \n",
       "309        H  0.42  \n",
       "310        A -1.00  \n",
       "311        H  0.15  \n",
       "312        A  0.53  \n",
       "313        D -1.00  \n",
       "314        H  0.12  \n",
       "315        H  1.48  \n",
       "316        A -1.00  \n",
       "317        H  1.06  \n",
       "318        A  0.28  \n",
       "\n",
       "[319 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet_current_season[['INFO_Date', 'probs_A','probs_D','probs_H', 'probs', 'prob_less_bet', 'pred', 'INFO_FTR', 'WIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
